# INTL Compiler

**INTL (Intent Language)** is a structured intermediate representation designed to be written by frontier AI models and compiled into idiomatic, production-ready code in 24 target languages and frameworks.

Small fine-tuned **LoRA adapters on Qwen2.5-Coder-3B** do the heavy lifting â€” each adapter specialises in one target language/framework combination, trained on thousands of INTL â†’ code pairs.

---

## Architecture

```
User Requirement (freeform)
        â”‚
        â–¼
  generator.py  â”€â”€â”€â”€ decompose() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Project Manifest (JSON)
        â”‚
        â–¼
  generator.py  â”€â”€â”€â”€ generate_module() â”€â”€â”€â”€â”€â”€â–º .intl files  (parallel, one per module)
        â”‚
        â–¼
  parser.py     â”€â”€â”€â”€ parse() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Typed AST
        â”‚
        â–¼
  index.py      â”€â”€â”€â”€ index_module() â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º SQLite Semantic Index
        â”‚
        â–¼
  router.py     â”€â”€â”€â”€ route() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Adapter name  (O(1) lookup)
        â”‚
        â–¼
  compiler.py   â”€â”€â”€â”€ compile() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Target code  (Qwen2.5-Coder-3B + LoRA)
        â”‚
        â–¼
  validator.py  â”€â”€â”€â”€ validate() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º T1â€“T7 checks
        â”‚ fail
        â–¼
  escalation.py â”€â”€â”€â”€ escalate() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Corrected code  (Claude frontier model)
        â”‚
        â–¼
  generator.py  â”€â”€â”€â”€ patch() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º PATCH blocks  (incremental updates)
```

---

## How It Works

1. **Generator** (`generator.py`) â€” calls Claude to decompose a freeform requirement into a project manifest, then generates `.intl` source files for each module in parallel. Incremental updates produce PATCH blocks.
2. **Parser** (`grammar.lark` + `parser.py`) â€” validates INTL source against a Lark EBNF grammar and produces a typed AST (dataclasses). 24 constructs, precise line/column errors.
3. **Semantic Index** (`index.py`) â€” SQLite database tracking every compiled block, dirty state, dependency graph, and compilation history.
4. **LoRA Router** (`router.py`) â€” O(1) lookup table mapping language profile strings to adapter names. No inference required.
5. **Compiler** (`compiler.py`) â€” loads Qwen2.5-Coder-3B with the appropriate LoRA adapter via PEFT. Temperature 0.1. Wraps every output in `INTL:BEGIN / INTL:END` sentinels.
6. **Validator** (`validator.py`) â€” seven deterministic checks (T1â€“T7) on every compiled output. Returns a `ValidationResult` with pass/fail details and an escalation package on failure.
7. **Escalation** (`escalation.py`) â€” Claude frontier layer invoked when the LoRA retry budget is exhausted. Corrections are saved as Category C training pairs, continuously improving adapters.
8. **Training Data Generator** (`datagen.py`) â€” generates JSONL training pairs (A/B/C split) for any adapter using Claude.
9. **CLI** (`cli.py`) â€” `intl compile`, `intl build`, `intl status`, `intl adapters`, `intl validate`.

---

## 24 Target Adapters

| Phase | Adapters | Status |
|-------|----------|--------|
| **0** | `python_fastapi`, `sql_postgres` | ğŸ”² Training pending |
| **1** | `python_django`, `python_flask`, `typescript_express`, `sql_mysql` | ğŸ”² Training pending |
| **2** | `typescript_nextjs`, `php_laravel`, `php_vanilla`, `javascript_vanilla`, `html_jinja2`, `html_blade`, `css_tailwind` | ğŸ”² Training pending |
| **3** | `java_spring`, `csharp_dotnet`, `go_gin`, `ruby_rails`, `sql_tsql`, `sql_sqlite` | ğŸ”² Training pending |
| **4** | `swift_ios`, `kotlin_android`, `dart_flutter` | ğŸ”² Training pending |
| **5** | `rust_axum`, `cpp_modern` | ğŸ”² Training pending |

---

## Component Status

| Component | File | Tests | Status |
|-----------|------|-------|--------|
| Lark Grammar | `intl/grammar.lark` | â€” | âœ… Done |
| Parser | `intl/parser.py` | `tests/test_parser.py` | âœ… Done |
| Semantic Index | `intl/index.py` | `tests/test_index.py` | âœ… Done |
| LoRA Router | `intl/router.py` | `tests/test_router.py` | âœ… Done |
| Validator T1â€“T7 | `intl/validator.py` | `tests/test_validator.py` | âœ… Done |
| Training Data Gen | `intl/datagen.py` | â€” | âœ… Done |
| Compiler Engine | `intl/compiler.py` | â€” | âœ… Done |
| CLI | `intl/cli.py` | â€” | âœ… Done |
| Generator | `intl/generator.py` | `tests/test_generator.py` | âœ… Done |
| Escalation | `intl/escalation.py` | `tests/test_escalation.py` | âœ… Done |
| **Total tests** | | **193 / 193 passing** | âœ… |

---

## Quick Start

```bash
pip install -e .

# Compile a single .intl file
intl compile mymodule.intl --profile python_fastapi

# Build an entire project (auto-discovers .intl files)
intl build project/

# Check compilation status
intl status

# List available adapters
intl adapters

# Validate a compiled output
intl validate output.py --profile python_fastapi
```

---

## Project Structure

```
intl-compiler/
â”œâ”€â”€ README.md
â”œâ”€â”€ SPEC.md                        â† mirror of INTL_Specification.md
â”œâ”€â”€ intl/
â”‚   â”œâ”€â”€ grammar.lark               â† Lark EBNF â€” 24 constructs
â”‚   â”œâ”€â”€ parser.py                  â† typed AST dataclasses
â”‚   â”œâ”€â”€ index.py                   â† SQLite semantic index
â”‚   â”œâ”€â”€ router.py                  â† O(1) adapter lookup
â”‚   â”œâ”€â”€ compiler.py                â† Qwen2.5-Coder-3B + LoRA via PEFT
â”‚   â”œâ”€â”€ validator.py               â† T1â€“T7 validation pipeline
â”‚   â”œâ”€â”€ datagen.py                 â† JSONL training pair generator (Claude)
â”‚   â”œâ”€â”€ generator.py               â† INTL source generator (Claude)
â”‚   â”œâ”€â”€ escalation.py              â† Frontier correction layer (Claude)
â”‚   â”œâ”€â”€ cli.py                     â† CLI entry point
â”‚   â”œâ”€â”€ generated/                 â† .intl files produced by generator.py
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_parser.py
â”‚       â”œâ”€â”€ test_index.py
â”‚       â”œâ”€â”€ test_router.py
â”‚       â”œâ”€â”€ test_validator.py
â”‚       â”œâ”€â”€ test_generator.py
â”‚       â””â”€â”€ test_escalation.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ adapters.json              â† adapter registry (24 entries)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ <adapter>/
â”‚       â”œâ”€â”€ train.jsonl            â† A+B pairs (~60/30 split)
â”‚       â”œâ”€â”€ validation.jsonl       â† 200-pair held-out set
â”‚       â””â”€â”€ corrections.jsonl      â† Category C (escalation corrections)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ INTL_Specification.md      â† full language spec
â””â”€â”€ scripts/
    â””â”€â”€ train_adapter.sh           â† Vast.ai training script
```

---

## Training Data Format

Each JSONL line is a `{system, prompt, completion}` triple:

```jsonl
{
  "system": "You are the INTL compiler for Python FastAPI...",
  "prompt": "FUNCTION login [id=f001]\n  INTENT ...",
  "completion": "# â•â•â• INTL:BEGIN [id=f001] login â•â•â•\nasync def login(...): ..."
}
```

| Category | Split | Description |
|----------|-------|-------------|
| A | ~60% | Fresh INTL â†’ target code |
| B | ~30% | PATCH blocks |
| C | ~10% | Error correction (also from escalation) |

200 validation pairs per adapter, held out from training.

---

## Validation Checks (T1â€“T7)

| Check | Name | Description |
|-------|------|-------------|
| T1 | Syntax | Output is syntactically valid for the target language |
| T2 | Sentinels | `INTL:BEGIN` / `INTL:END` present with correct block ID |
| T3 | Preconditions | Every `PRECONDITION` token appears in compiled code |
| T4 | Postconditions | Every `POSTCONDITION` token appears in compiled code |
| T5 | Side Effects | `MUTATES`/`OBSERVABLE` declarations honoured |
| T6 | Types | Return type matches `RETURN` declaration |
| T7 | No Placeholders | No `TODO`, `FIXME`, `unimplemented!()` etc. in output |

Failed checks trigger re-compilation (up to retry budget), then escalation to Claude.

---

## Training Cost

Total estimated training cost: **~$2.85** across all 24 adapters on Vast.ai RTX 4090 instances (~$0.12/adapter).

---

## Models

| Role | Model |
|------|-------|
| Base compiler | `Qwen/Qwen2.5-Coder-3B-Instruct` |
| LoRA adapters | `$HF_USERNAME/intl-adapters` (HuggingFace) |
| Generator / Escalation | `claude-sonnet-4-6` |
| Training data gen | `claude-sonnet-4-6` |

---

## License

Proprietary â€” Confidential.
