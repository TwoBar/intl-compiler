{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return {\n        \"id\": product.id,\n        \"name\": product.name,\n        \"price\": product.price,\n        \"description\": product.description\n    }\nINTL:END\n\nPATCH f0408 [target=f0408]\n  INTENT \"add confidence score to product response\"\n  ADD AFTER: \"description\": product.description\n    \"confidence\": product.confidence_score if product.confidence_score else 0.85\nEND PATCH f0408", "completion": "INTL:BEGIN\n@app.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return {\n        \"id\": product.id,\n        \"name\": product.name,\n        \"price\": product.price,\n        \"description\": product.description,\n        \"confidence\": product.confidence_score if product.confidence_score else 0.85\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 408}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_session [id=f0040]\n  INTENT       \"invalidate user session and log revocation event\"\n  PRECONDITION token.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.success IS TRUE\n  READS        sessions_table\n  MUTATES      sessions_table, audit_log_table\n  OBSERVABLE\n\n  session = QUERY sessions_table WHERE token == token LIMIT 1\n  IF session IS NULL THEN FAIL SessionError(\"session_not_found\")\n  IF session.user_id != user_id THEN FAIL SessionError(\"unauthorized_revocation\")\n  DELETE sessions_table WHERE token == token\n  PERSIST audit_log_table (user_id: user_id, action: \"session_revoked\", token_hash: hash(token), timestamp: now())\n  RETURN RevokeResult(success: TRUE)\nEND FUNCTION revoke_session [id=f0040]", "completion": "# ═══ INTL:BEGIN [id=f0040] revoke_session ═══\nimport logging\nfrom datetime import datetime\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_session(token: str, user_id: int) -> RevokeResult:\n    assert len(token) > 0, \"token must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    \n    session = await db.query(sessions_table).filter(token=token).first()\n    if session is None:\n        raise SessionError(\"session_not_found\")\n    if session.user_id != user_id:\n        raise SessionError(\"unauthorized_revocation\")\n    \n    await db.delete(sessions_table).filter(token=token)\n    \n    token_hash = hashlib.sha256(token.encode()).hexdigest()\n    await db.insert(audit_log_table, \n                    user_id=user_id, \n                    action=\"session_revoked\", \n                    token_hash=token_hash, \n                    timestamp=datetime.utcnow())\n    \n    logger.info(\"revoke_session: user_id=%d token_hash=%s\", user_id, token_hash[:16])\n    result = RevokeResult(success=True)\n    assert result.success is True\n    return result\n# ═══ INTL:END   [id=f0040] revoke_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 40}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/webhook/process\")\nasync def process_webhook(request: WebhookRequest):\n    result = validate_payload(request.data)\n    event_type = request.headers.get(\"x-event-type\")\n    return {\"status\": \"received\", \"event\": event_type}\nINTL:END\n\nPATCH f0730 [target=f0730]\n  INTENT \"add confidence scoring to webhook validation\"\n  ADD BEFORE: result = validate_payload(request.data)\n    confidence_score = calculate_confidence(request.headers, request.data)\n    if confidence_score < 0.7:\n        raise HTTPException(status_code=400, detail=\"Low confidence webhook\")\nEND PATCH f0730", "completion": "INTL:BEGIN\n@app.post(\"/webhook/process\")\nasync def process_webhook(request: WebhookRequest):\n    confidence_score = calculate_confidence(request.headers, request.data)\n    if confidence_score < 0.7:\n        raise HTTPException(status_code=400, detail=\"Low confidence webhook\")\n    result = validate_payload(request.data)\n    event_type = request.headers.get(\"x-event-type\")\n    return {\"status\": \"received\", \"event\": event_type}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 730}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI, HTTPException\nfrom typing import List\n\napp = FastAPI()\n\n@app.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    if product_id <= 0:\n        raise HTTPException(status_code=400, detail=\"Invalid product ID\")\n    return {\"product_id\": product_id, \"name\": \"Sample Product\"}\n\n@app.post(\"/products\")\nasync def create_product(name: str, price: float):\n    if not name or price < 0:\n        raise HTTPException(status_code=400, detail=\"Invalid input\")\n    return {\"id\": 1, \"name\": name, \"price\": price}\nINTL:END\n\nPATCH f1098 [target=f1098]\n  INTENT \"add rate limiting to product endpoints\"\n  ADD BEFORE: rate_limit_check(user_id) for get_product and create_product\n  MODIFY: import slowapi dependencies\nEND PATCH f1098", "completion": "INTL:BEGIN\nfrom fastapi import FastAPI, HTTPException, Request\nfrom slowapi import Limiter\nfrom slowapi.util import get_remote_address\nfrom typing import List\n\napp = FastAPI()\nlimiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\n\n@app.get(\"/products/{product_id}\")\n@limiter.limit(\"5/minute\")\nasync def get_product(request: Request, product_id: int):\n    if product_id <= 0:\n        raise HTTPException(status_code=400, detail=\"Invalid product ID\")\n    return {\"product_id\": product_id, \"name\": \"Sample Product\"}\n\n@app.post(\"/products\")\n@limiter.limit(\"3/minute\")\nasync def create_product(request: Request, name: str, price: float):\n    if not name or price < 0:\n        raise HTTPException(status_code=400, detail=\"Invalid input\")\n    return {\"id\": 1, \"name\": name, \"price\": price}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PATCH", "idx": 1098}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_permission_chain [id=f1420]\n  INTENT       \"grant a permission to a user through a sequence of validation and audit steps\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION permission_name.length > 0\n  PRECONDITION requester_role IN (\"admin\", \"manager\")\n  POSTCONDITION result.grant_id IS NOT NULL\n  READS        users_table, permissions_table, roles_table\n  MUTATES      user_permissions_table, audit_log_table\n  OBSERVABLE\n\n  SEQUENCE\n    Step 1: QUERY users_table WHERE id == user_id LIMIT 1\n      -> user = result\n      -> IF user IS NULL THEN FAIL ValidationError(\"user_not_found\")\n    \n    Step 2: QUERY permissions_table WHERE name == permission_name LIMIT 1\n      -> permission = result\n      -> IF permission IS NULL THEN FAIL ValidationError(\"permission_not_found\")\n    \n    Step 3: QUERY roles_table WHERE role_name == requester_role LIMIT 1\n      -> requester_role_record = result\n      -> IF requester_role_record.can_grant_permissions IS FALSE THEN FAIL AuthorizationError(\"insufficient_grant_rights\")\n    \n    Step 4: QUERY user_permissions_table WHERE user_id == user_id AND permission_id == permission.id LIMIT 1\n      -> existing_grant = result\n      -> IF existing_grant IS NOT NULL THEN FAIL ConflictError(\"permission_already_granted\")\n    \n    Step 5: PERSIST user_permissions_table (user_id: user_id, permission_id: permission.id, granted_at: now(), granted_by: requester_id)\n      -> grant_id = result.id\n    \n    Step 6: PERSIST audit_log_table (action: \"GRANT\", user_id: user_id, permission_id: permission.id, requester_id: requester_id, timestamp: now())\n  END SEQUENCE\n\n  RETURN GrantResult(grant_id: grant_id, permission_name: permission_name, user_id: user_id)\nEND FUNCTION grant_permission_chain [id=f1420]", "completion": "# ═══ INTL:BEGIN [id=f1420] grant_permission_chain ═══\nimport logging\nfrom datetime import datetime\nfrom typing import NamedTuple\n\nlogger = logging.getLogger(__name__)\n\nclass GrantResult(NamedTuple):\n    grant_id: str\n    permission_name: str\n    user_id: str\n\nasync def grant_permission_chain(\n    user_id: str,\n    permission_name: str,\n    requester_id: str,\n    requester_role: str\n) -> GrantResult:\n    # Preconditions\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(permission_name) > 0, \"permission_name must not be empty\"\n    assert requester_role in (\"admin\", \"manager\"), \"requester_role must be admin or manager\"\n    \n    # Step 1: Validate user exists\n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise ValidationError(\"user_not_found\")\n    \n    # Step 2: Validate permission exists\n    permission = await db.query(permissions_table).filter(name=permission_name).first()\n    if permission is None:\n        raise ValidationError(\"permission_not_found\")\n    \n    # Step 3: Validate requester has grant rights\n    requester_role_record = await db.query(roles_table).filter(role_name=requester_role).first()\n    if requester_role_record is None or not requester_role_record.can_grant_permissions:\n        raise AuthorizationError(\"insufficient_grant_rights\")\n    \n    # Step 4: Check permission not already granted\n    existing_grant = await db.query(user_permissions_table).filter(\n        user_id=user_id,\n        permission_id=permission.id\n    ).first()\n    if existing_grant is not None:\n        raise ConflictError(\"permission_already_granted\")\n    \n    # Step 5: Grant permission\n    grant_result = await db.insert(\n        user_permissions_table,\n        user_id=user_id,\n        permission_id=permission.id,\n        granted_at=datetime.utcnow(),\n        granted_by=requester_id\n    )\n    grant_id = grant_result.id\n    \n    # Step 6: Log audit event\n    await db.insert(\n        audit_log_table,\n        action=\"GRANT\",\n        user_id=user_id,\n        permission_id=permission.id,\n        requester_id=requester_id,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\n        \"grant_permission_chain: grant_id=%s user_id=%s permission=%s requester=%s\",\n        grant_id, user_id, permission_name, requester_id\n    )\n    \n    result = GrantResult(grant_id=grant_id, permission_name=permission_name, user_id=user_id)\n    assert result.grant_id is not None\n    return result\n# ═══ INTL:END   [id=f1420] grant_permission_chain ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 1420}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_order [id=f1742]\n  INTENT       \"process customer order and reserve inventory with confidence scoring\"\n  PRECONDITION order_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION customer_id IS NOT NULL\n  POSTCONDITION result.status IN (\"confirmed\", \"pending_approval\")\n  POSTCONDITION result.confidence >= 0.75\n  READS        orders_table, inventory_table, customers_table\n  MUTATES      orders_table, inventory_reservations_table\n  OBSERVABLE\n\n  order = QUERY orders_table WHERE id == order_id LIMIT 1\n  IF order IS NULL THEN FAIL OrderError(\"order_not_found\")\n  customer = QUERY customers_table WHERE id == customer_id LIMIT 1\n  IF customer IS NULL THEN FAIL OrderError(\"customer_not_found\")\n  inventory = QUERY inventory_table WHERE product_id == order.product_id LIMIT 1\n  IF inventory.available < quantity THEN FAIL OrderError(\"insufficient_stock\")\n  \n  confidence = 0.0\n  IF customer.credit_score >= 750 THEN confidence += 0.4\n  IF inventory.available >= (quantity * 2) THEN confidence += 0.35\n  IF order.total_amount < 5000 THEN confidence += 0.25\n  \n  status = \"confirmed\"\n  IF confidence < 0.75 THEN status = \"pending_approval\"\n  \n  PERSIST orders_table (id: order_id, status: status, confidence: confidence, processed_at: now())\n  PERSIST inventory_reservations_table (order_id: order_id, product_id: order.product_id, quantity: quantity, reserved_at: now())\n  RETURN OrderResult(order_id: order_id, status: status, confidence: confidence)\nEND FUNCTION process_order [id=f1742]", "completion": "# ═══ INTL:BEGIN [id=f1742] process_order ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def process_order(order_id: str, customer_id: str, quantity: int) -> OrderResult:\n    assert len(order_id) > 0, \"order_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    assert customer_id is not None, \"customer_id must not be null\"\n    \n    order = await db.query(orders_table).filter(id=order_id).first()\n    if order is None:\n        raise OrderError(\"order_not_found\")\n    \n    customer = await db.query(customers_table).filter(id=customer_id).first()\n    if customer is None:\n        raise OrderError(\"customer_not_found\")\n    \n    inventory = await db.query(inventory_table).filter(\n        product_id=order.product_id\n    ).first()\n    if inventory.available < quantity:\n        raise OrderError(\"insufficient_stock\")\n    \n    confidence = 0.0\n    if customer.credit_score >= 750:\n        confidence += 0.4\n    if inventory.available >= (quantity * 2):\n        confidence += 0.35\n    if order.total_amount < 5000:\n        confidence += 0.25\n    \n    status = \"confirmed\" if confidence >= 0.75 else \"pending_approval\"\n    \n    await db.update(\n        orders_table,\n        where={\"id\": order_id},\n        values={\n            \"status\": status,\n            \"confidence\": confidence,\n            \"processed_at\": datetime.utcnow()\n        }\n    )\n    \n    await db.insert(\n        inventory_reservations_table,\n        order_id=order_id,\n        product_id=order.product_id,\n        quantity=quantity,\n        reserved_at=datetime.utcnow()\n    )\n    \n    logger.info(\n        \"process_order: order_id=%s, customer_id=%s, status=%s, confidence=%.2f\",\n        order_id, customer_id, status, confidence\n    )\n    \n    result = OrderResult(order_id=order_id, status=status, confidence=confidence)\n    assert result.status in (\"confirmed\", \"pending_approval\"), \"invalid status\"\n    assert result.confidence >= 0.75 or result.status == \"pending_approval\", \"confidence postcondition\"\n    return result\n# ═══ INTL:END   [id=f1742] process_order ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 1742}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION normalize_user_profile [id=f2432]\n  INTENT       \"normalize and enrich user profile data with standardized fields\"\n  PRECONDITION user.name IS NOT NULL\n  PRECONDITION user.email IS NOT NULL\n  PRECONDITION len(user.name) >= 2\n  POSTCONDITION result.normalized_name IS NOT NULL\n  POSTCONDITION result.email_domain IS NOT NULL\n  READS        users_table\n  MUTATES      user_profiles_table\n  TRANSFORM    user.name -> trim().lower().title_case()\n  TRANSFORM    user.email -> extract_domain()\n  TRANSFORM    user.phone -> format_phone_number() IF user.phone IS NOT NULL\n  OBSERVABLE\n\n  normalized_name = TRANSFORM user.name WITH trim().lower().title_case()\n  email_domain = TRANSFORM user.email WITH extract_domain()\n  phone_formatted = IF user.phone IS NOT NULL THEN TRANSFORM user.phone WITH format_phone_number() ELSE NULL\n  created_at = now()\n  PERSIST user_profiles_table (user_id: user.id, normalized_name: normalized_name, email_domain: email_domain, phone: phone_formatted, created_at: created_at)\n  RETURN UserProfile(normalized_name: normalized_name, email_domain: email_domain, phone: phone_formatted, created_at: created_at)\nEND FUNCTION normalize_user_profile [id=f2432]", "completion": "# ═══ INTL:BEGIN [id=f2432] normalize_user_profile ═══\nimport logging\nfrom datetime import datetime\nimport re\n\nlogger = logging.getLogger(__name__)\n\ndef extract_domain(email: str) -> str:\n    \"\"\"Extract domain from email address.\"\"\"\n    return email.split('@')[1] if '@' in email else \"\"\n\ndef format_phone_number(phone: str) -> str:\n    \"\"\"Format phone number to standard format.\"\"\"\n    digits = re.sub(r'\\D', '', phone)\n    if len(digits) == 10:\n        return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n    elif len(digits) == 11 and digits[0] == '1':\n        return f\"+1 ({digits[1:4]}) {digits[4:7]}-{digits[7:]}\"\n    return phone\n\nasync def normalize_user_profile(user: UserInput) -> UserProfile:\n    assert user.name is not None, \"user name must not be null\"\n    assert user.email is not None, \"user email must not be null\"\n    assert len(user.name) >= 2, \"user name must be at least 2 characters\"\n    \n    normalized_name = user.name.strip().lower().title()\n    email_domain = extract_domain(user.email)\n    phone_formatted = format_phone_number(user.phone) if user.phone is not None else None\n    created_at = datetime.utcnow()\n    \n    await db.insert(\n        user_profiles_table,\n        user_id=user.id,\n        normalized_name=normalized_name,\n        email_domain=email_domain,\n        phone=phone_formatted,\n        created_at=created_at\n    )\n    \n    logger.info(\"normalize_user_profile: user_id=%s, normalized_name=%s, email_domain=%s\", \n                user.id, normalized_name, email_domain)\n    \n    result = UserProfile(\n        normalized_name=normalized_name,\n        email_domain=email_domain,\n        phone=phone_formatted,\n        created_at=created_at\n    )\n    assert result.normalized_name is not None\n    assert result.email_domain is not None\n    return result\n# ═══ INTL:END   [id=f2432] normalize_user_profile ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 2432}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_inventory [id=f2754]\n  INTENT       \"replenish stock for a product and log the transaction\"\n  PRECONDITION product_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION warehouse_id.length > 0\n  POSTCONDITION result.stock_level >= 0\n  READS        products_table, warehouses_table\n  MUTATES      inventory_table, audit_log_table\n  OBSERVABLE\n\n  warehouse = QUERY warehouses_table WHERE id == warehouse_id LIMIT 1\n  FALLBACK warehouse = DEFAULT_WAREHOUSE()\n  \n  product = QUERY products_table WHERE id == product_id LIMIT 1\n  IF product IS NULL THEN FAIL ProductError(\"product_not_found\")\n  \n  current_stock = QUERY inventory_table WHERE product_id == product_id AND warehouse_id == warehouse.id LIMIT 1\n  FALLBACK current_stock = InventoryRecord(product_id: product_id, warehouse_id: warehouse.id, quantity: 0)\n  \n  new_stock = current_stock.quantity + quantity\n  PERSIST inventory_table (product_id: product_id, warehouse_id: warehouse.id, quantity: new_stock, updated_at: now())\n  PERSIST audit_log_table (product_id: product_id, action: \"restock\", quantity_delta: quantity, warehouse_id: warehouse.id, timestamp: now())\n  \n  RETURN RestockResult(stock_level: new_stock, warehouse_id: warehouse.id)\nEND FUNCTION restock_inventory [id=f2754]", "completion": "# ═══ INTL:BEGIN [id=f2754] restock_inventory ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_inventory(product_id: str, quantity: int, warehouse_id: str) -> RestockResult:\n    assert len(product_id) > 0, \"product_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than zero\"\n    assert len(warehouse_id) > 0, \"warehouse_id must not be empty\"\n    \n    warehouse = await db.query(warehouses_table).filter(id=warehouse_id).first()\n    if warehouse is None:\n        warehouse = DEFAULT_WAREHOUSE()\n    \n    product = await db.query(products_table).filter(id=product_id).first()\n    if product is None:\n        raise ProductError(\"product_not_found\")\n    \n    current_stock = await db.query(inventory_table).filter(\n        product_id=product_id, warehouse_id=warehouse.id\n    ).first()\n    if current_stock is None:\n        current_stock = InventoryRecord(\n            product_id=product_id,\n            warehouse_id=warehouse.id,\n            quantity=0\n        )\n    \n    new_stock = current_stock.quantity + quantity\n    \n    await db.update(\n        inventory_table,\n        filter_dict={\"product_id\": product_id, \"warehouse_id\": warehouse.id},\n        update_dict={\n            \"quantity\": new_stock,\n            \"updated_at\": datetime.utcnow()\n        }\n    )\n    \n    await db.insert(\n        audit_log_table,\n        product_id=product_id,\n        action=\"restock\",\n        quantity_delta=quantity,\n        warehouse_id=warehouse.id,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"restock_inventory: product=%s warehouse=%s quantity_delta=%d new_stock=%d\",\n                product_id, warehouse.id, quantity, new_stock)\n    \n    result = RestockResult(stock_level=new_stock, warehouse_id=warehouse.id)\n    assert result.stock_level >= 0, \"stock_level must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f2754] restock_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 2754}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/search\")\nasync def search_products(query: str, db: Session = Depends(get_db)):\n    results = db.query(Product).filter(Product.name.contains(query)).all()\n    return {\"results\": results, \"count\": len(results)}\nINTL:END\n\nPATCH f3122 [target=f3122]\n  INTENT \"wrap search query in database transaction with rollback on error\"\n  ADD BEFORE: db.begin()\n  ADD AFTER: db.commit()\n  ADD EXCEPT: db.rollback()\nEND PATCH f3122", "completion": "INTL:BEGIN\n@router.post(\"/search\")\nasync def search_products(query: str, db: Session = Depends(get_db)):\n    try:\n        db.begin()\n        results = db.query(Product).filter(Product.name.contains(query)).all()\n        db.commit()\n        return {\"results\": results, \"count\": len(results)}\n    except Exception:\n        db.rollback()\n        raise\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 3122}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\napp = FastAPI()\nengine = create_engine(\"sqlite:///analytics.db\")\nSessionLocal = sessionmaker(bind=engine)\n\n@app.get(\"/metrics/{metric_id}\")\ndef get_metric(metric_id: int):\n    session = SessionLocal()\n    result = session.query(Metric).filter(Metric.id == metric_id).first()\n    session.close()\n    return result\n\n@app.post(\"/metrics\")\ndef create_metric(data: dict):\n    session = SessionLocal()\n    metric = Metric(**data)\n    session.add(metric)\n    session.commit()\n    session.close()\n    return metric\nINTL:END\n\nPATCH f0041 [target=f0041]\n  INTENT \"add database lock for concurrent analytics writes\"\n  ADD BEFORE: session.add(metric)\n  LOCK: with_for_update() on query to prevent race conditions\nEND PATCH f0041", "completion": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\napp = FastAPI()\nengine = create_engine(\"sqlite:///analytics.db\")\nSessionLocal = sessionmaker(bind=engine)\n\n@app.get(\"/metrics/{metric_id}\")\ndef get_metric(metric_id: int):\n    session = SessionLocal()\n    result = session.query(Metric).filter(Metric.id == metric_id).first()\n    session.close()\n    return result\n\n@app.post(\"/metrics\")\ndef create_metric(data: dict):\n    session = SessionLocal()\n    metric = Metric(**data)\n    with session.begin_nested():\n        session.query(Metric).with_for_update().filter(Metric.id == metric_id).first()\n        session.add(metric)\n    session.commit()\n    session.close()\n    return metric\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "LOCK", "idx": 41}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/products/summary\")\nasync def get_product_summary(category: str = None):\n    products = await db.query(Product).filter_by(category=category).all()\n    total_price = sum(p.price for p in products)\n    total_count = len(products)\n    return {\n        \"category\": category,\n        \"total_count\": total_count,\n        \"total_price\": total_price,\n        \"products\": products\n    }\nINTL:END\n\nPATCH f0409 [target=f0409]\n  INTENT \"add inventory aggregation to product summary response\"\n  ADD BEFORE: return statement\n  AGGREGATE inventory_status: group products by stock level (in_stock, low_stock, out_of_stock)\nEND PATCH f0409", "completion": "INTL:BEGIN\n@router.get(\"/products/summary\")\nasync def get_product_summary(category: str = None):\n    products = await db.query(Product).filter_by(category=category).all()\n    total_price = sum(p.price for p in products)\n    total_count = len(products)\n    \n    inventory_status = {\n        \"in_stock\": len([p for p in products if p.stock > 10]),\n        \"low_stock\": len([p for p in products if 0 < p.stock <= 10]),\n        \"out_of_stock\": len([p for p in products if p.stock == 0])\n    }\n    \n    return {\n        \"category\": category,\n        \"total_count\": total_count,\n        \"total_price\": total_price,\n        \"inventory_status\": inventory_status,\n        \"products\": products\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "AGGREGATE", "idx": 409}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION activate_user_workflow [id=f1099]\n  INTENT       \"activate a user account through email verification and profile completion sequence\"\n  PRECONDITION user_id > 0\n  PRECONDITION verification_code.length == 6\n  PRECONDITION full_name.length > 0\n  POSTCONDITION result.is_active == TRUE\n  READS        users_table\n  READS        verification_codes_table\n  MUTATES      users_table\n  MUTATES      verification_codes_table\n  OBSERVABLE\n\n  SEQUENCE\n    code_record = QUERY verification_codes_table WHERE user_id == user_id AND code == verification_code LIMIT 1\n    IF code_record IS NULL THEN FAIL ValidationError(\"invalid_verification_code\")\n    IF code_record.expires_at < now() THEN FAIL ValidationError(\"code_expired\")\n    user = QUERY users_table WHERE id == user_id LIMIT 1\n    IF user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n    IF user.is_active == TRUE THEN FAIL ConflictError(\"user_already_active\")\n    PERSIST users_table (id: user_id, full_name: full_name, is_active: TRUE, activated_at: now())\n    DELETE verification_codes_table WHERE user_id == user_id\n  END SEQUENCE\n\n  RETURN UserActivated(user_id: user_id, is_active: TRUE, activated_at: now())\nEND FUNCTION activate_user_workflow [id=f1099]", "completion": "# ═══ INTL:BEGIN [id=f1099] activate_user_workflow ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def activate_user_workflow(user_id: int, verification_code: str, full_name: str) -> UserActivated:\n    assert user_id > 0, \"user_id must be positive\"\n    assert len(verification_code) == 6, \"verification_code must be exactly 6 characters\"\n    assert len(full_name) > 0, \"full_name must not be empty\"\n    \n    code_record = await db.query(verification_codes_table).filter(\n        user_id=user_id, code=verification_code\n    ).first()\n    if code_record is None:\n        raise ValidationError(\"invalid_verification_code\")\n    \n    if code_record.expires_at < datetime.utcnow():\n        raise ValidationError(\"code_expired\")\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    if user.is_active is True:\n        raise ConflictError(\"user_already_active\")\n    \n    now = datetime.utcnow()\n    await db.update(users_table, where={\"id\": user_id},\n                    values={\"full_name\": full_name, \"is_active\": True, \"activated_at\": now})\n    \n    await db.delete(verification_codes_table, where={\"user_id\": user_id})\n    \n    logger.info(\"activate_user_workflow: user_id=%d activated with full_name=%s\", user_id, full_name)\n    \n    result = UserActivated(user_id=user_id, is_active=True, activated_at=now)\n    assert result.is_active is True\n    return result\n# ═══ INTL:END   [id=f1099] activate_user_workflow ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 1099}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION compute_user_cohort_metrics [id=f0731]\n  INTENT       \"aggregate cohort analytics and persist metrics within SLA\"\n  PRECONDITION cohort_id.length > 0\n  PRECONDITION time_window_days > 0\n  PRECONDITION time_window_days <= 365\n  TIMEOUT      30s\n  POSTCONDITION result.metrics_id IS NOT NULL\n  POSTCONDITION result.computed_at IS NOT NULL\n  READS        events_table\n  READS        users_table\n  MUTATES      cohort_metrics_table\n  OBSERVABLE\n\n  IF cohort_id IS EMPTY THEN FAIL ValidationError(\"cohort_id_required\")\n  events = QUERY events_table WHERE cohort_id == cohort_id AND created_at >= now()-time_window_days*days TIMEOUT 15s\n  IF events IS NULL THEN FAIL QueryError(\"events_unavailable\")\n  retention = COUNT(events WHERE event_type == \"retention\") / COUNT(events)\n  engagement = SUM(events.engagement_score) / COUNT(events)\n  metrics_id = generate_uuid()\n  PERSIST cohort_metrics_table (metrics_id: metrics_id, cohort_id: cohort_id, retention: retention, engagement: engagement, computed_at: now())\n  RETURN CohortMetrics(metrics_id: metrics_id, retention: retention, engagement: engagement, computed_at: now())\nEND FUNCTION compute_user_cohort_metrics [id=f0731]", "completion": "# ═══ INTL:BEGIN [id=f0731] compute_user_cohort_metrics ═══\nimport logging\nimport asyncio\nfrom datetime import datetime, timedelta\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\nasync def compute_user_cohort_metrics(cohort_id: str, time_window_days: int) -> CohortMetrics:\n    assert len(cohort_id) > 0, \"cohort_id must not be empty\"\n    assert time_window_days > 0, \"time_window_days must be positive\"\n    assert time_window_days <= 365, \"time_window_days must not exceed 365\"\n    \n    if not cohort_id:\n        raise ValidationError(\"cohort_id_required\")\n    \n    try:\n        events = await asyncio.wait_for(\n            db.query(events_table)\n              .filter(cohort_id=cohort_id, created_at__gte=datetime.utcnow() - timedelta(days=time_window_days))\n              .all(),\n            timeout=15.0\n        )\n    except asyncio.TimeoutError:\n        raise QueryError(\"events_unavailable\")\n    \n    if events is None or len(events) == 0:\n        raise QueryError(\"events_unavailable\")\n    \n    retention_count = sum(1 for e in events if e.event_type == \"retention\")\n    retention = retention_count / len(events) if len(events) > 0 else 0.0\n    engagement = sum(e.engagement_score for e in events) / len(events) if len(events) > 0 else 0.0\n    \n    metrics_id = str(uuid.uuid4())\n    computed_at = datetime.utcnow()\n    \n    await db.insert(\n        cohort_metrics_table,\n        metrics_id=metrics_id,\n        cohort_id=cohort_id,\n        retention=retention,\n        engagement=engagement,\n        computed_at=computed_at\n    )\n    \n    logger.info(\"compute_user_cohort_metrics: cohort_id=%s, metrics_id=%s, retention=%.2f, engagement=%.2f\",\n                cohort_id, metrics_id, retention, engagement)\n    \n    result = CohortMetrics(\n        metrics_id=metrics_id,\n        retention=retention,\n        engagement=engagement,\n        computed_at=computed_at\n    )\n    \n    assert result.metrics_id is not None\n    assert result.computed_at is not None\n    return result\n# ═══ INTL:END   [id=f0731] compute_user_cohort_metrics ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TIMEOUT", "idx": 731}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/reviews\")\nasync def get_reviews(skip: int = 0, limit: int = 10):\n    reviews = db.query(Review).offset(skip).limit(limit).all()\n    return reviews\nINTL:END\n\nPATCH f1743 [target=f1743]\n  INTENT \"add filtering by rating to the review query\"\n  ADD PARAMETER: rating: int = None\n  MODIFY QUERY: filter by rating if provided\nEND PATCH f1743", "completion": "INTL:BEGIN\n@app.get(\"/reviews\")\nasync def get_reviews(skip: int = 0, limit: int = 10, rating: int = None):\n    query = db.query(Review)\n    if rating is not None:\n        query = query.filter(Review.rating == rating)\n    reviews = query.offset(skip).limit(limit).all()\n    return reviews\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "QUERY", "idx": 1743}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_bulk_permissions [id=f1421]\n  INTENT       \"grant multiple permissions to a user in batch\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION permissions_list.length > 0\n  PRECONDITION permissions_list.length <= 100\n  POSTCONDITION result.granted_count == permissions_list.length\n  READS        users_table\n  READS        permissions_catalog\n  MUTATES      user_permissions_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n  \n  granted_count = 0\n  LOOP permission IN permissions_list DO\n    perm_def = QUERY permissions_catalog WHERE name == permission LIMIT 1\n    IF perm_def IS NULL THEN CONTINUE\n    \n    existing = QUERY user_permissions_table WHERE user_id == user_id AND permission == permission LIMIT 1\n    IF existing IS NOT NULL THEN CONTINUE\n    \n    PERSIST user_permissions_table (user_id: user_id, permission: permission, granted_at: now())\n    granted_count = granted_count + 1\n  END LOOP\n  \n  RETURN GrantResult(granted_count: granted_count, user_id: user_id)\nEND FUNCTION grant_bulk_permissions [id=f1421]", "completion": "# ═══ INTL:BEGIN [id=f1421] grant_bulk_permissions ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def grant_bulk_permissions(user_id: str, permissions_list: List[str]) -> GrantResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(permissions_list) > 0, \"permissions_list must not be empty\"\n    assert len(permissions_list) <= 100, \"permissions_list must not exceed 100 items\"\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    granted_count = 0\n    for permission in permissions_list:\n        perm_def = await db.query(permissions_catalog).filter(name=permission).first()\n        if perm_def is None:\n            continue\n        \n        existing = await db.query(user_permissions_table).filter(\n            user_id=user_id, permission=permission\n        ).first()\n        if existing is not None:\n            continue\n        \n        await db.insert(user_permissions_table, \n                       user_id=user_id, \n                       permission=permission,\n                       granted_at=datetime.utcnow())\n        granted_count += 1\n    \n    logger.info(\"grant_bulk_permissions: user=%s, granted=%d, total_requested=%d\", \n                user_id, granted_count, len(permissions_list))\n    \n    result = GrantResult(granted_count=granted_count, user_id=user_id)\n    assert result.granted_count == granted_count\n    return result\n# ═══ INTL:END   [id=f1421] grant_bulk_permissions ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 1421}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/analytics/events\")\nasync def get_events(user_id: str, limit: int = 100):\n    events = db.query(Event).filter(Event.user_id == user_id).limit(limit).all()\n    return {\n        \"user_id\": user_id,\n        \"event_count\": len(events),\n        \"events\": [\n            {\n                \"id\": e.id,\n                \"timestamp\": e.timestamp,\n                \"event_type\": e.event_type,\n                \"data\": e.data\n            }\n            for e in events\n        ]\n    }\nINTL:END\n\nPATCH f2111 [target=f2111]\n  INTENT \"transform raw event data to include calculated metrics\"\n  TRANSFORM events INTO enriched_events:\n    ADD FIELD: duration_ms = e.duration if hasattr(e, 'duration') else 0\n    ADD FIELD: severity_level = classify_severity(e.event_type)\n    REMOVE FIELD: data\nEND PATCH f2111", "completion": "INTL:BEGIN\n@app.get(\"/analytics/events\")\nasync def get_events(user_id: str, limit: int = 100):\n    events = db.query(Event).filter(Event.user_id == user_id).limit(limit).all()\n    enriched_events = [\n        {\n            \"id\": e.id,\n            \"timestamp\": e.timestamp,\n            \"event_type\": e.event_type,\n            \"duration_ms\": e.duration if hasattr(e, 'duration') else 0,\n            \"severity_level\": classify_severity(e.event_type)\n        }\n        for e in events\n    ]\n    return {\n        \"user_id\": user_id,\n        \"event_count\": len(enriched_events),\n        \"events\": enriched_events\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 2111}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/coupons/{coupon_id}\")\nasync def get_coupon(coupon_id: str, db: Session = Depends(get_db)):\n    coupon = db.query(Coupon).filter(Coupon.id == coupon_id).first()\n    if not coupon:\n        raise HTTPException(status_code=404, detail=\"Coupon not found\")\n    return coupon\nINTL:END\n\nPATCH f2755 [target=f2755]\n  INTENT \"add fallback response when coupon service is unavailable\"\n  ADD FALLBACK: return {\"id\": coupon_id, \"status\": \"unavailable\", \"discount\": 0}\nEND PATCH f2755", "completion": "INTL:BEGIN\n@router.get(\"/coupons/{coupon_id}\")\nasync def get_coupon(coupon_id: str, db: Session = Depends(get_db)):\n    try:\n        coupon = db.query(Coupon).filter(Coupon.id == coupon_id).first()\n        if not coupon:\n            raise HTTPException(status_code=404, detail=\"Coupon not found\")\n        return coupon\n    except Exception:\n        return {\"id\": coupon_id, \"status\": \"unavailable\", \"discount\": 0}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 2755}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: int):\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    return review\nINTL:END\n\nPATCH f3123 [target=f3123]\n  INTENT \"add response timestamp to review return\"\n  MODIFY RETURN: include created_at field in response\nEND PATCH f3123", "completion": "INTL:BEGIN\n@app.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: int):\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    return {**review.__dict__, \"created_at\": review.created_at}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "RETURN", "idx": 3123}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return product\nINTL:END\n\nPATCH f0042 [target=f0042]\n  INTENT \"emit structured product response with metadata\"\n  EMIT SCHEMA: ProductResponse\n  ADD BEFORE return: response_metadata = {\"timestamp\": datetime.now(), \"version\": \"1.0\"}\n  MODIFY return: return {**product.dict(), \"meta\": response_metadata}\nEND PATCH f0042", "completion": "INTL:BEGIN\n@router.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    response_metadata = {\"timestamp\": datetime.now(), \"version\": \"1.0\"}\n    return {**product.dict(), \"meta\": response_metadata}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "EMIT", "idx": 42}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_api_key [id=f0410]\n  INTENT       \"revoke an active API key and prevent further use\"\n  PRECONDITION key_id.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.revoked_at IS NOT NULL\n  READS        api_keys_table\n  MUTATES      api_keys_table\n  LOCK         api_keys_table FOR UPDATE\n  OBSERVABLE\n\n  LOCK api_keys_table FOR UPDATE\n  key_record = QUERY api_keys_table WHERE id == key_id LIMIT 1\n  IF key_record IS NULL THEN FAIL NotFoundError(\"key_not_found\")\n  IF key_record.user_id != user_id THEN FAIL PermissionError(\"unauthorized_revocation\")\n  IF key_record.revoked_at IS NOT NULL THEN FAIL ConflictError(\"key_already_revoked\")\n  now_timestamp = now()\n  UPDATE api_keys_table SET revoked_at = now_timestamp WHERE id == key_id\n  RETURN ApiKeyRevocationResult(key_id: key_id, revoked_at: now_timestamp)\nEND FUNCTION revoke_api_key [id=f0410]", "completion": "# ═══ INTL:BEGIN [id=f0410] revoke_api_key ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_api_key(key_id: str, user_id: int) -> ApiKeyRevocationResult:\n    assert len(key_id) > 0, \"key_id must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    \n    async with db.transaction():\n        async with db.lock(api_keys_table, mode=\"FOR UPDATE\"):\n            key_record = await db.query(api_keys_table).filter(id=key_id).first()\n            if key_record is None:\n                raise NotFoundError(\"key_not_found\")\n            if key_record.user_id != user_id:\n                raise PermissionError(\"unauthorized_revocation\")\n            if key_record.revoked_at is not None:\n                raise ConflictError(\"key_already_revoked\")\n            \n            now_timestamp = datetime.utcnow()\n            await db.update(api_keys_table).filter(id=key_id).set(revoked_at=now_timestamp)\n            logger.info(\"revoke_api_key: key_id=%s user_id=%s revoked_at=%s\", \n                       key_id, user_id, now_timestamp)\n            \n            result = ApiKeyRevocationResult(key_id=key_id, revoked_at=now_timestamp)\n            assert result.revoked_at is not None\n            return result\n# ═══ INTL:END   [id=f0410] revoke_api_key ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOCK", "idx": 410}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION rotate_api_key [id=f1100]\n  INTENT       \"rotate an existing API key and emit audit event\"\n  PRECONDITION key_id.length > 0\n  PRECONDITION user_id > 0\n  PRECONDITION reason.length > 0\n  POSTCONDITION result.new_key IS NOT NULL\n  POSTCONDITION result.old_key_revoked IS TRUE\n  READS        api_keys_table\n  MUTATES      api_keys_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n  \n  existing_key = QUERY api_keys_table WHERE id == key_id AND owner_id == user_id LIMIT 1\n  IF existing_key IS NULL THEN FAIL KeyError(\"key_not_found\")\n  IF existing_key.revoked IS TRUE THEN FAIL KeyError(\"key_already_revoked\")\n  \n  new_key_value = generate_secure_key()\n  new_key_hash = hash_key(new_key_value)\n  \n  PERSIST api_keys_table (id: key_id, hash: new_key_hash, rotated_at: now(), revoked: FALSE)\n  PERSIST api_keys_table (owner_id: user_id, revoked: TRUE, revoked_at: now())\n  \n  EMIT AuditEvent(event_type: \"key_rotation\", user_id: user_id, key_id: key_id, \n                  reason: reason, timestamp: now())\n  \n  RETURN KeyRotationResult(new_key: new_key_value, old_key_revoked: TRUE)\nEND FUNCTION rotate_api_key [id=f1100]", "completion": "# ═══ INTL:BEGIN [id=f1100] rotate_api_key ═══\nimport logging\nfrom datetime import datetime\nimport secrets\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def rotate_api_key(key_id: str, user_id: int, reason: str) -> KeyRotationResult:\n    assert len(key_id) > 0, \"key_id must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    assert len(reason) > 0, \"reason must not be empty\"\n    \n    existing_key = await db.query(api_keys_table).filter(\n        id=key_id, owner_id=user_id\n    ).first()\n    \n    if existing_key is None:\n        raise KeyError(\"key_not_found\")\n    if existing_key.revoked is True:\n        raise KeyError(\"key_already_revoked\")\n    \n    new_key_value = secrets.token_urlsafe(32)\n    new_key_hash = hashlib.sha256(new_key_value.encode()).hexdigest()\n    \n    await db.update(api_keys_table, \n                   where={\"id\": key_id},\n                   hash=new_key_hash,\n                   rotated_at=datetime.utcnow(),\n                   revoked=False)\n    \n    await db.update(api_keys_table,\n                   where={\"owner_id\": user_id, \"id\": key_id},\n                   revoked=True,\n                   revoked_at=datetime.utcnow())\n    \n    await db.insert(audit_log_table,\n                   event_type=\"key_rotation\",\n                   user_id=user_id,\n                   key_id=key_id,\n                   reason=reason,\n                   timestamp=datetime.utcnow())\n    \n    logger.info(\"rotate_api_key: user_id=%d key_id=%s reason=%s\", user_id, key_id, reason)\n    \n    result = KeyRotationResult(new_key=new_key_value, old_key_revoked=True)\n    assert result.new_key is not None\n    assert result.old_key_revoked is True\n    return result\n# ═══ INTL:END   [id=f1100] rotate_api_key ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "EMIT", "idx": 1100}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_shipments [id=f1744]\n  INTENT       \"process pending shipments and update tracking status\"\n  PRECONDITION shipments IS NOT NULL\n  PRECONDITION max_batch_size > 0\n  POSTCONDITION processed_count >= 0\n  READS        shipments_table\n  MUTATES      shipments_table\n  MUTATES      tracking_history_table\n  OBSERVABLE\n\n  processed_count = 0\n  LOOP shipment IN QUERY shipments_table WHERE status == \"pending\" LIMIT max_batch_size\n    IF shipment.carrier_id IS NULL THEN CONTINUE\n    tracking_info = fetch_carrier_tracking(shipment.carrier_id, shipment.tracking_number)\n    IF tracking_info.current_status != shipment.status THEN\n      UPDATE shipments_table SET status = tracking_info.current_status WHERE id == shipment.id\n      PERSIST tracking_history_table (shipment_id: shipment.id, old_status: shipment.status, new_status: tracking_info.current_status, updated_at: now())\n      processed_count = processed_count + 1\n    END IF\n  END LOOP\n  RETURN ShipmentResult(processed: processed_count)\nEND FUNCTION process_shipments [id=f1744]", "completion": "# ═══ INTL:BEGIN [id=f1744] process_shipments ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def process_shipments(shipments: List[dict], max_batch_size: int) -> ShipmentResult:\n    assert shipments is not None, \"shipments must not be null\"\n    assert max_batch_size > 0, \"max_batch_size must be greater than 0\"\n    \n    processed_count = 0\n    pending_shipments = await db.query(shipments_table).filter(\n        status=\"pending\"\n    ).limit(max_batch_size).all()\n    \n    for shipment in pending_shipments:\n        if shipment.carrier_id is None:\n            continue\n        \n        tracking_info = await fetch_carrier_tracking(\n            shipment.carrier_id,\n            shipment.tracking_number\n        )\n        \n        if tracking_info.current_status != shipment.status:\n            old_status = shipment.status\n            new_status = tracking_info.current_status\n            \n            await db.update(\n                shipments_table,\n                where={\"id\": shipment.id},\n                values={\"status\": new_status}\n            )\n            \n            await db.insert(\n                tracking_history_table,\n                shipment_id=shipment.id,\n                old_status=old_status,\n                new_status=new_status,\n                updated_at=datetime.utcnow()\n            )\n            \n            processed_count += 1\n            logger.info(\n                \"process_shipments: shipment_id=%s status_changed=%s->%s\",\n                shipment.id,\n                old_status,\n                new_status\n            )\n    \n    result = ShipmentResult(processed=processed_count)\n    assert result.processed >= 0, \"processed_count must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f1744] process_shipments ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 1744}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION update_user_profile [id=f2434]\n  INTENT       \"apply partial updates to user profile and log the change\"\n  PRECONDITION user_id > 0\n  PRECONDITION updates IS NOT NULL\n  PRECONDITION updates.display_name.length <= 255\n  POSTCONDITION result.updated_at IS NOT NULL\n  READS        users_table\n  MUTATES      users_table audit_log_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n  PATCH user WITH updates\n  PERSIST users_table user\n  PERSIST audit_log_table (user_id: user_id, action: \"profile_update\", changes: updates, timestamp: now())\n  RETURN UserProfile(id: user.id, display_name: user.display_name, email: user.email, updated_at: user.updated_at)\nEND FUNCTION update_user_profile [id=f2434]", "completion": "# ═══ INTL:BEGIN [id=f2434] update_user_profile ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def update_user_profile(user_id: int, updates: dict) -> UserProfile:\n    assert user_id > 0, \"user_id must be positive\"\n    assert updates is not None, \"updates must not be null\"\n    assert updates.get(\"display_name\") is None or len(updates[\"display_name\"]) <= 255, \"display_name must not exceed 255 chars\"\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    user.update(updates)\n    user.updated_at = datetime.utcnow()\n    await db.update(users_table, user)\n    \n    await db.insert(audit_log_table, user_id=user_id, action=\"profile_update\", \n                    changes=updates, timestamp=datetime.utcnow())\n    \n    logger.info(\"update_user_profile: user_id=%d, changes=%s\", user_id, updates)\n    \n    result = UserProfile(id=user.id, display_name=user.display_name, \n                        email=user.email, updated_at=user.updated_at)\n    assert result.updated_at is not None\n    return result\n# ═══ INTL:END   [id=f2434] update_user_profile ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PATCH", "idx": 2434}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    contents = await file.read()\n    with open(file.filename, \"wb\") as f:\n        f.write(contents)\n    return {\"filename\": file.filename}\nINTL:END\n\nPATCH f2756 [target=f2756]\n  INTENT \"validate file sequence: check mime type before read, then verify size after read, then write to disk\"\n  ADD BEFORE: contents = await file.read() | validate_mimetype(file.content_type)\n  ADD AFTER: contents = await file.read() | verify_size(contents, MAX_SIZE)\n  ADD BEFORE: f.write(contents) | sanitize_filename(file.filename)\nEND PATCH f2756", "completion": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    validate_mimetype(file.content_type)\n    contents = await file.read()\n    verify_size(contents, MAX_SIZE)\n    with open(sanitize_filename(file.filename), \"wb\") as f:\n        f.write(contents)\n    return {\"filename\": file.filename}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 2756}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION send_notification [id=f3124]\n  INTENT       \"deliver notification to user and track delivery status\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION message.length > 0\n  PRECONDITION message.length <= 500\n  PRECONDITION recipient_email IS NOT NULL\n  POSTCONDITION result.notification_id IS NOT NULL\n  POSTCONDITION result.delivered IS TRUE\n  READS        users_table\n  MUTATES      notifications_table\n  MUTATES      delivery_log_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE user_id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL NotFoundError(\"user_does_not_exist\")\n  notification_id = generate_uuid()\n  PERSIST notifications_table (id: notification_id, user_id: user_id, message: message, created_at: now())\n  PERSIST delivery_log_table (notification_id: notification_id, recipient: recipient_email, status: \"sent\", sent_at: now())\n  RETURN NotificationResult(notification_id: notification_id, delivered: TRUE)\nEND FUNCTION send_notification [id=f3124]", "completion": "# ═══ INTL:BEGIN [id=f3124] send_notification ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\n\nlogger = logging.getLogger(__name__)\n\nasync def send_notification(user_id: str, message: str, recipient_email: str) -> NotificationResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(message) > 0, \"message must not be empty\"\n    assert len(message) <= 500, \"message must not exceed 500 characters\"\n    assert recipient_email is not None, \"recipient_email must not be null\"\n    \n    user = await db.query(users_table).filter(user_id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_does_not_exist\")\n    \n    notification_id = str(uuid4())\n    await db.insert(notifications_table, \n                   id=notification_id, \n                   user_id=user_id, \n                   message=message, \n                   created_at=datetime.utcnow())\n    \n    await db.insert(delivery_log_table,\n                   notification_id=notification_id,\n                   recipient=recipient_email,\n                   status=\"sent\",\n                   sent_at=datetime.utcnow())\n    \n    logger.info(\"send_notification: notification_id=%s, user_id=%s, recipient=%s\", \n                notification_id, user_id, recipient_email)\n    \n    result = NotificationResult(notification_id=notification_id, delivered=True)\n    assert result.notification_id is not None\n    assert result.delivered is True\n    return result\n# ═══ INTL:END   [id=f3124] send_notification ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 3124}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/search\")\nasync def search(q: str, limit: int = 10):\n    results = db.query(q)\n    return {\"results\": results[:limit]}\nINTL:END\n\nPATCH f0043 [target=f0043]\n  INTENT \"add cache retrieval before database query\"\n  ADD BEFORE: cached_result = cache.get(cache_key)\n  ADD AFTER: if cached_result: return {\"results\": cached_result}\nEND PATCH f0043", "completion": "INTL:BEGIN\n@router.get(\"/search\")\nasync def search(q: str, limit: int = 10):\n    cache_key = f\"search:{q}:{limit}\"\n    cached_result = cache.get(cache_key)\n    if cached_result:\n        return {\"results\": cached_result}\n    results = db.query(q)\n    return {\"results\": results[:limit]}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CACHE GET", "idx": 43}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION list_role_permissions [id=f0733]\n  INTENT       \"retrieve paginated list of permissions for a given role with filtering\"\n  PRECONDITION role_id > 0\n  PRECONDITION page_size > 0 AND page_size <= 100\n  PRECONDITION page_number >= 1\n  POSTCONDITION result.items IS NOT NULL\n  POSTCONDITION result.total_count >= 0\n  READS        roles_table, permissions_table, role_permissions_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n  \n  role = QUERY roles_table WHERE id == role_id LIMIT 1\n  IF role IS NULL THEN FAIL PermissionError(\"role_not_found\")\n  \n  offset = (page_number - 1) * page_size\n  perms = PAGINATE role_permissions_table \n    WHERE role_id == role_id \n    JOIN permissions_table ON role_permissions_table.permission_id == permissions_table.id\n    ORDER BY permissions_table.name ASC\n    LIMIT page_size OFFSET offset\n  \n  total = COUNT role_permissions_table WHERE role_id == role_id\n  \n  PERSIST audit_log_table (action: \"list_permissions\", role_id: role_id, timestamp: now(), user_id: context.user_id)\n  \n  RETURN PaginatedPermissions(items: perms, total_count: total, page: page_number, page_size: page_size)\nEND FUNCTION list_role_permissions [id=f0733]", "completion": "# ═══ INTL:BEGIN [id=f0733] list_role_permissions ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def list_role_permissions(\n    role_id: int,\n    page_number: int,\n    page_size: int,\n    context: RequestContext\n) -> PaginatedPermissions:\n    assert role_id > 0, \"role_id must be positive\"\n    assert page_size > 0 and page_size <= 100, \"page_size must be between 1 and 100\"\n    assert page_number >= 1, \"page_number must be at least 1\"\n    \n    role = await db.query(roles_table).filter(id=role_id).first()\n    if role is None:\n        raise PermissionError(\"role_not_found\")\n    \n    offset = (page_number - 1) * page_size\n    \n    perms = await db.query(role_permissions_table).filter(\n        role_id=role_id\n    ).join(\n        permissions_table,\n        role_permissions_table.permission_id == permissions_table.id\n    ).order_by(\n        permissions_table.name\n    ).limit(page_size).offset(offset).all()\n    \n    total = await db.query(role_permissions_table).filter(\n        role_id=role_id\n    ).count()\n    \n    await db.insert(\n        audit_log_table,\n        action=\"list_permissions\",\n        role_id=role_id,\n        timestamp=datetime.utcnow(),\n        user_id=context.user_id\n    )\n    \n    logger.info(\"list_role_permissions: role_id=%d, page=%d, page_size=%d, total=%d\",\n                role_id, page_number, page_size, total)\n    \n    result = PaginatedPermissions(\n        items=perms,\n        total_count=total,\n        page=page_number,\n        page_size=page_size\n    )\n    assert result.items is not None, \"items must not be null\"\n    assert result.total_count >= 0, \"total_count must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f0733] list_role_permissions ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PAGINATE", "idx": 733}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/reports/{report_id}\")\nasync def get_report(report_id: int, db: Session = Depends(get_db)):\n    report = db.query(Report).filter(Report.id == report_id).first()\n    if not report:\n        raise HTTPException(status_code=404, detail=\"Report not found\")\n    return report\nINTL:END\n\nPATCH f1423 [target=f1423]\n  INTENT \"add validation and logging sequence to report retrieval\"\n  ADD BEFORE: validate_report_access(report_id)\n  ADD AFTER: logger.info(f\"Report {report_id} retrieved by user\")\nEND PATCH f1423", "completion": "INTL:BEGIN\n@app.get(\"/reports/{report_id}\")\nasync def get_report(report_id: int, db: Session = Depends(get_db)):\n    validate_report_access(report_id)\n    report = db.query(Report).filter(Report.id == report_id).first()\n    if not report:\n        raise HTTPException(status_code=404, detail=\"Report not found\")\n    logger.info(f\"Report {report_id} retrieved by user\")\n    return report\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 1423}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    new_review = Review(\n        user_id=review.user_id,\n        product_id=review.product_id,\n        rating=review.rating,\n        text=review.text\n    )\n    db.add(new_review)\n    db.commit()\n    return {\"id\": new_review.id, \"status\": \"created\"}\nINTL:END\n\nPATCH f1101 [target=f1101]\n  INTENT \"add automatic transaction rollback on database persistence errors\"\n  PERSIST: ADD ERROR_HANDLER db.rollback() on_exception\nEND PATCH f1101", "completion": "INTL:BEGIN\n@router.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    try:\n        new_review = Review(\n            user_id=review.user_id,\n            product_id=review.product_id,\n            rating=review.rating,\n            text=review.text\n        )\n        db.add(new_review)\n        db.commit()\n        return {\"id\": new_review.id, \"status\": \"created\"}\n    except Exception as e:\n        db.rollback()\n        raise\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 1101}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/api/keys\")\nasync def create_api_key(request: KeyRequest, db: Session = Depends(get_db)):\n    key = APIKey(\n        user_id=request.user_id,\n        key_hash=hash_key(request.key),\n        created_at=datetime.utcnow()\n    )\n    db.add(key)\n    db.commit()\n    return {\"status\": \"created\", \"key_id\": key.id}\nINTL:END\n\nPATCH f1745 [target=f1745]\n  INTENT \"add encrypted persistence for sensitive api key metadata\"\n  ADD BEFORE: db.commit()\n    key.encrypted_secret = encrypt_secret(request.secret)\n  ADD AFTER: db.commit()\n    persist_key_audit_log(key.id, request.user_id, \"api_key_created\")\nEND PATCH f1745", "completion": "INTL:BEGIN\n@app.post(\"/api/keys\")\nasync def create_api_key(request: KeyRequest, db: Session = Depends(get_db)):\n    key = APIKey(\n        user_id=request.user_id,\n        key_hash=hash_key(request.key),\n        created_at=datetime.utcnow()\n    )\n    db.add(key)\n    key.encrypted_secret = encrypt_secret(request.secret)\n    db.commit()\n    persist_key_audit_log(key.id, request.user_id, \"api_key_created\")\n    return {\"status\": \"created\", \"key_id\": key.id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 1745}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    db_review = Review(\n        title=review.title,\n        content=review.content,\n        rating=review.rating\n    )\n    db.add(db_review)\n    db.commit()\n    db.refresh(db_review)\n    return db_review\nINTL:END\n\nPATCH f2113 [target=f2113]\n  INTENT \"add validation failure handling for invalid rating values\"\n  FAIL ON: rating < 1 or rating > 5\n  ADD: raise HTTPException(status_code=400, detail=\"Rating must be between 1 and 5\")\nEND PATCH f2113", "completion": "INTL:BEGIN\n@app.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    if review.rating < 1 or review.rating > 5:\n        raise HTTPException(status_code=400, detail=\"Rating must be between 1 and 5\")\n    db_review = Review(\n        title=review.title,\n        content=review.content,\n        rating=review.rating\n    )\n    db.add(db_review)\n    db.commit()\n    db.refresh(db_review)\n    return db_review\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "FAIL", "idx": 2113}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/audit/log\")\nasync def create_audit_log(event: AuditEvent):\n    log_entry = {\n        \"timestamp\": datetime.utcnow(),\n        \"event_type\": event.type,\n        \"user_id\": event.user_id,\n        \"action\": event.action,\n        \"resource\": event.resource,\n        \"status\": event.status\n    }\n    await db.audit_logs.insert_one(log_entry)\n    return {\"logged\": True}\nINTL:END\n\nPATCH f2757 [target=f2757]\n  INTENT \"add confidence score to audit log entries\"\n  ADD AFTER: \"status\": event.status,\n  ADD: \"confidence\": event.confidence_score\nEND PATCH f2757", "completion": "INTL:BEGIN\n@app.post(\"/audit/log\")\nasync def create_audit_log(event: AuditEvent):\n    log_entry = {\n        \"timestamp\": datetime.utcnow(),\n        \"event_type\": event.type,\n        \"user_id\": event.user_id,\n        \"action\": event.action,\n        \"resource\": event.resource,\n        \"status\": event.status,\n        \"confidence\": event.confidence_score\n    }\n    await db.audit_logs.insert_one(log_entry)\n    return {\"logged\": True}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 2757}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/subscriptions/{subscription_id}/confirm\")\nasync def confirm_subscription(subscription_id: str, request: ConfirmRequest, db: Session = Depends(get_db)):\n    subscription = db.query(Subscription).filter(Subscription.id == subscription_id).first()\n    if not subscription:\n        raise HTTPException(status_code=404, detail=\"Subscription not found\")\n    \n    subscription.status = \"active\"\n    db.commit()\n    return {\"status\": \"confirmed\", \"subscription_id\": subscription_id}\nINTL:END\n\nPATCH f2435 [target=f2435]\n  INTENT \"add confidence score validation to subscription confirmation\"\n  ADD BEFORE: subscription.status = \"active\"\n    confidence_score = calculate_confidence(subscription, request)\n    if confidence_score < 0.75:\n        raise HTTPException(status_code=422, detail=f\"Confidence score {confidence_score} below threshold\")\nEND PATCH f2435", "completion": "INTL:BEGIN\n@router.post(\"/subscriptions/{subscription_id}/confirm\")\nasync def confirm_subscription(subscription_id: str, request: ConfirmRequest, db: Session = Depends(get_db)):\n    subscription = db.query(Subscription).filter(Subscription.id == subscription_id).first()\n    if not subscription:\n        raise HTTPException(status_code=404, detail=\"Subscription not found\")\n    \n    confidence_score = calculate_confidence(subscription, request)\n    if confidence_score < 0.75:\n        raise HTTPException(status_code=422, detail=f\"Confidence score {confidence_score} below threshold\")\n    subscription.status = \"active\"\n    db.commit()\n    return {\"status\": \"confirmed\", \"subscription_id\": subscription_id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 2435}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    if not file.filename:\n        return {\"error\": \"No filename provided\"}\n    \n    saved_path = await save_to_disk(file)\n    return {\"filename\": file.filename, \"path\": saved_path}\nINTL:END\n\nPATCH f0044 [target=f0044]\n  INTENT \"add file size validation before return\"\n  ADD BEFORE: return {\"filename\": file.filename, \"path\": saved_path}\n    max_size = 10 * 1024 * 1024\n    if file.size > max_size:\n        return {\"error\": f\"File exceeds {max_size} bytes\"}\nEND PATCH f0044", "completion": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    if not file.filename:\n        return {\"error\": \"No filename provided\"}\n    \n    saved_path = await save_to_disk(file)\n    max_size = 10 * 1024 * 1024\n    if file.size > max_size:\n        return {\"error\": f\"File exceeds {max_size} bytes\"}\n    return {\"filename\": file.filename, \"path\": saved_path}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "RETURN", "idx": 44}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/subscriptions\")\nasync def create_subscription(req: SubscriptionRequest, db: Session = Depends(get_db)):\n    user = db.query(User).filter(User.id == req.user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    \n    sub = Subscription(\n        user_id=req.user_id,\n        plan=req.plan,\n        status=\"active\"\n    )\n    db.add(sub)\n    db.commit()\n    return {\"subscription_id\": sub.id, \"status\": sub.status}\nINTL:END\n\nPATCH f0412 [target=f0412]\n  INTENT \"add confidence scoring to subscription creation validation\"\n  ADD BEFORE: sub = Subscription(\n    confidence_score = validate_subscription_confidence(user, req.plan)\n    ADD TO: sub definition\nEND PATCH f0412", "completion": "INTL:BEGIN\n@router.post(\"/subscriptions\")\nasync def create_subscription(req: SubscriptionRequest, db: Session = Depends(get_db)):\n    user = db.query(User).filter(User.id == req.user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    \n    confidence_score = validate_subscription_confidence(user, req.plan)\n    sub = Subscription(\n        user_id=req.user_id,\n        plan=req.plan,\n        status=\"active\",\n        confidence_score=confidence_score\n    )\n    db.add(sub)\n    db.commit()\n    return {\"subscription_id\": sub.id, \"status\": sub.status, \"confidence\": confidence_score}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 412}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION refresh_session [id=f1102]\n  INTENT       \"refresh an active session token with extended expiration\"\n  PRECONDITION token.length > 0\n  PRECONDITION token_type == \"bearer\"\n  POSTCONDITION result.new_token IS NOT NULL\n  POSTCONDITION result.expires_at > now()\n  READS        sessions_table\n  READS        users_table\n  MUTATES      sessions_table\n  OBSERVABLE\n\n  session = QUERY sessions_table WHERE token == token LIMIT 1\n  FALLBACK session IS NULL THEN\n    QUERY users_table WHERE last_active > now()-7d LIMIT 10\n    RETURN SessionRefreshFailed(reason: \"session_expired\", suggestions: [])\n  END FALLBACK\n\n  IF session.expires_at < now() THEN FAIL SessionError(\"token_already_expired\")\n  \n  new_token = generate_token(session.user_id)\n  new_expiry = now() + 72h\n  \n  PERSIST sessions_table (id: session.id, token: new_token, expires_at: new_expiry)\n  DELETE sessions_table WHERE id == session.id AND token == token\n  \n  RETURN SessionToken(token: new_token, expires_at: new_expiry)\nEND FUNCTION refresh_session [id=f1102]", "completion": "# ═══ INTL:BEGIN [id=f1102] refresh_session ═══\nimport logging\nfrom datetime import datetime, timedelta\n\nlogger = logging.getLogger(__name__)\n\nasync def refresh_session(token: str, token_type: str) -> dict:\n    assert len(token) > 0, \"token must not be empty\"\n    assert token_type == \"bearer\", \"token_type must be 'bearer'\"\n    \n    session = await db.query(sessions_table).filter(token=token).first()\n    \n    if session is None:\n        recent_users = await db.query(users_table).filter(\n            last_active__gt=datetime.utcnow() - timedelta(days=7)\n        ).limit(10).all()\n        logger.warning(\"refresh_session: session_not_found, token=%s\", token[:16])\n        raise SessionRefreshFailed(reason=\"session_expired\", suggestions=[])\n    \n    if session.expires_at < datetime.utcnow():\n        raise SessionError(\"token_already_expired\")\n    \n    new_token = generate_token(session.user_id)\n    new_expiry = datetime.utcnow() + timedelta(hours=72)\n    \n    await db.update(sessions_table, id=session.id, \n                    token=new_token, expires_at=new_expiry)\n    await db.delete(sessions_table, id=session.id, token=token)\n    \n    logger.info(\"refresh_session: user=%s, old_token=%s\", \n                session.user_id, token[:16])\n    \n    result = SessionToken(token=new_token, expires_at=new_expiry)\n    assert result.new_token is not None\n    assert result.expires_at > datetime.utcnow()\n    return result\n# ═══ INTL:END   [id=f1102] refresh_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 1102}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION upload_document [id=f1424]\n  INTENT       \"validate and persist uploaded document with virus scan\"\n  PRECONDITION file_size > 0\n  PRECONDITION file_size <= 52428800\n  PRECONDITION file_name.length > 0\n  PRECONDITION file_name.length <= 255\n  PRECONDITION mime_type IN (\"application/pdf\", \"application/msword\", \"text/plain\")\n  POSTCONDITION result.document_id IS NOT NULL\n  POSTCONDITION result.scan_status == \"clean\"\n  READS        mime_types_table\n  MUTATES      documents_table\n  MUTATES      file_storage\n  OBSERVABLE\n\n  IF file_size == 0 THEN FAIL ValidationError(\"file_is_empty\")\n  IF file_size > 52428800 THEN FAIL ValidationError(\"file_exceeds_50mb\")\n  IF file_name.length == 0 THEN FAIL ValidationError(\"filename_required\")\n  IF file_name.length > 255 THEN FAIL ValidationError(\"filename_too_long\")\n  allowed_types = QUERY mime_types_table WHERE enabled == true\n  IF mime_type NOT IN allowed_types THEN FAIL ValidationError(\"unsupported_file_type\")\n  \n  scan_result = scan_virus(file_buffer)\n  IF scan_result.threat_detected THEN FAIL SecurityError(\"malware_detected\")\n  \n  document_id = generate_uuid()\n  file_path = store_file(file_buffer, document_id, file_name)\n  PERSIST documents_table (id: document_id, file_name: file_name, file_path: file_path, mime_type: mime_type, file_size: file_size, scan_status: \"clean\", uploaded_at: now())\n  RETURN DocumentUpload(document_id: document_id, file_name: file_name, scan_status: \"clean\")\nEND FUNCTION upload_document [id=f1424]", "completion": "# ═══ INTL:BEGIN [id=f1424] upload_document ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\n\nlogger = logging.getLogger(__name__)\n\nasync def upload_document(file_buffer: bytes, file_name: str, file_size: int, mime_type: str) -> DocumentUpload:\n    assert file_size > 0, \"file_is_empty\"\n    assert file_size <= 52428800, \"file_exceeds_50mb\"\n    assert len(file_name) > 0, \"filename_required\"\n    assert len(file_name) <= 255, \"filename_too_long\"\n    \n    allowed_types = await db.query(mime_types_table).filter(enabled=True).all()\n    allowed_mime_types = {mt.mime_type for mt in allowed_types}\n    if mime_type not in allowed_mime_types:\n        raise ValidationError(\"unsupported_file_type\")\n    \n    scan_result = await scan_virus(file_buffer)\n    if scan_result.threat_detected:\n        raise SecurityError(\"malware_detected\")\n    \n    document_id = str(uuid4())\n    file_path = await store_file(file_buffer, document_id, file_name)\n    \n    await db.insert(\n        documents_table,\n        id=document_id,\n        file_name=file_name,\n        file_path=file_path,\n        mime_type=mime_type,\n        file_size=file_size,\n        scan_status=\"clean\",\n        uploaded_at=datetime.utcnow()\n    )\n    \n    logger.info(\"upload_document: document_id=%s, file_name=%s, file_size=%d\", document_id, file_name, file_size)\n    \n    result = DocumentUpload(document_id=document_id, file_name=file_name, scan_status=\"clean\")\n    assert result.document_id is not None\n    assert result.scan_status == \"clean\"\n    return result\n# ═══ INTL:END   [id=f1424] upload_document ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FAIL", "idx": 1424}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_batch_uploads [id=f1746]\n  INTENT       \"validate and store multiple file uploads with virus scanning\"\n  PRECONDITION files.length > 0\n  PRECONDITION files.length <= 100\n  PRECONDITION max_file_size > 0\n  POSTCONDITION result.processed_count == result.success_count + result.failed_count\n  READS        virus_definitions\n  MUTATES      uploads_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n\n  processed_count = 0\n  success_count = 0\n  failed_count = 0\n  results = []\n\n  LOOP file IN files DO\n    processed_count = processed_count + 1\n    IF file.size > max_file_size THEN\n      APPEND results (file_name: file.name, status: \"rejected\", reason: \"exceeds_size_limit\")\n      failed_count = failed_count + 1\n      CONTINUE\n    END IF\n    IF NOT scan_virus(file.content, virus_definitions) THEN\n      APPEND results (file_name: file.name, status: \"rejected\", reason: \"virus_detected\")\n      failed_count = failed_count + 1\n      CONTINUE\n    END IF\n    file_id = generate_uuid()\n    PERSIST uploads_table (id: file_id, file_name: file.name, file_size: file.size, upload_timestamp: now(), user_id: user_id, status: \"completed\")\n    APPEND results (file_name: file.name, status: \"uploaded\", file_id: file_id)\n    success_count = success_count + 1\n  END LOOP\n\n  PERSIST audit_log_table (user_id: user_id, action: \"batch_upload\", file_count: processed_count, success_count: success_count, timestamp: now())\n  RETURN BatchUploadResult(processed_count: processed_count, success_count: success_count, failed_count: failed_count, details: results)\nEND FUNCTION process_batch_uploads [id=f1746]", "completion": "# ═══ INTL:BEGIN [id=f1746] process_batch_uploads ═══\nimport logging\nimport uuid\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def process_batch_uploads(\n    files: List[UploadFile],\n    user_id: str,\n    max_file_size: int\n) -> BatchUploadResult:\n    assert len(files) > 0, \"files list must not be empty\"\n    assert len(files) <= 100, \"files list must not exceed 100 items\"\n    assert max_file_size > 0, \"max_file_size must be greater than 0\"\n\n    virus_definitions = await db.query(virus_definitions_table).all()\n\n    processed_count = 0\n    success_count = 0\n    failed_count = 0\n    results = []\n\n    for file in files:\n        processed_count += 1\n        file_content = await file.read()\n\n        if len(file_content) > max_file_size:\n            results.append({\n                \"file_name\": file.filename,\n                \"status\": \"rejected\",\n                \"reason\": \"exceeds_size_limit\"\n            })\n            failed_count += 1\n            continue\n\n        if not scan_virus(file_content, virus_definitions):\n            results.append({\n                \"file_name\": file.filename,\n                \"status\": \"rejected\",\n                \"reason\": \"virus_detected\"\n            })\n            failed_count += 1\n            continue\n\n        file_id = str(uuid.uuid4())\n        await db.insert(uploads_table,\n                       id=file_id,\n                       file_name=file.filename,\n                       file_size=len(file_content),\n                       upload_timestamp=datetime.utcnow(),\n                       user_id=user_id,\n                       status=\"completed\")\n\n        results.append({\n            \"file_name\": file.filename,\n            \"status\": \"uploaded\",\n            \"file_id\": file_id\n        })\n        success_count += 1\n\n    await db.insert(audit_log_table,\n                   user_id=user_id,\n                   action=\"batch_upload\",\n                   file_count=processed_count,\n                   success_count=success_count,\n                   timestamp=datetime.utcnow())\n\n    logger.info(\"batch_upload: user=%s, processed=%d, success=%d, failed=%d\",\n               user_id, processed_count, success_count, failed_count)\n\n    result = BatchUploadResult(\n        processed_count=processed_count,\n        success_count=success_count,\n        failed_count=failed_count,\n        details=results\n    )\n    assert result.processed_count == result.success_count + result.failed_count\n    return result\n# ═══ INTL:END   [id=f1746] process_batch_uploads ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 1746}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION list_active_sessions [id=f2436]\n  INTENT       \"retrieve paginated list of active user sessions with filtering\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION page >= 1\n  PRECONDITION page_size > 0 AND page_size <= 100\n  POSTCONDITION result.total >= 0\n  POSTCONDITION result.items IS NOT NULL\n  READS        sessions_table\n  MUTATES      session_audit_log\n  OBSERVABLE\n\n  sessions = PAGINATE sessions_table \n    WHERE user_id == user_id AND expires_at > now()\n    ORDER BY created_at DESC\n    PAGE page\n    SIZE page_size\n  \n  total_count = COUNT sessions_table WHERE user_id == user_id AND expires_at > now()\n  PERSIST session_audit_log (user_id: user_id, action: \"list_sessions\", page: page, timestamp: now())\n  RETURN SessionList(items: sessions, total: total_count, page: page, page_size: page_size)\nEND FUNCTION list_active_sessions [id=f2436]", "completion": "# ═══ INTL:BEGIN [id=f2436] list_active_sessions ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def list_active_sessions(\n    user_id: str,\n    page: int,\n    page_size: int\n) -> SessionList:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert page >= 1, \"page must be >= 1\"\n    assert page_size > 0, \"page_size must be > 0\"\n    assert page_size <= 100, \"page_size must be <= 100\"\n    \n    offset = (page - 1) * page_size\n    sessions = await db.query(sessions_table).filter(\n        user_id=user_id,\n        expires_at__gt=datetime.utcnow()\n    ).order_by(\"-created_at\").offset(offset).limit(page_size).all()\n    \n    total_count = await db.query(sessions_table).filter(\n        user_id=user_id,\n        expires_at__gt=datetime.utcnow()\n    ).count()\n    \n    await db.insert(\n        session_audit_log,\n        user_id=user_id,\n        action=\"list_sessions\",\n        page=page,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"list_active_sessions: user_id=%s page=%d total=%d\", user_id, page, total_count)\n    \n    result = SessionList(\n        items=sessions,\n        total=total_count,\n        page=page,\n        page_size=page_size\n    )\n    assert result.total >= 0\n    assert result.items is not None\n    return result\n# ═══ INTL:END   [id=f2436] list_active_sessions ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PAGINATE", "idx": 2436}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION search_and_bookmark [id=f2114]\n  INTENT       \"search products by query and atomically bookmark top result for user\"\n  PRECONDITION query.length > 0\n  PRECONDITION query.length <= 256\n  PRECONDITION user_id > 0\n  PRECONDITION limit >= 1\n  PRECONDITION limit <= 100\n  POSTCONDITION result.search_id IS NOT NULL\n  POSTCONDITION result.bookmarked_product_id IS NOT NULL\n  READS        products_table\n  MUTATES      search_logs_table\n  MUTATES      bookmarks_table\n  OBSERVABLE\n\n  TRANSACTION\n    results = QUERY products_table WHERE name ILIKE query LIMIT limit\n    IF results.length == 0 THEN FAIL SearchError(\"no_products_found\")\n    top_product = results[0]\n    search_log = PERSIST search_logs_table (user_id: user_id, query: query, result_count: results.length, top_product_id: top_product.id, searched_at: now())\n    existing_bookmark = QUERY bookmarks_table WHERE user_id == user_id AND product_id == top_product.id LIMIT 1\n    IF existing_bookmark IS NULL THEN\n      PERSIST bookmarks_table (user_id: user_id, product_id: top_product.id, created_at: now())\n    END IF\n  END TRANSACTION\n  \n  RETURN SearchResult(search_id: search_log.id, bookmarked_product_id: top_product.id, total_results: results.length)\nEND FUNCTION search_and_bookmark [id=f2114]", "completion": "# ═══ INTL:BEGIN [id=f2114] search_and_bookmark ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def search_and_bookmark(user_id: int, query: str, limit: int = 20) -> SearchResult:\n    assert len(query) > 0, \"query must not be empty\"\n    assert len(query) <= 256, \"query must be at most 256 characters\"\n    assert user_id > 0, \"user_id must be positive\"\n    assert limit >= 1, \"limit must be at least 1\"\n    assert limit <= 100, \"limit must be at most 100\"\n    \n    async with db.transaction():\n        results = await db.query(products_table).filter(\n            products_table.name.ilike(f\"%{query}%\")\n        ).limit(limit).all()\n        \n        if not results:\n            raise SearchError(\"no_products_found\")\n        \n        top_product = results[0]\n        \n        search_log = await db.insert(\n            search_logs_table,\n            user_id=user_id,\n            query=query,\n            result_count=len(results),\n            top_product_id=top_product.id,\n            searched_at=datetime.utcnow()\n        )\n        \n        existing_bookmark = await db.query(bookmarks_table).filter(\n            (bookmarks_table.user_id == user_id) &\n            (bookmarks_table.product_id == top_product.id)\n        ).limit(1).first()\n        \n        if existing_bookmark is None:\n            await db.insert(\n                bookmarks_table,\n                user_id=user_id,\n                product_id=top_product.id,\n                created_at=datetime.utcnow()\n            )\n        \n        logger.info(\"search_and_bookmark: user_id=%s query=%s top_product_id=%s result_count=%s\",\n                    user_id, query, top_product.id, len(results))\n    \n    assert search_log.id is not None\n    assert top_product.id is not None\n    \n    return SearchResult(\n        search_id=search_log.id,\n        bookmarked_product_id=top_product.id,\n        total_results=len(results)\n    )\n# ═══ INTL:END   [id=f2114] search_and_bookmark ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 2114}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom redis import Redis\n\napp = FastAPI()\ncache = Redis(host='localhost', port=6379, db=0)\n\n@app.get(\"/inventory/{item_id}\")\ndef get_inventory(item_id: str):\n    result = cache.get(f\"inventory:{item_id}\")\n    if result:\n        return {\"cached\": True, \"data\": result}\n    return {\"cached\": False, \"data\": None}\n\n@app.post(\"/inventory/{item_id}\")\ndef update_inventory(item_id: str, quantity: int):\n    cache.set(f\"inventory:{item_id}\", quantity)\n    return {\"status\": \"updated\", \"item_id\": item_id}\nINTL:END\n\nPATCH f2758 [target=f2758]\n  INTENT \"add TTL expiration to cache SET operations for inventory items\"\n  MODIFY: cache.set(f\"inventory:{item_id}\", quantity)\n  REPLACE WITH: cache.setex(f\"inventory:{item_id}\", 3600, quantity)\nEND PATCH f2758", "completion": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom redis import Redis\n\napp = FastAPI()\ncache = Redis(host='localhost', port=6379, db=0)\n\n@app.get(\"/inventory/{item_id}\")\ndef get_inventory(item_id: str):\n    result = cache.get(f\"inventory:{item_id}\")\n    if result:\n        return {\"cached\": True, \"data\": result}\n    return {\"cached\": False, \"data\": None}\n\n@app.post(\"/inventory/{item_id}\")\ndef update_inventory(item_id: str, quantity: int):\n    cache.setex(f\"inventory:{item_id}\", 3600, quantity)\n    return {\"status\": \"updated\", \"item_id\": item_id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CACHE SET", "idx": 2758}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/api/resource\")\nasync def create_resource(request: ResourceRequest, current_user: User = Depends(get_current_user)):\n    resource = Resource(name=request.name, owner_id=current_user.id)\n    db.add(resource)\n    db.commit()\n    return {\"status\": \"created\", \"resource_id\": resource.id}\nINTL:END\n\nPATCH f0413 [target=f0413]\n  INTENT \"transform resource creation to enforce role-based permissions\"\n  TRANSFORM check_ownership → check_role_permission(current_user, \"resource:create\")\n  ADD BEFORE: if not check_role_permission(current_user, \"resource:create\"): raise HTTPException(status_code=403, detail=\"Insufficient permissions\")\nEND PATCH f0413", "completion": "INTL:BEGIN\n@app.post(\"/api/resource\")\nasync def create_resource(request: ResourceRequest, current_user: User = Depends(get_current_user)):\n    if not check_role_permission(current_user, \"resource:create\"):\n        raise HTTPException(status_code=403, detail=\"Insufficient permissions\")\n    resource = Resource(name=request.name, owner_id=current_user.id)\n    db.add(resource)\n    db.commit()\n    return {\"status\": \"created\", \"resource_id\": resource.id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 413}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_role_hierarchy [id=f0045]\n  INTENT       \"grant a role to a user, propagating permissions through the role hierarchy\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION role_name.length > 0\n  PRECONDITION requester_id IS NOT NULL\n  POSTCONDITION result.success == TRUE\n  READS        users_table, roles_table, permissions_table, role_hierarchy_table\n  MUTATES      user_roles_table, audit_log_table\n  OBSERVABLE\n\n  SEQUENCE\n    step_1: requester = QUERY users_table WHERE id == requester_id LIMIT 1\n    IF requester IS NULL THEN FAIL AuthError(\"requester_not_found\")\n    \n    step_2: role = QUERY roles_table WHERE name == role_name LIMIT 1\n    IF role IS NULL THEN FAIL PermissionError(\"role_not_found\")\n    \n    step_3: IF NOT requester.admin THEN FAIL AuthError(\"insufficient_permissions\")\n    \n    step_4: target_user = QUERY users_table WHERE id == user_id LIMIT 1\n    IF target_user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n    \n    step_5: parent_roles = QUERY role_hierarchy_table WHERE child_role_id == role.id\n    \n    step_6: PERSIST user_roles_table (user_id: user_id, role_id: role.id, granted_at: now(), granted_by: requester_id)\n    \n    step_7: FOR each parent IN parent_roles DO\n      PERSIST user_roles_table (user_id: user_id, role_id: parent.parent_role_id, granted_at: now(), granted_by: requester_id)\n    END FOR\n    \n    step_8: PERSIST audit_log_table (action: \"role_granted\", target_user_id: user_id, role_id: role.id, requester_id: requester_id, timestamp: now())\n  END SEQUENCE\n\n  RETURN GrantResult(success: TRUE, role_id: role.id, user_id: user_id)\nEND FUNCTION grant_role_hierarchy [id=f0045]", "completion": "# ═══ INTL:BEGIN [id=f0045] grant_role_hierarchy ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def grant_role_hierarchy(user_id: str, role_name: str, requester_id: str) -> GrantResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(role_name) > 0, \"role_name must not be empty\"\n    assert requester_id is not None, \"requester_id must not be null\"\n    \n    # step_1: Verify requester exists\n    requester = await db.query(users_table).filter(id=requester_id).first()\n    if requester is None:\n        raise AuthError(\"requester_not_found\")\n    \n    # step_2: Verify role exists\n    role = await db.query(roles_table).filter(name=role_name).first()\n    if role is None:\n        raise PermissionError(\"role_not_found\")\n    \n    # step_3: Check requester has admin privileges\n    if not requester.admin:\n        raise AuthError(\"insufficient_permissions\")\n    \n    # step_4: Verify target user exists\n    target_user = await db.query(users_table).filter(id=user_id).first()\n    if target_user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    # step_5: Fetch parent roles from hierarchy\n    parent_roles = await db.query(role_hierarchy_table).filter(\n        child_role_id=role.id\n    ).all()\n    \n    # step_6: Grant the primary role\n    await db.insert(\n        user_roles_table,\n        user_id=user_id,\n        role_id=role.id,\n        granted_at=datetime.utcnow(),\n        granted_by=requester_id\n    )\n    \n    # step_7: Grant all inherited parent roles\n    for parent in parent_roles:\n        await db.insert(\n            user_roles_table,\n            user_id=user_id,\n            role_id=parent.parent_role_id,\n            granted_at=datetime.utcnow(),\n            granted_by=requester_id\n        )\n    \n    # step_8: Log audit entry\n    await db.insert(\n        audit_log_table,\n        action=\"role_granted\",\n        target_user_id=user_id,\n        role_id=role.id,\n        requester_id=requester_id,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"grant_role_hierarchy: user=%s, role=%s, requester=%s\", \n                user_id, role.id, requester_id)\n    \n    result = GrantResult(success=True, role_id=role.id, user_id=user_id)\n    assert result.success == True\n    return result\n# ═══ INTL:END   [id=f0045] grant_role_hierarchy ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 45}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/shipments\")\nasync def create_shipment(shipment: ShipmentRequest):\n    order_id = shipment.order_id\n    carrier = shipment.carrier\n    tracking_number = generate_tracking()\n    db.insert_shipment(order_id, carrier, tracking_number)\n    return {\"status\": \"created\", \"tracking\": tracking_number}\nINTL:END\n\nPATCH f1103 [target=f1103]\n  INTENT \"add database transaction wrapping to ensure atomic shipment creation\"\n  ADD BEFORE: session.begin_transaction()\n  ADD AFTER: session.commit()\nEND PATCH f1103", "completion": "INTL:BEGIN\n@app.post(\"/shipments\")\nasync def create_shipment(shipment: ShipmentRequest):\n    session.begin_transaction()\n    order_id = shipment.order_id\n    carrier = shipment.carrier\n    tracking_number = generate_tracking()\n    db.insert_shipment(order_id, carrier, tracking_number)\n    session.commit()\n    return {\"status\": \"created\", \"tracking\": tracking_number}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 1103}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_permission [id=f0735]\n  INTENT       \"grant a permission to a user with validation and audit logging\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION permission_name.length > 0\n  PRECONDITION requester_role IN (\"admin\", \"owner\")\n  POSTCONDITION result.granted IS TRUE\n  READS        users_table\n  READS        roles_table\n  MUTATES      permissions_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n\n  requester = QUERY users_table WHERE id == requester_id LIMIT 1\n  IF requester IS NULL THEN FAIL PermissionError(\"requester_not_found\")\n  IF requester.role NOT IN (\"admin\", \"owner\") THEN FAIL PermissionError(\"insufficient_privileges\")\n  \n  target_user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF target_user IS NULL THEN FAIL PermissionError(\"target_user_not_found\")\n  \n  perm_check = QUERY permissions_table WHERE user_id == user_id AND permission == permission_name LIMIT 1\n  IF perm_check IS NOT NULL THEN FAIL PermissionError(\"permission_already_granted\")\n  \n  PERSIST permissions_table (user_id: user_id, permission: permission_name, granted_by: requester_id, granted_at: now())\n  PERSIST audit_log_table (action: \"GRANT_PERMISSION\", actor_id: requester_id, target_id: user_id, permission: permission_name, timestamp: now())\n  \n  RETURN PermissionGrant(granted: TRUE, user_id: user_id, permission: permission_name)\nEND FUNCTION grant_permission [id=f0735]", "completion": "# ═══ INTL:BEGIN [id=f0735] grant_permission ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nclass PermissionError(Exception):\n    pass\n\nasync def grant_permission(user_id: str, permission_name: str, requester_id: str, requester_role: str) -> dict:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(permission_name) > 0, \"permission_name must not be empty\"\n    assert requester_role in (\"admin\", \"owner\"), \"requester_role must be admin or owner\"\n    \n    requester = await db.query(users_table).filter(id=requester_id).first()\n    if requester is None:\n        raise PermissionError(\"requester_not_found\")\n    if requester.role not in (\"admin\", \"owner\"):\n        raise PermissionError(\"insufficient_privileges\")\n    \n    target_user = await db.query(users_table).filter(id=user_id).first()\n    if target_user is None:\n        raise PermissionError(\"target_user_not_found\")\n    \n    perm_check = await db.query(permissions_table).filter(\n        user_id=user_id, permission=permission_name\n    ).first()\n    if perm_check is not None:\n        raise PermissionError(\"permission_already_granted\")\n    \n    await db.insert(\n        permissions_table,\n        user_id=user_id,\n        permission=permission_name,\n        granted_by=requester_id,\n        granted_at=datetime.utcnow()\n    )\n    \n    await db.insert(\n        audit_log_table,\n        action=\"GRANT_PERMISSION\",\n        actor_id=requester_id,\n        target_id=user_id,\n        permission=permission_name,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"grant_permission: requester=%s granted %s to user=%s\", requester_id, permission_name, user_id)\n    \n    result = {\"granted\": True, \"user_id\": user_id, \"permission\": permission_name}\n    assert result[\"granted\"] is True\n    return result\n# ═══ INTL:END   [id=f0735] grant_permission ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FAIL", "idx": 735}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_session [id=f1425]\n  INTENT       \"invalidate an active session token and log the revocation event\"\n  PRECONDITION token.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.revoked IS TRUE\n  READS        sessions_table\n  MUTATES      sessions_table, audit_log\n  OBSERVABLE\n\n  session = QUERY sessions_table WHERE token == token LIMIT 1\n  IF session IS NULL THEN FAIL SessionError(\"session_not_found\")\n  IF session.user_id != user_id THEN FAIL SessionError(\"unauthorized_revocation\")\n  IF session.expires_at < now() THEN FAIL SessionError(\"session_already_expired\")\n  UPDATE sessions_table SET status = \"revoked\", revoked_at = now() WHERE token == token\n  PERSIST audit_log (user_id: user_id, action: \"session_revoke\", timestamp: now(), token_hash: hash(token))\n  RETURN RevokeResult(revoked: TRUE, revoked_at: now())\nEND FUNCTION revoke_session [id=f1425]", "completion": "# ═══ INTL:BEGIN [id=f1425] revoke_session ═══\nimport logging\nfrom datetime import datetime\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_session(token: str, user_id: int) -> RevokeResult:\n    assert len(token) > 0, \"token must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    \n    session = await db.query(sessions_table).filter(token=token).first()\n    if session is None:\n        raise SessionError(\"session_not_found\")\n    if session.user_id != user_id:\n        raise SessionError(\"unauthorized_revocation\")\n    if session.expires_at < datetime.utcnow():\n        raise SessionError(\"session_already_expired\")\n    \n    await db.update(sessions_table).filter(token=token).set(\n        status=\"revoked\", revoked_at=datetime.utcnow()\n    )\n    \n    token_hash = hashlib.sha256(token.encode()).hexdigest()\n    await db.insert(audit_log, user_id=user_id, action=\"session_revoke\",\n                    timestamp=datetime.utcnow(), token_hash=token_hash)\n    \n    logger.info(\"revoke_session: user_id=%s token_hash=%s\", user_id, token_hash[:16])\n    \n    result = RevokeResult(revoked=True, revoked_at=datetime.utcnow())\n    assert result.revoked is True\n    return result\n# ═══ INTL:END   [id=f1425] revoke_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 1425}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/resources/{resource_id}/check\")\nasync def check_resource_permissions(resource_id: str, user_id: str):\n    perm1 = db.query_user_role(user_id)\n    perm2 = db.query_resource_access(resource_id)\n    perm3 = db.query_group_membership(user_id)\n    perm4 = db.query_delegation_rights(user_id)\n    \n    result = {\n        \"role\": perm1,\n        \"access\": perm2,\n        \"group\": perm3,\n        \"delegation\": perm4\n    }\n    return result\nINTL:END\n\nPATCH f1747 [target=f1747]\n  INTENT \"parallelize permission lookups for performance\"\n  CONSTRUCT PARALLEL\n  ADD: import asyncio\n  MODIFY: Execute perm1, perm2, perm3, perm4 queries concurrently using gather\nEND PATCH f1747", "completion": "INTL:BEGIN\nimport asyncio\n\n@app.get(\"/resources/{resource_id}/check\")\nasync def check_resource_permissions(resource_id: str, user_id: str):\n    perm1, perm2, perm3, perm4 = await asyncio.gather(\n        db.query_user_role(user_id),\n        db.query_resource_access(resource_id),\n        db.query_group_membership(user_id),\n        db.query_delegation_rights(user_id)\n    )\n    \n    result = {\n        \"role\": perm1,\n        \"access\": perm2,\n        \"group\": perm3,\n        \"delegation\": perm4\n    }\n    return result\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PARALLEL", "idx": 1747}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION apply_coupon [id=f2115]\n  INTENT       \"validate and apply a coupon code to a cart, returning discount details\"\n  PRECONDITION coupon_code.length > 0\n  PRECONDITION cart_id.length > 0\n  PRECONDITION quantity > 0\n  POSTCONDITION result.discount_amount >= 0\n  READS        coupons_table, carts_table\n  MUTATES      coupon_usage_table\n  OBSERVABLE\n\n  coupon = QUERY coupons_table WHERE code == coupon_code LIMIT 1\n  IF coupon IS NULL THEN FAIL CouponError(\"coupon_not_found\")\n  IF coupon.is_active == FALSE THEN FAIL CouponError(\"coupon_expired\")\n  IF coupon.max_uses IS NOT NULL AND coupon.used_count >= coupon.max_uses THEN FAIL CouponError(\"coupon_limit_reached\")\n  cart = QUERY carts_table WHERE id == cart_id LIMIT 1\n  IF cart IS NULL THEN FAIL CartError(\"cart_not_found\")\n  discount_amount = (cart.subtotal * coupon.discount_percent) / 100\n  IF discount_amount > coupon.max_discount THEN discount_amount = coupon.max_discount\n  PERSIST coupon_usage_table (coupon_id: coupon.id, cart_id: cart_id, applied_at: now())\n  RETURN CouponResult(coupon_code: coupon_code, discount_amount: discount_amount, final_total: cart.subtotal - discount_amount)\nEND FUNCTION apply_coupon [id=f2115]", "completion": "# ═══ INTL:BEGIN [id=f2115] apply_coupon ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def apply_coupon(coupon_code: str, cart_id: str, quantity: int) -> CouponResult:\n    assert len(coupon_code) > 0, \"coupon_code must not be empty\"\n    assert len(cart_id) > 0, \"cart_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    \n    coupon = await db.query(coupons_table).filter(code=coupon_code).first()\n    if coupon is None:\n        raise CouponError(\"coupon_not_found\")\n    if coupon.is_active is False:\n        raise CouponError(\"coupon_expired\")\n    if coupon.max_uses is not None and coupon.used_count >= coupon.max_uses:\n        raise CouponError(\"coupon_limit_reached\")\n    \n    cart = await db.query(carts_table).filter(id=cart_id).first()\n    if cart is None:\n        raise CartError(\"cart_not_found\")\n    \n    discount_amount = (cart.subtotal * coupon.discount_percent) / 100\n    if discount_amount > coupon.max_discount:\n        discount_amount = coupon.max_discount\n    \n    await db.insert(coupon_usage_table, coupon_id=coupon.id, cart_id=cart_id,\n                    applied_at=datetime.utcnow())\n    \n    logger.info(\"apply_coupon: coupon=%s cart=%s discount=%.2f\", coupon_code, cart_id, discount_amount)\n    \n    final_total = cart.subtotal - discount_amount\n    result = CouponResult(coupon_code=coupon_code, discount_amount=discount_amount, final_total=final_total)\n    assert result.discount_amount >= 0\n    return result\n# ═══ INTL:END   [id=f2115] apply_coupon ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "RETURN", "idx": 2115}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/process_payment\")\nasync def process_payment(payment: PaymentRequest):\n    user = get_user(payment.user_id)\n    amount = validate_amount(payment.amount)\n    transaction = create_transaction(user, amount)\n    charge_card(transaction.card_id, amount)\n    log_transaction(transaction)\n    return {\"status\": \"success\", \"transaction_id\": transaction.id}\nINTL:END\n\nPATCH f2437 [target=f2437]\n  INTENT \"add rate limiting and fraud check to payment sequence\"\n  ADD BEFORE: rate_limit_check(payment.user_id)\n  ADD AFTER: validate_amount(payment.amount): fraud_detection_check(user, amount)\nEND PATCH f2437", "completion": "INTL:BEGIN\n@app.post(\"/process_payment\")\nasync def process_payment(payment: PaymentRequest):\n    rate_limit_check(payment.user_id)\n    user = get_user(payment.user_id)\n    amount = validate_amount(payment.amount)\n    fraud_detection_check(user, amount)\n    transaction = create_transaction(user, amount)\n    charge_card(transaction.card_id, amount)\n    log_transaction(transaction)\n    return {\"status\": \"success\", \"transaction_id\": transaction.id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 2437}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_inventory [id=f2759]\n  INTENT       \"replenish stock for a product and log the transaction\"\n  PRECONDITION product_id.length > 0\n  PRECONDITION quantity > 0\n  POSTCONDITION result.stock_level >= 0\n  READS        products_table\n  MUTATES      products_table\n  MUTATES      inventory_log_table\n  OBSERVABLE\n\n  product = QUERY products_table WHERE id == product_id LIMIT 1\n  FALLBACK product IS NULL THEN\n    PERSIST inventory_log_table (product_id: product_id, action: \"restock_failed\", reason: \"product_not_found\", timestamp: now())\n    RETURN RestockResult(success: FALSE, stock_level: 0, message: \"Product not found\")\n  END FALLBACK\n\n  new_stock = product.stock_level + quantity\n  UPDATE products_table SET stock_level = new_stock WHERE id == product_id\n  PERSIST inventory_log_table (product_id: product_id, action: \"restock\", quantity_added: quantity, new_stock: new_stock, timestamp: now())\n  RETURN RestockResult(success: TRUE, stock_level: new_stock, message: \"Stock replenished successfully\")\nEND FUNCTION restock_inventory [id=f2759]", "completion": "# ═══ INTL:BEGIN [id=f2759] restock_inventory ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_inventory(product_id: str, quantity: int) -> RestockResult:\n    assert len(product_id) > 0, \"product_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    \n    product = await db.query(products_table).filter(id=product_id).first()\n    if product is None:\n        await db.insert(inventory_log_table, \n                       product_id=product_id, \n                       action=\"restock_failed\", \n                       reason=\"product_not_found\", \n                       timestamp=datetime.utcnow())\n        logger.warning(\"restock_inventory: product_not_found product_id=%s\", product_id)\n        return RestockResult(success=False, stock_level=0, message=\"Product not found\")\n    \n    new_stock = product.stock_level + quantity\n    await db.update(products_table).filter(id=product_id).set(stock_level=new_stock)\n    await db.insert(inventory_log_table,\n                   product_id=product_id,\n                   action=\"restock\",\n                   quantity_added=quantity,\n                   new_stock=new_stock,\n                   timestamp=datetime.utcnow())\n    \n    logger.info(\"restock_inventory: product_id=%s quantity=%d new_stock=%d\", product_id, quantity, new_stock)\n    result = RestockResult(success=True, stock_level=new_stock, message=\"Stock replenished successfully\")\n    assert result.stock_level >= 0, \"stock_level must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f2759] restock_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 2759}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION record_event_confidence [id=f0414]\n  INTENT       \"record user analytics event with confidence score validation\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION event_type IN (\"click\", \"view\", \"conversion\", \"error\")\n  PRECONDITION confidence_score >= 0.0\n  PRECONDITION confidence_score <= 1.0\n  POSTCONDITION result.event_id IS NOT NULL\n  POSTCONDITION result.persisted IS TRUE\n  READS        users_table\n  MUTATES      events_table\n  MUTATES      confidence_metrics_table\n  OBSERVABLE\n\n  CONFIDENCE threshold = 0.75\n  user = QUERY users_table WHERE user_id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL ValidationError(\"user_not_found\")\n  IF confidence_score < threshold THEN\n    PERSIST confidence_metrics_table (user_id: user_id, event_type: event_type, \n                                       confidence_score: confidence_score, \n                                       status: \"low_confidence\", recorded_at: now())\n    RETURN AnalyticsResult(event_id: NULL, persisted: FALSE, confidence: confidence_score)\n  END IF\n  event_id = generate_uuid()\n  PERSIST events_table (event_id: event_id, user_id: user_id, event_type: event_type, \n                        confidence_score: confidence_score, timestamp: now())\n  PERSIST confidence_metrics_table (user_id: user_id, event_type: event_type, \n                                     confidence_score: confidence_score, \n                                     status: \"recorded\", recorded_at: now())\n  RETURN AnalyticsResult(event_id: event_id, persisted: TRUE, confidence: confidence_score)\nEND FUNCTION record_event_confidence [id=f0414]", "completion": "# ═══ INTL:BEGIN [id=f0414] record_event_confidence ═══\nimport logging\nimport uuid\nfrom datetime import datetime\nfrom typing import Optional\n\nlogger = logging.getLogger(__name__)\n\nCONFIDENCE_THRESHOLD = 0.75\n\nasync def record_event_confidence(\n    user_id: str,\n    event_type: str,\n    confidence_score: float\n) -> AnalyticsResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert event_type in (\"click\", \"view\", \"conversion\", \"error\"), \\\n        \"event_type must be one of: click, view, conversion, error\"\n    assert confidence_score >= 0.0, \"confidence_score must be >= 0.0\"\n    assert confidence_score <= 1.0, \"confidence_score must be <= 1.0\"\n    \n    user = await db.query(users_table).filter(user_id=user_id).first()\n    if user is None:\n        raise ValidationError(\"user_not_found\")\n    \n    if confidence_score < CONFIDENCE_THRESHOLD:\n        await db.insert(\n            confidence_metrics_table,\n            user_id=user_id,\n            event_type=event_type,\n            confidence_score=confidence_score,\n            status=\"low_confidence\",\n            recorded_at=datetime.utcnow()\n        )\n        logger.info(\n            \"record_event_confidence: low_confidence threshold=%f score=%f user=%s event=%s\",\n            CONFIDENCE_THRESHOLD, confidence_score, user_id, event_type\n        )\n        result = AnalyticsResult(event_id=None, persisted=False, confidence=confidence_score)\n        assert result.persisted is False\n        return result\n    \n    event_id = str(uuid.uuid4())\n    await db.insert(\n        events_table,\n        event_id=event_id,\n        user_id=user_id,\n        event_type=event_type,\n        confidence_score=confidence_score,\n        timestamp=datetime.utcnow()\n    )\n    await db.insert(\n        confidence_metrics_table,\n        user_id=user_id,\n        event_type=event_type,\n        confidence_score=confidence_score,\n        status=\"recorded\",\n        recorded_at=datetime.utcnow()\n    )\n    logger.info(\n        \"record_event_confidence: recorded event_id=%s user=%s event=%s confidence=%f\",\n        event_id, user_id, event_type, confidence_score\n    )\n    result = AnalyticsResult(event_id=event_id, persisted=True, confidence=confidence_score)\n    assert result.event_id is not None\n    assert result.persisted is True\n    return result\n# ═══ INTL:END   [id=f0414] record_event_confidence ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 414}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION search_and_rank [id=f1104]\n  INTENT       \"execute multi-stage search pipeline with relevance ranking and result caching\"\n  PRECONDITION query.length > 0\n  PRECONDITION query.length <= 500\n  PRECONDITION limit > 0\n  PRECONDITION limit <= 100\n  POSTCONDITION result.items IS NOT NULL\n  POSTCONDITION result.total_count >= 0\n  READS        documents_table\n  READS        search_index\n  MUTATES      search_cache_table\n  MUTATES      search_analytics_table\n  OBSERVABLE\n\n  SEQUENCE\n    Step 1: Validate and normalize search query\n      normalized_query = normalize_text(query)\n      query_hash = hash_query(normalized_query)\n    \n    Step 2: Check cache for existing results\n      cached = QUERY search_cache_table WHERE query_hash == query_hash LIMIT 1\n      IF cached IS NOT NULL THEN\n        PERSIST search_analytics_table (query_hash: query_hash, cache_hit: true, timestamp: now())\n        RETURN SearchResult(items: cached.items, total_count: cached.total_count, from_cache: true)\n      END IF\n    \n    Step 3: Execute full-text search against index\n      documents = QUERY search_index WHERE MATCH(normalized_query) ORDER BY relevance DESC LIMIT limit\n      IF documents IS EMPTY THEN\n        PERSIST search_analytics_table (query_hash: query_hash, cache_hit: false, results_found: 0, timestamp: now())\n        RETURN SearchResult(items: [], total_count: 0, from_cache: false)\n      END IF\n    \n    Step 4: Enrich and rank results\n      ranked_items = []\n      FOR EACH doc IN documents DO\n        enriched = QUERY documents_table WHERE id == doc.id LIMIT 1\n        ranked_items.APPEND(SearchItem(id: enriched.id, title: enriched.title, score: doc.relevance_score))\n      END FOR\n    \n    Step 5: Persist results to cache\n      PERSIST search_cache_table (query_hash: query_hash, items: ranked_items, total_count: ranked_items.LENGTH, cached_at: now(), expires_at: now()+1h)\n      PERSIST search_analytics_table (query_hash: query_hash, cache_hit: false, results_found: ranked_items.LENGTH, timestamp: now())\n    \n    Step 6: Return final result set\n      result = SearchResult(items: ranked_items, total_count: ranked_items.LENGTH, from_cache: false)\n      RETURN result\n  END SEQUENCE\n\nEND FUNCTION search_and_rank [id=f1104]", "completion": "# ═══ INTL:BEGIN [id=f1104] search_and_rank ═══\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def search_and_rank(query: str, limit: int) -> SearchResult:\n    assert len(query) > 0, \"query must not be empty\"\n    assert len(query) <= 500, \"query must not exceed 500 characters\"\n    assert limit > 0, \"limit must be greater than 0\"\n    assert limit <= 100, \"limit must not exceed 100\"\n    \n    # Step 1: Validate and normalize search query\n    normalized_query = normalize_text(query)\n    query_hash = hash_query(normalized_query)\n    \n    # Step 2: Check cache for existing results\n    cached = await db.query(search_cache_table).filter(query_hash=query_hash).first()\n    if cached is not None:\n        await db.insert(search_analytics_table, query_hash=query_hash, cache_hit=True, timestamp=datetime.utcnow())\n        logger.info(\"search_and_rank: cache_hit query_hash=%s\", query_hash)\n        return SearchResult(items=cached.items, total_count=cached.total_count, from_cache=True)\n    \n    # Step 3: Execute full-text search against index\n    documents = await db.query(search_index).match(normalized_query).order_by(\"-relevance\").limit(limit).all()\n    if not documents:\n        await db.insert(search_analytics_table, query_hash=query_hash, cache_hit=False, results_found=0, timestamp=datetime.utcnow())\n        logger.info(\"search_and_rank: no_results query_hash=%s\", query_hash)\n        return SearchResult(items=[], total_count=0, from_cache=False)\n    \n    # Step 4: Enrich and rank results\n    ranked_items = []\n    for doc in documents:\n        enriched = await db.query(documents_table).filter(id=doc.id).first()\n        ranked_items.append(SearchItem(id=enriched.id, title=enriched.title, score=doc.relevance_score))\n    \n    # Step 5: Persist results to cache\n    await db.insert(search_cache_table, query_hash=query_hash, items=ranked_items, \n                    total_count=len(ranked_items), cached_at=datetime.utcnow(), \n                    expires_at=datetime.utcnow() + timedelta(hours=1))\n    await db.insert(search_analytics_table, query_hash=query_hash, cache_hit=False, \n                    results_found=len(ranked_items), timestamp=datetime.utcnow())\n    \n    # Step 6: Return final result set\n    result = SearchResult(items=ranked_items, total_count=len(ranked_items), from_cache=False)\n    assert result.items is not None\n    assert result.total_count >= 0\n    logger.info(\"search_and_rank: query_hash=%s results=%d\", query_hash, len(ranked_items))\n    return result\n# ═══ INTL:END   [id=f1104] search_and_rank ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 1104}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION get_user_profile [id=f1748]\n  INTENT       \"retrieve user profile with caching to reduce database load\"\n  PRECONDITION user_id > 0\n  PRECONDITION cache_ttl >= 60\n  POSTCONDITION result.user_id IS NOT NULL\n  POSTCONDITION result.email IS NOT NULL\n  READS        users_table\n  MUTATES      cache_stats_table\n  OBSERVABLE\n\n  cached_user = CACHE GET user_profile:{user_id} TTL cache_ttl\n  IF cached_user IS NOT NULL THEN\n    PERSIST cache_stats_table (key: \"user_profile:{user_id}\", hit: true, accessed_at: now())\n    RETURN cached_user\n  END IF\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n  user_profile = UserProfile(user_id: user.id, email: user.email, name: user.name, created_at: user.created_at)\n  CACHE SET user_profile:{user_id} = user_profile TTL cache_ttl\n  PERSIST cache_stats_table (key: \"user_profile:{user_id}\", hit: false, accessed_at: now())\n  RETURN user_profile\nEND FUNCTION get_user_profile [id=f1748]", "completion": "# ═══ INTL:BEGIN [id=f1748] get_user_profile ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def get_user_profile(user_id: int, cache_ttl: int = 3600) -> UserProfile:\n    assert user_id > 0, \"user_id must be greater than 0\"\n    assert cache_ttl >= 60, \"cache_ttl must be at least 60 seconds\"\n    \n    cache_key = f\"user_profile:{user_id}\"\n    cached_user = await cache.get(cache_key)\n    \n    if cached_user is not None:\n        await db.insert(cache_stats_table, \n                       key=cache_key, \n                       hit=True, \n                       accessed_at=datetime.utcnow())\n        logger.info(\"get_user_profile: cache_hit user_id=%s\", user_id)\n        return cached_user\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    user_profile = UserProfile(\n        user_id=user.id,\n        email=user.email,\n        name=user.name,\n        created_at=user.created_at\n    )\n    \n    await cache.set(cache_key, user_profile, ttl=cache_ttl)\n    await db.insert(cache_stats_table,\n                   key=cache_key,\n                   hit=False,\n                   accessed_at=datetime.utcnow())\n    logger.info(\"get_user_profile: cache_miss user_id=%s\", user_id)\n    \n    assert user_profile.user_id is not None\n    assert user_profile.email is not None\n    return user_profile\n# ═══ INTL:END   [id=f1748] get_user_profile ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CACHE GET", "idx": 1748}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION calculate_shipment_cost [id=f1426]\n  INTENT       \"compute final shipping cost with tax and insurance\"\n  PRECONDITION weight > 0\n  PRECONDITION destination_zip.length == 5\n  PRECONDITION insurance_coverage IN [\"none\", \"basic\", \"full\"]\n  POSTCONDITION result.total_cost > 0\n  POSTCONDITION result.breakdown IS NOT NULL\n  READS        shipping_rates_table\n  READS        tax_rules_table\n  MUTATES      cost_calculations_log\n  OBSERVABLE\n\n  base_rate = QUERY shipping_rates_table WHERE weight_min <= weight AND weight_max >= weight LIMIT 1\n  IF base_rate IS NULL THEN FAIL RateNotFoundError(\"no_rate_for_weight\")\n  \n  tax_rate = QUERY tax_rules_table WHERE zip_code == destination_zip LIMIT 1\n  IF tax_rate IS NULL THEN FAIL TaxConfigError(\"invalid_destination_zip\")\n  \n  insurance_cost = 0.0\n  IF insurance_coverage == \"basic\" THEN insurance_cost = base_rate.amount * 0.05\n  IF insurance_coverage == \"full\" THEN insurance_cost = base_rate.amount * 0.12\n  \n  subtotal = base_rate.amount + insurance_cost\n  tax_amount = subtotal * tax_rate.rate\n  total = subtotal + tax_amount\n  \n  PERSIST cost_calculations_log (weight: weight, zip_code: destination_zip, coverage: insurance_coverage, total_cost: total, calculated_at: now())\n  \n  RETURN ShipmentCost(total_cost: total, base_rate: base_rate.amount, insurance_cost: insurance_cost, tax_amount: tax_amount, breakdown: CostBreakdown(subtotal: subtotal, tax_rate: tax_rate.rate))\nEND FUNCTION calculate_shipment_cost [id=f1426]", "completion": "# ═══ INTL:BEGIN [id=f1426] calculate_shipment_cost ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def calculate_shipment_cost(\n    weight: float,\n    destination_zip: str,\n    insurance_coverage: str\n) -> ShipmentCost:\n    assert weight > 0, \"weight must be greater than 0\"\n    assert len(destination_zip) == 5, \"destination_zip must be exactly 5 characters\"\n    assert insurance_coverage in [\"none\", \"basic\", \"full\"], \"insurance_coverage must be one of: none, basic, full\"\n    \n    base_rate = await db.query(shipping_rates_table).filter(\n        weight_min__lte=weight,\n        weight_max__gte=weight\n    ).first()\n    \n    if base_rate is None:\n        raise RateNotFoundError(\"no_rate_for_weight\")\n    \n    tax_rate = await db.query(tax_rules_table).filter(zip_code=destination_zip).first()\n    \n    if tax_rate is None:\n        raise TaxConfigError(\"invalid_destination_zip\")\n    \n    insurance_cost = 0.0\n    if insurance_coverage == \"basic\":\n        insurance_cost = base_rate.amount * 0.05\n    elif insurance_coverage == \"full\":\n        insurance_cost = base_rate.amount * 0.12\n    \n    subtotal = base_rate.amount + insurance_cost\n    tax_amount = subtotal * tax_rate.rate\n    total = subtotal + tax_amount\n    \n    await db.insert(\n        cost_calculations_log,\n        weight=weight,\n        zip_code=destination_zip,\n        coverage=insurance_coverage,\n        total_cost=total,\n        calculated_at=datetime.utcnow()\n    )\n    \n    logger.info(\"shipment_cost_calculated: weight=%s, zip=%s, coverage=%s, total=%s\", \n                weight, destination_zip, insurance_coverage, total)\n    \n    result = ShipmentCost(\n        total_cost=total,\n        base_rate=base_rate.amount,\n        insurance_cost=insurance_cost,\n        tax_amount=tax_amount,\n        breakdown=CostBreakdown(\n            subtotal=subtotal,\n            tax_rate=tax_rate.rate\n        )\n    )\n    \n    assert result.total_cost > 0, \"total_cost must be greater than 0\"\n    assert result.breakdown is not None, \"breakdown must not be null\"\n    \n    return result\n# ═══ INTL:END   [id=f1426] calculate_shipment_cost ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "RETURN", "idx": 1426}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/webhook/process\")\nasync def process_webhook(payload: dict):\n    user_id = payload.get(\"user_id\")\n    event_type = payload.get(\"event_type\")\n    \n    db.execute(\"INSERT INTO events (user_id, type) VALUES (?, ?)\", (user_id, event_type))\n    db.commit()\n    \n    return {\"status\": \"success\"}\nINTL:END\n\nPATCH f2116 [target=f2116]\n  INTENT \"wrap webhook event processing in database transaction with rollback on failure\"\n  ADD BEFORE: db.begin()\n  ADD AFTER db.commit(): db.rollback() on exception\n  WRAP: database operations in try-except-finally block\nEND PATCH f2116", "completion": "INTL:BEGIN\n@app.post(\"/webhook/process\")\nasync def process_webhook(payload: dict):\n    user_id = payload.get(\"user_id\")\n    event_type = payload.get(\"event_type\")\n    \n    try:\n        db.begin()\n        db.execute(\"INSERT INTO events (user_id, type) VALUES (?, ?)\", (user_id, event_type))\n        db.commit()\n    except Exception as e:\n        db.rollback()\n        raise e\n    \n    return {\"status\": \"success\"}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 2116}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_role [id=f2438]\n  INTENT       \"assign a role to a user and cache the updated permissions\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION role_name.length > 0\n  PRECONDITION role_name IN [\"admin\", \"editor\", \"viewer\"]\n  POSTCONDITION result.success IS TRUE\n  READS        users_table, roles_table\n  MUTATES      user_roles_table, permissions_cache\n  OBSERVABLE\n\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL PermissionError(\"user_not_found\")\n  role = QUERY roles_table WHERE name == role_name LIMIT 1\n  IF role IS NULL THEN FAIL PermissionError(\"role_not_found\")\n  PERSIST user_roles_table (user_id: user_id, role_id: role.id, assigned_at: now())\n  perms = QUERY roles_table WHERE id == role.id SELECT permissions\n  CACHE SET permissions_cache (user_id: user_id, permissions: perms, ttl: 3600)\n  RETURN GrantResult(success: TRUE, role_id: role.id)\nEND FUNCTION grant_role [id=f2438]", "completion": "# ═══ INTL:BEGIN [id=f2438] grant_role ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def grant_role(user_id: str, role_name: str) -> GrantResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(role_name) > 0, \"role_name must not be empty\"\n    assert role_name in [\"admin\", \"editor\", \"viewer\"], \"role_name must be one of: admin, editor, viewer\"\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise PermissionError(\"user_not_found\")\n    \n    role = await db.query(roles_table).filter(name=role_name).first()\n    if role is None:\n        raise PermissionError(\"role_not_found\")\n    \n    await db.insert(user_roles_table, user_id=user_id, role_id=role.id, \n                    assigned_at=datetime.utcnow())\n    \n    perms = await db.query(roles_table).filter(id=role.id).select(\"permissions\").first()\n    \n    await cache.set(\n        key=f\"permissions:{user_id}\",\n        value={\"user_id\": user_id, \"permissions\": perms},\n        ttl=3600\n    )\n    \n    logger.info(\"grant_role: user_id=%s role_id=%s role_name=%s\", user_id, role.id, role_name)\n    result = GrantResult(success=True, role_id=role.id)\n    assert result.success is True\n    return result\n# ═══ INTL:END   [id=f2438] grant_role ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CACHE SET", "idx": 2438}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/api/keys\")\ndef create_api_key(user_id: str, key_data: dict):\n    key = generate_key()\n    return {\n        \"api_key\": key,\n        \"user_id\": user_id,\n        \"created_at\": datetime.utcnow()\n    }\nINTL:END\n\nPATCH f2760 [target=f2760]\n  INTENT \"persist generated api key to database\"\n  ADD PERSIST: db.save_api_key(user_id, key, datetime.utcnow())\nEND PATCH f2760", "completion": "INTL:BEGIN\n@app.post(\"/api/keys\")\ndef create_api_key(user_id: str, key_data: dict):\n    key = generate_key()\n    db.save_api_key(user_id, key, datetime.utcnow())\n    return {\n        \"api_key\": key,\n        \"user_id\": user_id,\n        \"created_at\": datetime.utcnow()\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 2760}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/login\")\nasync def login(credentials: LoginRequest):\n    user = authenticate_user(credentials.username, credentials.password)\n    if not user:\n        raise HTTPException(status_code=401, detail=\"Invalid credentials\")\n    token = create_access_token(user.id)\n    return {\"access_token\": token, \"token_type\": \"bearer\"}\nINTL:END\n\nPATCH f3128 [target=f3128]\n  INTENT \"add observable logging and metrics tracking to authentication endpoint\"\n  ADD BEFORE: logger.info(f\"Login attempt for user: {credentials.username}\")\n  ADD AFTER authenticate_user: logger.warning(f\"Failed login attempt for: {credentials.username}\") if not user\n  ADD BEFORE return: metrics.increment(\"auth.login.success\", tags=[f\"user_id:{user.id}\"])\nEND PATCH f3128", "completion": "INTL:BEGIN\n@app.post(\"/login\")\nasync def login(credentials: LoginRequest):\n    logger.info(f\"Login attempt for user: {credentials.username}\")\n    user = authenticate_user(credentials.username, credentials.password)\n    if not user:\n        logger.warning(f\"Failed login attempt for: {credentials.username}\")\n        raise HTTPException(status_code=401, detail=\"Invalid credentials\")\n    token = create_access_token(user.id)\n    metrics.increment(\"auth.login.success\", tags=[f\"user_id:{user.id}\"])\n    return {\"access_token\": token, \"token_type\": \"bearer\"}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 3128}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION bulk_update_inventory [id=f0047]\n  INTENT       \"update stock levels for multiple products in batch\"\n  PRECONDITION product_ids.length > 0\n  PRECONDITION product_ids.length <= 1000\n  PRECONDITION adjustments.length == product_ids.length\n  POSTCONDITION result.updated_count > 0\n  READS        products_table\n  MUTATES      products_table\n  MUTATES      inventory_log_table\n  OBSERVABLE\n\n  updated_count = 0\n  LOOP product_id IN product_ids WITH adjustment IN adjustments DO\n    product = QUERY products_table WHERE id == product_id LIMIT 1\n    IF product IS NULL THEN CONTINUE\n    IF product.stock_level + adjustment < 0 THEN CONTINUE\n    new_stock = product.stock_level + adjustment\n    UPDATE products_table SET stock_level = new_stock WHERE id == product_id\n    PERSIST inventory_log_table (product_id: product_id, adjustment: adjustment, timestamp: now())\n    updated_count = updated_count + 1\n  END LOOP\n  \n  RETURN BulkUpdateResult(updated_count: updated_count)\nEND FUNCTION bulk_update_inventory [id=f0047]", "completion": "# ═══ INTL:BEGIN [id=f0047] bulk_update_inventory ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def bulk_update_inventory(product_ids: List[str], adjustments: List[int]) -> BulkUpdateResult:\n    assert len(product_ids) > 0, \"product_ids must not be empty\"\n    assert len(product_ids) <= 1000, \"product_ids must not exceed 1000 items\"\n    assert len(adjustments) == len(product_ids), \"adjustments length must match product_ids length\"\n    \n    updated_count = 0\n    \n    for product_id, adjustment in zip(product_ids, adjustments):\n        product = await db.query(products_table).filter(id=product_id).first()\n        if product is None:\n            continue\n        if product.stock_level + adjustment < 0:\n            continue\n        new_stock = product.stock_level + adjustment\n        await db.update(products_table).filter(id=product_id).set(stock_level=new_stock)\n        await db.insert(inventory_log_table, \n                       product_id=product_id, \n                       adjustment=adjustment, \n                       timestamp=datetime.utcnow())\n        updated_count += 1\n    \n    logger.info(\"bulk_update_inventory: updated_count=%d, total_processed=%d\", updated_count, len(product_ids))\n    result = BulkUpdateResult(updated_count=updated_count)\n    assert result.updated_count > 0\n    return result\n# ═══ INTL:END   [id=f0047] bulk_update_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 47}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    contents = await file.read()\n    file_size = len(contents)\n    file_hash = hashlib.md5(contents).hexdigest()\n    return {\n        \"filename\": file.filename,\n        \"size\": file_size,\n        \"hash\": file_hash\n    }\nINTL:END\n\nPATCH f1105 [target=f1105]\n  INTENT \"aggregate file metadata into a structured response object\"\n  ADD BEFORE: file_metadata = {}\n  AGGREGATE: {filename, size, hash} INTO file_metadata\n  RETURN: file_metadata instead of dict literal\nEND PATCH f1105", "completion": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    contents = await file.read()\n    file_size = len(contents)\n    file_hash = hashlib.md5(contents).hexdigest()\n    file_metadata = {\n        \"filename\": file.filename,\n        \"size\": file_size,\n        \"hash\": file_hash\n    }\n    return file_metadata\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "AGGREGATE", "idx": 1105}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/analytics/events\")\nasync def get_events(user_id: str, limit: int = 100):\n    try:\n        events = await db.query_events(user_id, limit)\n        return {\"status\": \"success\", \"data\": events}\n    except DatabaseError as e:\n        logger.error(f\"Query failed: {e}\")\n        return {\"status\": \"error\", \"message\": \"Database unavailable\"}\nINTL:END\n\nPATCH f1427 [target=f1427]\n  INTENT \"add fallback caching layer when database is unavailable\"\n  FALLBACK: use_cache_fallback(user_id, limit)\n  ADD AFTER: except DatabaseError as e:\nEND PATCH f1427", "completion": "INTL:BEGIN\n@app.get(\"/analytics/events\")\nasync def get_events(user_id: str, limit: int = 100):\n    try:\n        events = await db.query_events(user_id, limit)\n        return {\"status\": \"success\", \"data\": events}\n    except DatabaseError as e:\n        logger.error(f\"Query failed: {e}\")\n        events = await use_cache_fallback(user_id, limit)\n        return {\"status\": \"success\", \"data\": events, \"cached\": True}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 1427}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION generate_sales_report [id=f1749]\n  INTENT       \"generate aggregated sales report with caching for performance\"\n  PRECONDITION region.length > 0\n  PRECONDITION start_date < end_date\n  PRECONDITION cache_ttl_seconds > 0\n  POSTCONDITION result.total_sales >= 0\n  READS        orders_table\n  READS        products_table\n  MUTATES      report_cache_table\n  OBSERVABLE\n\n  cache_key = CONCAT(\"sales_report:\", region, \":\", start_date, \":\", end_date)\n  cached_result = CACHE GET cache_key\n  IF cached_result IS NOT NULL THEN RETURN cached_result\n  \n  orders = QUERY orders_table WHERE region == region AND order_date >= start_date AND order_date <= end_date\n  total_sales = SUM orders.amount\n  product_count = COUNT DISTINCT orders.product_id\n  \n  report = SalesReport(\n    region: region,\n    total_sales: total_sales,\n    product_count: product_count,\n    generated_at: now()\n  )\n  \n  PERSIST report_cache_table (cache_key: cache_key, data: report, expires_at: now()+cache_ttl_seconds)\n  RETURN report\nEND FUNCTION generate_sales_report [id=f1749]", "completion": "# ═══ INTL:BEGIN [id=f1749] generate_sales_report ═══\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Optional\n\nlogger = logging.getLogger(__name__)\n\nasync def generate_sales_report(\n    region: str,\n    start_date: datetime,\n    end_date: datetime,\n    cache_ttl_seconds: int\n) -> SalesReport:\n    assert len(region) > 0, \"region must not be empty\"\n    assert start_date < end_date, \"start_date must be before end_date\"\n    assert cache_ttl_seconds > 0, \"cache_ttl_seconds must be positive\"\n    \n    cache_key = f\"sales_report:{region}:{start_date.isoformat()}:{end_date.isoformat()}\"\n    \n    cached_result = await cache_store.get(cache_key)\n    if cached_result is not None:\n        logger.info(\"generate_sales_report: cache_hit cache_key=%s\", cache_key)\n        return cached_result\n    \n    orders = await db.query(orders_table).filter(\n        region=region,\n        order_date__gte=start_date,\n        order_date__lte=end_date\n    ).all()\n    \n    total_sales = sum(order.amount for order in orders)\n    product_ids = set(order.product_id for order in orders)\n    product_count = len(product_ids)\n    \n    report = SalesReport(\n        region=region,\n        total_sales=total_sales,\n        product_count=product_count,\n        generated_at=datetime.utcnow()\n    )\n    \n    expires_at = datetime.utcnow() + timedelta(seconds=cache_ttl_seconds)\n    await db.insert(\n        report_cache_table,\n        cache_key=cache_key,\n        data=report.dict(),\n        expires_at=expires_at\n    )\n    \n    logger.info(\"generate_sales_report: cache_miss cache_key=%s region=%s total_sales=%f\", \n                cache_key, region, total_sales)\n    \n    assert report.total_sales >= 0, \"total_sales must be non-negative\"\n    return report\n# ═══ INTL:END   [id=f1749] generate_sales_report ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CACHE GET", "idx": 1749}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, user_id: int):\n    db_review = Review(\n        user_id=user_id,\n        rating=review.rating,\n        text=review.text\n    )\n    db.session.add(db_review)\n    db.session.commit()\n    return {\"id\": db_review.id, \"status\": \"created\"}\nINTL:END\n\nPATCH f2439 [target=f2439]\n  INTENT \"add rate limiting to the function\"\n  ADD BEFORE: rate_limit_check(user_id)\n  ADD AFTER_COMMIT: log_review_event(db_review.id, user_id)\nEND PATCH f2439", "completion": "INTL:BEGIN\n@app.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, user_id: int):\n    rate_limit_check(user_id)\n    db_review = Review(\n        user_id=user_id,\n        rating=review.rating,\n        text=review.text\n    )\n    db.session.add(db_review)\n    db.session.commit()\n    log_review_event(db_review.id, user_id)\n    return {\"id\": db_review.id, \"status\": \"created\"}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 2439}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_inventory [id=f2117]\n  INTENT       \"receive shipment and update stock levels for multiple items\"\n  PRECONDITION shipment_id.length > 0\n  PRECONDITION items.length > 0\n  PRECONDITION warehouse_id.length > 0\n  POSTCONDITION result.items_updated > 0\n  READS        inventory_table\n  READS        shipments_table\n  MUTATES      inventory_table\n  MUTATES      shipment_events_table\n  OBSERVABLE\n\n  shipment = QUERY shipments_table WHERE id == shipment_id LIMIT 1\n  IF shipment IS NULL THEN FAIL ShipmentError(\"shipment_not_found\")\n  IF shipment.status != \"in_transit\" THEN FAIL ShipmentError(\"invalid_shipment_status\")\n  \n  updated_count = 0\n  FOR item IN items DO\n    stock_record = QUERY inventory_table WHERE sku == item.sku AND warehouse_id == warehouse_id LIMIT 1\n    IF stock_record IS NULL THEN\n      PERSIST inventory_table (sku: item.sku, warehouse_id: warehouse_id, quantity: item.quantity, last_updated: now())\n    ELSE\n      UPDATE inventory_table SET quantity = stock_record.quantity + item.quantity WHERE sku == item.sku AND warehouse_id == warehouse_id\n    END IF\n    updated_count = updated_count + 1\n  END FOR\n  \n  PERSIST shipment_events_table (shipment_id: shipment_id, event_type: \"restocked\", timestamp: now(), warehouse_id: warehouse_id)\n  RETURN RestockResult(items_updated: updated_count, shipment_id: shipment_id)\nEND FUNCTION restock_inventory [id=f2117]", "completion": "# ═══ INTL:BEGIN [id=f2117] restock_inventory ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_inventory(shipment_id: str, items: List[dict], warehouse_id: str) -> RestockResult:\n    assert len(shipment_id) > 0, \"shipment_id must not be empty\"\n    assert len(items) > 0, \"items list must not be empty\"\n    assert len(warehouse_id) > 0, \"warehouse_id must not be empty\"\n    \n    shipment = await db.query(shipments_table).filter(id=shipment_id).first()\n    if shipment is None:\n        raise ShipmentError(\"shipment_not_found\")\n    if shipment.status != \"in_transit\":\n        raise ShipmentError(\"invalid_shipment_status\")\n    \n    updated_count = 0\n    for item in items:\n        stock_record = await db.query(inventory_table).filter(\n            sku=item[\"sku\"], \n            warehouse_id=warehouse_id\n        ).first()\n        \n        if stock_record is None:\n            await db.insert(\n                inventory_table,\n                sku=item[\"sku\"],\n                warehouse_id=warehouse_id,\n                quantity=item[\"quantity\"],\n                last_updated=datetime.utcnow()\n            )\n        else:\n            await db.update(\n                inventory_table,\n                where={\"sku\": item[\"sku\"], \"warehouse_id\": warehouse_id},\n                values={\"quantity\": stock_record.quantity + item[\"quantity\"]}\n            )\n        updated_count += 1\n    \n    await db.insert(\n        shipment_events_table,\n        shipment_id=shipment_id,\n        event_type=\"restocked\",\n        timestamp=datetime.utcnow(),\n        warehouse_id=warehouse_id\n    )\n    \n    result = RestockResult(items_updated=updated_count, shipment_id=shipment_id)\n    logger.info(\"restock_inventory: shipment_id=%s, warehouse_id=%s, items_updated=%d\", \n                shipment_id, warehouse_id, updated_count)\n    assert result.items_updated > 0, \"result must have updated at least one item\"\n    return result\n# ═══ INTL:END   [id=f2117] restock_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 2117}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_inventory [id=f0048]\n  INTENT       \"replenish stock for a product and log the transaction\"\n  PRECONDITION product_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION warehouse_id.length > 0\n  POSTCONDITION result.stock_updated IS NOT NULL\n  READS        products_table\n  MUTATES      inventory_table, audit_log_table\n  OBSERVABLE\n\n  product = QUERY products_table WHERE id == product_id LIMIT 1\n  FALLBACK\n    CASE product IS NULL\n      FAIL NotFoundError(\"product_not_found\")\n    CASE product.status == \"discontinued\"\n      WARN \"product_discontinued\" WITH default_action=log_warning\n  END FALLBACK\n  \n  current_stock = product.stock_level\n  new_stock = current_stock + quantity\n  PERSIST inventory_table (product_id: product_id, stock_level: new_stock, warehouse_id: warehouse_id, updated_at: now())\n  PERSIST audit_log_table (product_id: product_id, action: \"restock\", quantity: quantity, warehouse_id: warehouse_id, timestamp: now())\n  RETURN StockUpdate(stock_updated: new_stock, previous_stock: current_stock)\nEND FUNCTION restock_inventory [id=f0048]", "completion": "# ═══ INTL:BEGIN [id=f0048] restock_inventory ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_inventory(product_id: str, quantity: int, warehouse_id: str) -> StockUpdate:\n    assert len(product_id) > 0, \"product_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    assert len(warehouse_id) > 0, \"warehouse_id must not be empty\"\n    \n    product = await db.query(products_table).filter(id=product_id).first()\n    \n    if product is None:\n        raise NotFoundError(\"product_not_found\")\n    \n    if product.status == \"discontinued\":\n        logger.warning(\"restock_inventory: product_discontinued, product_id=%s\", product_id)\n    \n    current_stock = product.stock_level\n    new_stock = current_stock + quantity\n    \n    await db.insert(inventory_table, product_id=product_id, stock_level=new_stock,\n                    warehouse_id=warehouse_id, updated_at=datetime.utcnow())\n    await db.insert(audit_log_table, product_id=product_id, action=\"restock\",\n                    quantity=quantity, warehouse_id=warehouse_id, timestamp=datetime.utcnow())\n    \n    logger.info(\"restock_inventory: product_id=%s, quantity=%d, new_stock=%d, warehouse_id=%s\",\n                product_id, quantity, new_stock, warehouse_id)\n    \n    result = StockUpdate(stock_updated=new_stock, previous_stock=current_stock)\n    assert result.stock_updated is not None\n    return result\n# ═══ INTL:END   [id=f0048] restock_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 48}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION store_upload_metadata [id=f3129]\n  INTENT       \"persist file upload metadata and cache for fast retrieval\"\n  PRECONDITION file_id.length > 0\n  PRECONDITION file_size > 0\n  PRECONDITION file_size <= 5368709120\n  PRECONDITION user_id > 0\n  POSTCONDITION result.cached IS TRUE\n  READS        users_table\n  MUTATES      uploads_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL AuthError(\"user_not_found\")\n  IF user.storage_quota_bytes < file_size THEN FAIL QuotaError(\"insufficient_storage\")\n  \n  upload_record = (file_id: file_id, user_id: user_id, file_size: file_size, uploaded_at: now(), status: \"completed\")\n  PERSIST uploads_table upload_record\n  \n  CACHE SET upload_metadata:file_id WITH upload_record EXPIRE 3600\n  CACHE SET user_uploads:user_id WITH LIST_APPEND upload_record EXPIRE 7200\n  \n  RETURN UploadResult(cached: TRUE, file_id: file_id, size_bytes: file_size)\nEND FUNCTION store_upload_metadata [id=f3129]", "completion": "# ═══ INTL:BEGIN [id=f3129] store_upload_metadata ═══\nimport logging\nfrom datetime import datetime, timedelta\n\nlogger = logging.getLogger(__name__)\n\nasync def store_upload_metadata(\n    file_id: str,\n    file_size: int,\n    user_id: int,\n    cache_client\n) -> UploadResult:\n    assert len(file_id) > 0, \"file_id must not be empty\"\n    assert file_size > 0, \"file_size must be greater than 0\"\n    assert file_size <= 5368709120, \"file_size must not exceed 5GB\"\n    assert user_id > 0, \"user_id must be a positive integer\"\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise AuthError(\"user_not_found\")\n    if user.storage_quota_bytes < file_size:\n        raise QuotaError(\"insufficient_storage\")\n    \n    upload_record = {\n        \"file_id\": file_id,\n        \"user_id\": user_id,\n        \"file_size\": file_size,\n        \"uploaded_at\": datetime.utcnow().isoformat(),\n        \"status\": \"completed\"\n    }\n    \n    await db.insert(uploads_table, **upload_record)\n    \n    await cache_client.setex(\n        f\"upload_metadata:{file_id}\",\n        timedelta(seconds=3600),\n        upload_record\n    )\n    \n    user_uploads_key = f\"user_uploads:{user_id}\"\n    await cache_client.lpush(user_uploads_key, upload_record)\n    await cache_client.expire(user_uploads_key, timedelta(seconds=7200))\n    \n    logger.info(\n        \"store_upload_metadata: file_id=%s user_id=%s size_bytes=%d\",\n        file_id, user_id, file_size\n    )\n    \n    result = UploadResult(cached=True, file_id=file_id, size_bytes=file_size)\n    assert result.cached is True\n    return result\n# ═══ INTL:END   [id=f3129] store_upload_metadata ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CACHE SET", "idx": 3129}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_item [id=f0416]\n  INTENT       \"replenish inventory stock with confidence-based validation\"\n  PRECONDITION item_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION confidence_score >= 0.7\n  POSTCONDITION result.status == \"success\"\n  READS        inventory_table\n  MUTATES      inventory_table, restock_log_table\n  OBSERVABLE\n\n  item = QUERY inventory_table WHERE item_id == item_id LIMIT 1\n  IF item IS NULL THEN FAIL ItemNotFoundError(\"item_not_found\")\n  \n  CONFIDENCE stock_confidence = calculate_confidence(item.last_audit_date, item.variance_rate)\n  IF stock_confidence < confidence_score THEN FAIL ConfidenceError(\"insufficient_confidence\")\n  \n  new_stock = item.current_stock + quantity\n  UPDATE inventory_table SET current_stock = new_stock, last_updated = now() WHERE item_id == item_id\n  PERSIST restock_log_table (item_id: item_id, quantity: quantity, timestamp: now(), confidence: stock_confidence)\n  \n  RETURN RestockResult(status: \"success\", new_stock: new_stock, confidence: stock_confidence)\nEND FUNCTION restock_item [id=f0416]", "completion": "# ═══ INTL:BEGIN [id=f0416] restock_item ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_item(item_id: str, quantity: int, confidence_score: float) -> RestockResult:\n    assert len(item_id) > 0, \"item_id must not be empty\"\n    assert quantity > 0, \"quantity must be positive\"\n    assert confidence_score >= 0.7, \"confidence_score must be at least 0.7\"\n    \n    item = await db.query(inventory_table).filter(item_id=item_id).first()\n    if item is None:\n        raise ItemNotFoundError(\"item_not_found\")\n    \n    stock_confidence = calculate_confidence(item.last_audit_date, item.variance_rate)\n    if stock_confidence < confidence_score:\n        raise ConfidenceError(\"insufficient_confidence\")\n    \n    new_stock = item.current_stock + quantity\n    await db.update(inventory_table).filter(item_id=item_id).set(\n        current_stock=new_stock,\n        last_updated=datetime.utcnow()\n    )\n    await db.insert(restock_log_table, item_id=item_id, quantity=quantity,\n                    timestamp=datetime.utcnow(), confidence=stock_confidence)\n    \n    logger.info(\"restock_item: item_id=%s quantity=%d confidence=%.2f\", item_id, quantity, stock_confidence)\n    result = RestockResult(status=\"success\", new_stock=new_stock, confidence=stock_confidence)\n    assert result.status == \"success\"\n    return result\n# ═══ INTL:END   [id=f0416] restock_item ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 416}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION calculate_shipping_cost [id=f0738]\n  INTENT       \"calculate and cache shipping cost based on origin, destination, and weight\"\n  PRECONDITION origin.length > 0\n  PRECONDITION destination.length > 0\n  PRECONDITION weight_kg > 0\n  POSTCONDITION result.cost >= 0\n  READS        shipping_rates_table\n  MUTATES      shipping_cache_table\n  OBSERVABLE\n\n  cache_key = CONCAT(origin, \":\", destination, \":\", weight_kg)\n  cached = CACHE GET cache_key FROM shipping_cache_table\n  IF cached IS NOT NULL THEN RETURN ShippingQuote(cost: cached.cost, cached: TRUE)\n  \n  rate = QUERY shipping_rates_table WHERE from_zone == origin AND to_zone == destination LIMIT 1\n  IF rate IS NULL THEN FAIL ShippingError(\"route_not_found\")\n  \n  base_cost = rate.base_price\n  weight_surcharge = weight_kg * rate.per_kg_rate\n  total_cost = base_cost + weight_surcharge\n  \n  PERSIST shipping_cache_table (cache_key: cache_key, origin: origin, destination: destination, weight_kg: weight_kg, cost: total_cost, created_at: now())\n  RETURN ShippingQuote(cost: total_cost, cached: FALSE)\nEND FUNCTION calculate_shipping_cost [id=f0738]", "completion": "# ═══ INTL:BEGIN [id=f0738] calculate_shipping_cost ═══\nimport logging\nfrom datetime import datetime\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def calculate_shipping_cost(origin: str, destination: str, weight_kg: float) -> ShippingQuote:\n    assert len(origin) > 0, \"origin must not be empty\"\n    assert len(destination) > 0, \"destination must not be empty\"\n    assert weight_kg > 0, \"weight_kg must be greater than 0\"\n    \n    cache_key = f\"{origin}:{destination}:{weight_kg}\"\n    \n    cached_record = await db.query(shipping_cache_table).filter(cache_key=cache_key).first()\n    if cached_record is not None:\n        logger.info(\"calculate_shipping_cost: cache_hit key=%s cost=%.2f\", cache_key, cached_record.cost)\n        result = ShippingQuote(cost=cached_record.cost, cached=True)\n        assert result.cost >= 0\n        return result\n    \n    rate = await db.query(shipping_rates_table).filter(\n        from_zone=origin,\n        to_zone=destination\n    ).first()\n    \n    if rate is None:\n        raise ShippingError(\"route_not_found\")\n    \n    base_cost = rate.base_price\n    weight_surcharge = weight_kg * rate.per_kg_rate\n    total_cost = base_cost + weight_surcharge\n    \n    await db.insert(\n        shipping_cache_table,\n        cache_key=cache_key,\n        origin=origin,\n        destination=destination,\n        weight_kg=weight_kg,\n        cost=total_cost,\n        created_at=datetime.utcnow()\n    )\n    \n    logger.info(\"calculate_shipping_cost: cache_miss key=%s cost=%.2f origin=%s destination=%s weight_kg=%.2f\", \n                cache_key, total_cost, origin, destination, weight_kg)\n    result = ShippingQuote(cost=total_cost, cached=False)\n    assert result.cost >= 0\n    return result\n# ═══ INTL:END   [id=f0738] calculate_shipping_cost ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CACHE GET", "idx": 738}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/search\")\nasync def search(q: str, limit: int = 10):\n    results = []\n    for item in database.query(q):\n        results.append(item)\n        if len(results) >= limit:\n            break\n    return {\"query\": q, \"results\": results}\nINTL:END\n\nPATCH f1106 [target=f1106]\n  INTENT \"add observable instrumentation to track search performance metrics\"\n  ADD BEFORE: logger.info(f\"search_started: query={q}\")\n  ADD AFTER: logger.info(f\"search_completed: query={q}, count={len(results)}, duration_ms={elapsed_ms}\")\nEND PATCH f1106", "completion": "INTL:BEGIN\n@app.get(\"/search\")\nasync def search(q: str, limit: int = 10):\n    import time\n    start_time = time.time()\n    logger.info(f\"search_started: query={q}\")\n    results = []\n    for item in database.query(q):\n        results.append(item)\n        if len(results) >= limit:\n            break\n    elapsed_ms = (time.time() - start_time) * 1000\n    logger.info(f\"search_completed: query={q}, count={len(results)}, duration_ms={elapsed_ms}\")\n    return {\"query\": q, \"results\": results}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 1106}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    contents = await file.read()\n    filename = file.filename\n    with open(f\"uploads/{filename}\", \"wb\") as f:\n        f.write(contents)\n    return {\"filename\": filename, \"size\": len(contents)}\nINTL:END\n\nPATCH f2440 [target=f2440]\n  INTENT \"sanitize and validate uploaded filename before storage\"\n  TRANSFORM filename: use secure_filename() wrapper\nEND PATCH f2440", "completion": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    contents = await file.read()\n    filename = secure_filename(file.filename)\n    with open(f\"uploads/{filename}\", \"wb\") as f:\n        f.write(contents)\n    return {\"filename\": filename, \"size\": len(contents)}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 2440}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@app.post(\"/users\")\nasync def create_user(user: UserCreate):\n    new_user = User(**user.dict())\n    db.add(new_user)\n    db.commit()\n    return new_user\nINTL:END\n\nPATCH f2762 [target=f2762]\n  INTENT \"add rate limiting to the sequence of user endpoints\"\n  ADD BEFORE: rate_limit_check(user_id) in get_user\n  ADD BEFORE: rate_limit_check(\"create_user\") in create_user\nEND PATCH f2762", "completion": "INTL:BEGIN\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    rate_limit_check(user_id)\n    user = db.query(User).filter(User.id == user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@app.post(\"/users\")\nasync def create_user(user: UserCreate):\n    rate_limit_check(\"create_user\")\n    new_user = User(**user.dict())\n    db.add(new_user)\n    db.commit()\n    return new_user\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 2762}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_shipment [id=f2118]\n  INTENT       \"atomically update shipment status and allocate inventory\"\n  PRECONDITION shipment_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION warehouse_id IS NOT NULL\n  POSTCONDITION result.shipment_status == \"allocated\"\n  POSTCONDITION result.tracking_number IS NOT NULL\n  READS        shipments_table, inventory_table\n  MUTATES      shipments_table, inventory_table, audit_log_table\n  OBSERVABLE\n\n  TRANSACTION BEGIN\n    shipment = QUERY shipments_table WHERE id == shipment_id LIMIT 1\n    IF shipment IS NULL THEN FAIL ShippingError(\"shipment_not_found\")\n    IF shipment.status != \"pending\" THEN FAIL ShippingError(\"invalid_shipment_state\")\n    \n    inventory = QUERY inventory_table WHERE warehouse_id == warehouse_id AND shipment_id == shipment_id LIMIT 1\n    IF inventory IS NULL THEN FAIL ShippingError(\"insufficient_inventory\")\n    IF inventory.available_quantity < quantity THEN FAIL ShippingError(\"quantity_unavailable\")\n    \n    tracking_number = generate_tracking_number(warehouse_id)\n    MUTATE shipments_table SET status = \"allocated\", tracking_number = tracking_number, allocated_at = now()\n    MUTATE inventory_table SET available_quantity = inventory.available_quantity - quantity, allocated_quantity = allocated_quantity + quantity\n    PERSIST audit_log_table (shipment_id: shipment_id, action: \"allocated\", warehouse_id: warehouse_id, quantity: quantity, timestamp: now())\n  TRANSACTION END\n  \n  RETURN ShipmentAllocation(shipment_id: shipment_id, tracking_number: tracking_number, shipment_status: \"allocated\")\nEND FUNCTION process_shipment [id=f2118]", "completion": "# ═══ INTL:BEGIN [id=f2118] process_shipment ═══\nimport logging\nfrom datetime import datetime\nfrom contextlib import asynccontextmanager\n\nlogger = logging.getLogger(__name__)\n\nasync def process_shipment(shipment_id: str, quantity: int, warehouse_id: str) -> ShipmentAllocation:\n    assert len(shipment_id) > 0, \"shipment_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    assert warehouse_id is not None, \"warehouse_id must not be null\"\n    \n    async with db.transaction():\n        shipment = await db.query(shipments_table).filter(id=shipment_id).first()\n        if shipment is None:\n            raise ShippingError(\"shipment_not_found\")\n        if shipment.status != \"pending\":\n            raise ShippingError(\"invalid_shipment_state\")\n        \n        inventory = await db.query(inventory_table).filter(\n            warehouse_id=warehouse_id,\n            shipment_id=shipment_id\n        ).first()\n        if inventory is None:\n            raise ShippingError(\"insufficient_inventory\")\n        if inventory.available_quantity < quantity:\n            raise ShippingError(\"quantity_unavailable\")\n        \n        tracking_number = generate_tracking_number(warehouse_id)\n        await db.update(\n            shipments_table,\n            where={\"id\": shipment_id},\n            values={\n                \"status\": \"allocated\",\n                \"tracking_number\": tracking_number,\n                \"allocated_at\": datetime.utcnow()\n            }\n        )\n        await db.update(\n            inventory_table,\n            where={\"warehouse_id\": warehouse_id, \"shipment_id\": shipment_id},\n            values={\n                \"available_quantity\": inventory.available_quantity - quantity,\n                \"allocated_quantity\": inventory.allocated_quantity + quantity\n            }\n        )\n        await db.insert(\n            audit_log_table,\n            shipment_id=shipment_id,\n            action=\"allocated\",\n            warehouse_id=warehouse_id,\n            quantity=quantity,\n            timestamp=datetime.utcnow()\n        )\n        \n        logger.info(\"process_shipment: shipment_id=%s tracking=%s quantity=%d warehouse=%s\",\n                    shipment_id, tracking_number, quantity, warehouse_id)\n    \n    result = ShipmentAllocation(\n        shipment_id=shipment_id,\n        tracking_number=tracking_number,\n        shipment_status=\"allocated\"\n    )\n    assert result.shipment_status == \"allocated\"\n    assert result.tracking_number is not None\n    return result\n# ═══ INTL:END   [id=f2118] process_shipment ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 2118}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_expired_sessions [id=f0049]\n  INTENT       \"scan and revoke all expired session tokens in batch\"\n  PRECONDITION batch_size > 0\n  PRECONDITION batch_size <= 1000\n  POSTCONDITION result.revoked_count >= 0\n  READS        sessions_table\n  MUTATES      sessions_table\n  OBSERVABLE\n\n  expired_sessions = QUERY sessions_table WHERE expires_at < now() LIMIT 10000\n  revoked_count = 0\n  LOOP session IN expired_sessions DO\n    IF session.status == \"active\" THEN\n      PERSIST sessions_table (id: session.id, status: \"revoked\", revoked_at: now())\n      revoked_count = revoked_count + 1\n      IF revoked_count % batch_size == 0 THEN\n        LOG \"batch checkpoint: revoked \" + revoked_count + \" sessions\"\n      END IF\n    END IF\n  END LOOP\n  LOG \"session revocation complete: total revoked=\" + revoked_count\n  RETURN RevocationResult(revoked_count: revoked_count)\nEND FUNCTION revoke_expired_sessions [id=f0049]", "completion": "# ═══ INTL:BEGIN [id=f0049] revoke_expired_sessions ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_expired_sessions(batch_size: int) -> RevocationResult:\n    assert batch_size > 0, \"batch_size must be greater than 0\"\n    assert batch_size <= 1000, \"batch_size must not exceed 1000\"\n    \n    expired_sessions = await db.query(sessions_table).filter(\n        expires_at__lt=datetime.utcnow()\n    ).limit(10000).all()\n    \n    revoked_count = 0\n    for session in expired_sessions:\n        if session.status == \"active\":\n            await db.update(\n                sessions_table,\n                where={\"id\": session.id},\n                data={\"status\": \"revoked\", \"revoked_at\": datetime.utcnow()}\n            )\n            revoked_count += 1\n            if revoked_count % batch_size == 0:\n                logger.info(\"batch checkpoint: revoked %d sessions\", revoked_count)\n    \n    logger.info(\"session revocation complete: total revoked=%d\", revoked_count)\n    result = RevocationResult(revoked_count=revoked_count)\n    assert result.revoked_count >= 0\n    return result\n# ═══ INTL:END   [id=f0049] revoke_expired_sessions ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 49}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_webhook [id=f3130]\n  INTENT       \"receive, validate, and transform incoming webhook payload into normalized event record\"\n  PRECONDITION payload IS NOT NULL\n  PRECONDITION signature.length > 0\n  PRECONDITION event_type IN (\"order.created\", \"order.updated\", \"payment.completed\")\n  POSTCONDITION result.event_id IS NOT NULL\n  READS        webhook_secrets\n  MUTATES      webhook_events_table\n  OBSERVABLE\n\n  TRANSFORM payload AS raw_payload INTO normalized_event {\n    timestamp: now(),\n    event_type: raw_payload.type,\n    source_id: raw_payload.source,\n    data: extract_nested_data(raw_payload.body),\n    checksum: compute_hash(raw_payload)\n  }\n  \n  secret = QUERY webhook_secrets WHERE provider == normalized_event.source LIMIT 1\n  IF secret IS NULL THEN FAIL ValidationError(\"unknown_provider\")\n  IF NOT verify_signature(raw_payload, signature, secret.key) THEN FAIL ValidationError(\"signature_mismatch\")\n  \n  event_record = PERSIST webhook_events_table (\n    event_id: generate_uuid(),\n    event_type: normalized_event.event_type,\n    source: normalized_event.source_id,\n    payload: normalized_event.data,\n    checksum: normalized_event.checksum,\n    received_at: normalized_event.timestamp,\n    processed: FALSE\n  )\n  \n  RETURN WebhookEvent(event_id: event_record.event_id, status: \"queued\")\nEND FUNCTION process_webhook [id=f3130]", "completion": "# ═══ INTL:BEGIN [id=f3130] process_webhook ═══\nimport logging\nimport hashlib\nimport uuid\nfrom datetime import datetime\nfrom typing import Any, Dict\n\nlogger = logging.getLogger(__name__)\n\nasync def process_webhook(payload: Dict[str, Any], signature: str, event_type: str) -> WebhookEvent:\n    assert payload is not None, \"payload must not be null\"\n    assert len(signature) > 0, \"signature must not be empty\"\n    assert event_type in (\"order.created\", \"order.updated\", \"payment.completed\"), \\\n        \"event_type must be one of: order.created, order.updated, payment.completed\"\n    \n    raw_payload = payload\n    normalized_event = {\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"event_type\": raw_payload.get(\"type\"),\n        \"source_id\": raw_payload.get(\"source\"),\n        \"data\": extract_nested_data(raw_payload.get(\"body\", {})),\n        \"checksum\": compute_hash(raw_payload)\n    }\n    \n    secret = await db.query(webhook_secrets).filter(provider=normalized_event[\"source_id\"]).first()\n    if secret is None:\n        raise ValidationError(\"unknown_provider\")\n    if not verify_signature(raw_payload, signature, secret.key):\n        raise ValidationError(\"signature_mismatch\")\n    \n    event_id = str(uuid.uuid4())\n    event_record = await db.insert(\n        webhook_events_table,\n        event_id=event_id,\n        event_type=normalized_event[\"event_type\"],\n        source=normalized_event[\"source_id\"],\n        payload=normalized_event[\"data\"],\n        checksum=normalized_event[\"checksum\"],\n        received_at=normalized_event[\"timestamp\"],\n        processed=False\n    )\n    \n    logger.info(\"process_webhook: event_id=%s event_type=%s source=%s\", \n                event_id, normalized_event[\"event_type\"], normalized_event[\"source_id\"])\n    \n    result = WebhookEvent(event_id=event_id, status=\"queued\")\n    assert result.event_id is not None\n    return result\n# ═══ INTL:END   [id=f3130] process_webhook ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 3130}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_order [id=f0417]\n  INTENT       \"validate and process customer order with inventory checks\"\n  PRECONDITION order_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION quantity <= 10000\n  POSTCONDITION result.order_status == \"confirmed\"\n  READS        orders_table, inventory_table\n  MUTATES      orders_table, inventory_table\n  OBSERVABLE\n\n  VALIDATE order_id IS NOT EMPTY ELSE OrderError(\"order_id_required\")\n  VALIDATE quantity > 0 ELSE OrderError(\"quantity_must_be_positive\")\n  VALIDATE quantity <= 10000 ELSE OrderError(\"quantity_exceeds_limit\")\n  \n  order = QUERY orders_table WHERE order_id == order_id LIMIT 1\n  IF order IS NULL THEN FAIL OrderError(\"order_not_found\")\n  \n  stock = QUERY inventory_table WHERE sku == order.sku LIMIT 1\n  IF stock IS NULL THEN FAIL OrderError(\"inventory_not_found\")\n  VALIDATE stock.available_qty >= quantity ELSE OrderError(\"insufficient_stock\")\n  \n  new_available = stock.available_qty - quantity\n  UPDATE inventory_table SET available_qty = new_available WHERE sku == order.sku\n  UPDATE orders_table SET order_status = \"confirmed\", processed_at = now() WHERE order_id == order_id\n  \n  RETURN OrderConfirmation(order_id: order_id, order_status: \"confirmed\", reserved_qty: quantity)\nEND FUNCTION process_order [id=f0417]", "completion": "# ═══ INTL:BEGIN [id=f0417] process_order ═══\nimport logging\nfrom datetime import datetime\nfrom typing import Optional\n\nlogger = logging.getLogger(__name__)\n\nclass OrderError(Exception):\n    pass\n\nclass OrderConfirmation:\n    def __init__(self, order_id: str, order_status: str, reserved_qty: int):\n        self.order_id = order_id\n        self.order_status = order_status\n        self.reserved_qty = reserved_qty\n\nasync def process_order(order_id: str, quantity: int) -> OrderConfirmation:\n    assert len(order_id) > 0, \"order_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    assert quantity <= 10000, \"quantity must not exceed 10000\"\n    \n    if not order_id or len(order_id) == 0:\n        raise OrderError(\"order_id_required\")\n    if quantity <= 0:\n        raise OrderError(\"quantity_must_be_positive\")\n    if quantity > 10000:\n        raise OrderError(\"quantity_exceeds_limit\")\n    \n    order = await db.query(orders_table).filter(order_id=order_id).first()\n    if order is None:\n        raise OrderError(\"order_not_found\")\n    \n    stock = await db.query(inventory_table).filter(sku=order.sku).first()\n    if stock is None:\n        raise OrderError(\"inventory_not_found\")\n    if stock.available_qty < quantity:\n        raise OrderError(\"insufficient_stock\")\n    \n    new_available = stock.available_qty - quantity\n    await db.update(inventory_table, sku=order.sku, \n                    available_qty=new_available)\n    await db.update(orders_table, order_id=order_id,\n                    order_status=\"confirmed\", processed_at=datetime.utcnow())\n    \n    logger.info(\"process_order: order_id=%s quantity=%d sku=%s\", \n                order_id, quantity, order.sku)\n    \n    result = OrderConfirmation(order_id=order_id, order_status=\"confirmed\", \n                               reserved_qty=quantity)\n    assert result.order_status == \"confirmed\"\n    return result\n# ═══ INTL:END   [id=f0417] process_order ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "VALIDATE", "idx": 417}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/coupons/{coupon_id}\")\nasync def get_coupon(coupon_id: str, db: Session = Depends(get_db)):\n    coupon = db.query(Coupon).filter(Coupon.id == coupon_id).first()\n    if not coupon:\n        raise HTTPException(status_code=404, detail=\"Coupon not found\")\n    return coupon\nINTL:END\n\nPATCH f0739 [target=f0739]\n  INTENT \"add observable metrics tracking for coupon retrieval events\"\n  ADD BEFORE: coupon = db.query(Coupon).filter(Coupon.id == coupon_id).first()\n    metrics.observe_coupon_lookup(coupon_id)\n  ADD AFTER: return coupon\n    metrics.observe_coupon_retrieved(coupon.id, coupon.discount_percent)\nEND PATCH f0739", "completion": "INTL:BEGIN\n@app.get(\"/coupons/{coupon_id}\")\nasync def get_coupon(coupon_id: str, db: Session = Depends(get_db)):\n    metrics.observe_coupon_lookup(coupon_id)\n    coupon = db.query(Coupon).filter(Coupon.id == coupon_id).first()\n    if not coupon:\n        raise HTTPException(status_code=404, detail=\"Coupon not found\")\n    metrics.observe_coupon_retrieved(coupon.id, coupon.discount_percent)\n    return coupon\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 739}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_refund [id=f1107]\n  INTENT       \"process a payment refund with intelligent fallback to manual review\"\n  PRECONDITION transaction_id.length > 0\n  PRECONDITION amount > 0\n  PRECONDITION amount <= transaction.original_amount\n  POSTCONDITION result.status IN (\"refunded\", \"pending_review\")\n  READS        transactions_table, payment_providers_table\n  MUTATES      refunds_table, audit_log_table\n  OBSERVABLE\n\n  transaction = QUERY transactions_table WHERE id == transaction_id LIMIT 1\n  IF transaction IS NULL THEN FAIL RefundError(\"transaction_not_found\")\n  \n  provider = QUERY payment_providers_table WHERE id == transaction.provider_id LIMIT 1\n  IF provider IS NULL THEN FAIL RefundError(\"provider_not_found\")\n  \n  refund_id = generate_refund_id()\n  \n  FALLBACK attempt_provider_refund(provider, transaction, amount)\n    ON_FAILURE gateway_timeout, gateway_error\n    THEN escalate_to_manual_review(refund_id, transaction, amount)\n  \n  result_status = FALLBACK_RESULT.status FALLBACK \"pending_review\"\n  \n  PERSIST refunds_table (refund_id: refund_id, transaction_id: transaction_id, amount: amount, status: result_status, created_at: now())\n  PERSIST audit_log_table (action: \"refund_processed\", refund_id: refund_id, user_id: actor_id, timestamp: now())\n  \n  RETURN RefundResponse(refund_id: refund_id, status: result_status, amount: amount)\nEND FUNCTION process_refund [id=f1107]", "completion": "# ═══ INTL:BEGIN [id=f1107] process_refund ═══\nimport logging\nfrom datetime import datetime\nfrom typing import Literal\n\nlogger = logging.getLogger(__name__)\n\nclass RefundError(Exception):\n    pass\n\nasync def process_refund(\n    transaction_id: str,\n    amount: float,\n    actor_id: str\n) -> RefundResponse:\n    assert len(transaction_id) > 0, \"transaction_id must not be empty\"\n    assert amount > 0, \"amount must be positive\"\n    \n    transaction = await db.query(transactions_table).filter(id=transaction_id).first()\n    if transaction is None:\n        raise RefundError(\"transaction_not_found\")\n    \n    assert amount <= transaction.original_amount, \"refund amount exceeds original transaction\"\n    \n    provider = await db.query(payment_providers_table).filter(id=transaction.provider_id).first()\n    if provider is None:\n        raise RefundError(\"provider_not_found\")\n    \n    refund_id = generate_refund_id()\n    result_status: Literal[\"refunded\", \"pending_review\"] = \"pending_review\"\n    \n    try:\n        provider_result = await attempt_provider_refund(provider, transaction, amount)\n        result_status = provider_result.status\n    except (TimeoutError, GatewayError) as e:\n        logger.warning(\"process_refund: provider gateway failed, escalating to manual review. refund_id=%s error=%s\", refund_id, str(e))\n        await escalate_to_manual_review(refund_id, transaction, amount)\n        result_status = \"pending_review\"\n    \n    await db.insert(\n        refunds_table,\n        refund_id=refund_id,\n        transaction_id=transaction_id,\n        amount=amount,\n        status=result_status,\n        created_at=datetime.utcnow()\n    )\n    \n    await db.insert(\n        audit_log_table,\n        action=\"refund_processed\",\n        refund_id=refund_id,\n        user_id=actor_id,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"process_refund: refund_id=%s transaction_id=%s amount=%.2f status=%s\", \n                refund_id, transaction_id, amount, result_status)\n    \n    result = RefundResponse(refund_id=refund_id, status=result_status, amount=amount)\n    assert result.status in (\"refunded\", \"pending_review\"), \"invalid refund status\"\n    return result\n# ═══ INTL:END   [id=f1107] process_refund ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 1107}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_webhook [id=f1429]\n  INTENT       \"validate incoming webhook payload and transform it into normalized event format\"\n  PRECONDITION payload IS NOT NULL\n  PRECONDITION signature.length > 0\n  PRECONDITION event_type IN [\"order.created\", \"order.updated\", \"payment.completed\"]\n  POSTCONDITION result.event_id IS NOT NULL\n  POSTCONDITION result.normalized_data IS NOT NULL\n  READS        webhooks_config\n  MUTATES      webhook_events_table\n  MUTATES      event_log_table\n  OBSERVABLE\n\n  IF NOT verify_signature(payload, signature, webhooks_config.secret_key) THEN\n    FAIL WebhookError(\"invalid_signature\")\n  \n  TRANSFORM normalized_data FROM payload USING normalize_schema(event_type)\n  \n  TRANSFORM enriched_data FROM normalized_data USING enrich_with_metadata(event_type)\n  \n  event_id = generate_uuid()\n  \n  PERSIST webhook_events_table (\n    event_id: event_id,\n    event_type: event_type,\n    raw_payload: payload,\n    normalized_data: enriched_data,\n    created_at: now()\n  )\n  \n  PERSIST event_log_table (\n    event_id: event_id,\n    status: \"processed\",\n    timestamp: now()\n  )\n  \n  RETURN WebhookEvent(event_id: event_id, normalized_data: enriched_data)\nEND FUNCTION process_webhook [id=f1429]", "completion": "# ═══ INTL:BEGIN [id=f1429] process_webhook ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\nfrom typing import Any, Dict, Literal\n\nlogger = logging.getLogger(__name__)\n\nasync def process_webhook(\n    payload: Dict[str, Any],\n    signature: str,\n    event_type: Literal[\"order.created\", \"order.updated\", \"payment.completed\"]\n) -> WebhookEvent:\n    assert payload is not None, \"payload must not be null\"\n    assert len(signature) > 0, \"signature must not be empty\"\n    assert event_type in [\"order.created\", \"order.updated\", \"payment.completed\"], \\\n        \"event_type must be one of: order.created, order.updated, payment.completed\"\n    \n    webhooks_config = await db.query(webhooks_config).first()\n    if not verify_signature(payload, signature, webhooks_config.secret_key):\n        raise WebhookError(\"invalid_signature\")\n    \n    normalized_data = normalize_schema(event_type, payload)\n    enriched_data = enrich_with_metadata(event_type, normalized_data)\n    \n    event_id = str(uuid4())\n    \n    await db.insert(\n        webhook_events_table,\n        event_id=event_id,\n        event_type=event_type,\n        raw_payload=payload,\n        normalized_data=enriched_data,\n        created_at=datetime.utcnow()\n    )\n    \n    await db.insert(\n        event_log_table,\n        event_id=event_id,\n        status=\"processed\",\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"webhook_processed: event_id=%s, event_type=%s\", event_id, event_type)\n    \n    result = WebhookEvent(event_id=event_id, normalized_data=enriched_data)\n    assert result.event_id is not None\n    assert result.normalized_data is not None\n    return result\n# ═══ INTL:END   [id=f1429] process_webhook ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 1429}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/sessions/{session_id}\")\nasync def get_session(session_id: str):\n    session = await db.sessions.find_one({\"id\": session_id})\n    if not session:\n        raise HTTPException(status_code=404, detail=\"Session not found\")\n    return session\nINTL:END\n\nPATCH f2119 [target=f2119]\n  INTENT \"add observable telemetry to track session retrieval events\"\n  ADD BEFORE: logger.info(f\"session_retrieval_attempt\", extra={\"session_id\": session_id})\n  ADD AFTER: logger.info(f\"session_retrieval_success\", extra={\"session_id\": session_id, \"user_id\": session.get(\"user_id\")})\nEND PATCH f2119", "completion": "INTL:BEGIN\n@app.get(\"/sessions/{session_id}\")\nasync def get_session(session_id: str):\n    logger.info(f\"session_retrieval_attempt\", extra={\"session_id\": session_id})\n    session = await db.sessions.find_one({\"id\": session_id})\n    if not session:\n        raise HTTPException(status_code=404, detail=\"Session not found\")\n    logger.info(f\"session_retrieval_success\", extra={\"session_id\": session_id, \"user_id\": session.get(\"user_id\")})\n    return session\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 2119}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION calculate_shipping_cost [id=f1751]\n  INTENT       \"calculate shipping cost based on origin, destination, and weight\"\n  PRECONDITION origin_zip.length == 5\n  PRECONDITION destination_zip.length == 5\n  PRECONDITION weight > 0\n  POSTCONDITION result.cost >= 0\n  READS        shipping_rates_table\n  READS        zone_mappings_table\n  MUTATES      shipping_quotes_table\n  OBSERVABLE\n\n  origin_zone = QUERY zone_mappings_table WHERE postal_code == origin_zip LIMIT 1\n  IF origin_zone IS NULL THEN FAIL ValidationError(\"invalid_origin_zip\")\n  dest_zone = QUERY zone_mappings_table WHERE postal_code == destination_zip LIMIT 1\n  IF dest_zone IS NULL THEN FAIL ValidationError(\"invalid_destination_zip\")\n  rate = QUERY shipping_rates_table WHERE from_zone == origin_zone.zone AND to_zone == dest_zone.zone AND weight_min <= weight AND weight_max >= weight LIMIT 1\n  IF rate IS NULL THEN FAIL RateNotFoundError(\"no_rate_for_route\")\n  cost = rate.base_rate + (weight * rate.per_lb_rate)\n  quote_id = generate_quote_id()\n  PERSIST shipping_quotes_table (quote_id: quote_id, origin_zip: origin_zip, destination_zip: destination_zip, weight: weight, cost: cost, created_at: now())\n  RETURN ShippingQuote(quote_id: quote_id, cost: cost)\nEND FUNCTION calculate_shipping_cost [id=f1751]", "completion": "# ═══ INTL:BEGIN [id=f1751] calculate_shipping_cost ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\n\nlogger = logging.getLogger(__name__)\n\nasync def calculate_shipping_cost(origin_zip: str, destination_zip: str, weight: float) -> ShippingQuote:\n    assert len(origin_zip) == 5, \"origin_zip must be exactly 5 characters\"\n    assert len(destination_zip) == 5, \"destination_zip must be exactly 5 characters\"\n    assert weight > 0, \"weight must be greater than 0\"\n    \n    origin_zone = await db.query(zone_mappings_table).filter(postal_code=origin_zip).first()\n    if origin_zone is None:\n        raise ValidationError(\"invalid_origin_zip\")\n    \n    dest_zone = await db.query(zone_mappings_table).filter(postal_code=destination_zip).first()\n    if dest_zone is None:\n        raise ValidationError(\"invalid_destination_zip\")\n    \n    rate = await db.query(shipping_rates_table).filter(\n        from_zone=origin_zone.zone,\n        to_zone=dest_zone.zone\n    ).filter(weight_min__lte=weight, weight_max__gte=weight).first()\n    \n    if rate is None:\n        raise RateNotFoundError(\"no_rate_for_route\")\n    \n    cost = rate.base_rate + (weight * rate.per_lb_rate)\n    quote_id = str(uuid4())\n    \n    await db.insert(shipping_quotes_table, \n                    quote_id=quote_id,\n                    origin_zip=origin_zip,\n                    destination_zip=destination_zip,\n                    weight=weight,\n                    cost=cost,\n                    created_at=datetime.utcnow())\n    \n    logger.info(\"calculate_shipping_cost: quote_id=%s origin=%s dest=%s weight=%.2f cost=%.2f\",\n                quote_id, origin_zip, destination_zip, weight, cost)\n    \n    result = ShippingQuote(quote_id=quote_id, cost=cost)\n    assert result.cost >= 0\n    return result\n# ═══ INTL:END   [id=f1751] calculate_shipping_cost ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "QUERY", "idx": 1751}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: str, db: Session = Depends(get_db)):\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    return review\nINTL:END\n\nPATCH f2441 [target=f2441]\n  INTENT \"add observability instrumentation to track review retrieval metrics\"\n  ADD BEFORE: logger.info(f\"Fetching review: {review_id}\")\n  ADD AFTER: logger.info(f\"Review retrieved successfully: {review_id}, rating: {review.rating}\")\nEND PATCH f2441", "completion": "INTL:BEGIN\n@router.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: str, db: Session = Depends(get_db)):\n    logger.info(f\"Fetching review: {review_id}\")\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    logger.info(f\"Review retrieved successfully: {review_id}, rating: {review.rating}\")\n    return review\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 2441}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION record_event [id=f3131]\n  INTENT       \"record user analytics event with metadata and persist to event log\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION event_type.length > 0\n  PRECONDITION timestamp > 0\n  POSTCONDITION result.event_id IS NOT NULL\n  READS        users_table\n  MUTATES      analytics_events_table\n  MUTATES      event_aggregates_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL ValidationError(\"user_not_found\")\n  event_id = generate_uuid()\n  PERSIST analytics_events_table (event_id: event_id, user_id: user_id, event_type: event_type, timestamp: timestamp, properties: properties)\n  aggregate = QUERY event_aggregates_table WHERE event_type == event_type LIMIT 1\n  IF aggregate IS NULL THEN PERSIST event_aggregates_table (event_type: event_type, count: 1, last_recorded_at: now())\n  ELSE PERSIST event_aggregates_table (event_type: event_type, count: aggregate.count + 1, last_recorded_at: now())\n  RETURN EventRecord(event_id: event_id, user_id: user_id, recorded_at: now())\nEND FUNCTION record_event [id=f3131]", "completion": "# ═══ INTL:BEGIN [id=f3131] record_event ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\n\nlogger = logging.getLogger(__name__)\n\nasync def record_event(user_id: str, event_type: str, timestamp: int, properties: dict = None) -> EventRecord:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(event_type) > 0, \"event_type must not be empty\"\n    assert timestamp > 0, \"timestamp must be positive\"\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise ValidationError(\"user_not_found\")\n    \n    event_id = str(uuid4())\n    \n    await db.insert(analytics_events_table, \n                   event_id=event_id, \n                   user_id=user_id, \n                   event_type=event_type, \n                   timestamp=timestamp, \n                   properties=properties or {})\n    \n    aggregate = await db.query(event_aggregates_table).filter(event_type=event_type).first()\n    \n    if aggregate is None:\n        await db.insert(event_aggregates_table, \n                       event_type=event_type, \n                       count=1, \n                       last_recorded_at=datetime.utcnow())\n    else:\n        await db.update(event_aggregates_table, \n                       where={\"event_type\": event_type},\n                       count=aggregate.count + 1, \n                       last_recorded_at=datetime.utcnow())\n    \n    logger.info(\"record_event: event_id=%s user_id=%s event_type=%s\", event_id, user_id, event_type)\n    \n    result = EventRecord(event_id=event_id, user_id=user_id, recorded_at=datetime.utcnow())\n    assert result.event_id is not None\n    return result\n# ═══ INTL:END   [id=f3131] record_event ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 3131}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION create_search_index [id=f2763]\n  INTENT       \"index a document for full-text search and record indexing metadata\"\n  PRECONDITION document_id.length > 0\n  PRECONDITION content.length > 100\n  PRECONDITION index_name IS NOT NULL\n  POSTCONDITION result.indexed IS TRUE\n  READS        documents_table\n  MUTATES      search_index, index_metadata_table\n  OBSERVABLE\n\n  doc = QUERY documents_table WHERE id == document_id LIMIT 1\n  IF doc IS NULL THEN FAIL DocumentError(\"document_not_found\")\n  IF content.length == 0 THEN FAIL ValidationError(\"content_cannot_be_empty\")\n  \n  indexed_tokens = tokenize_and_stem(content)\n  PERSIST search_index (document_id: document_id, tokens: indexed_tokens, index_name: index_name)\n  PERSIST index_metadata_table (document_id: document_id, indexed_at: now(), token_count: count(indexed_tokens), version: 1)\n  \n  RETURN IndexResult(indexed: TRUE, token_count: count(indexed_tokens), document_id: document_id)\nEND FUNCTION create_search_index [id=f2763]", "completion": "# ═══ INTL:BEGIN [id=f2763] create_search_index ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def create_search_index(document_id: str, content: str, index_name: str) -> IndexResult:\n    assert len(document_id) > 0, \"document_id must not be empty\"\n    assert len(content) > 100, \"content must be at least 100 characters\"\n    assert index_name is not None, \"index_name must not be null\"\n    \n    doc = await db.query(documents_table).filter(id=document_id).first()\n    if doc is None:\n        raise DocumentError(\"document_not_found\")\n    if len(content) == 0:\n        raise ValidationError(\"content_cannot_be_empty\")\n    \n    indexed_tokens = tokenize_and_stem(content)\n    \n    await db.insert(search_index, \n                    document_id=document_id, \n                    tokens=indexed_tokens, \n                    index_name=index_name)\n    \n    await db.insert(index_metadata_table,\n                    document_id=document_id,\n                    indexed_at=datetime.utcnow(),\n                    token_count=len(indexed_tokens),\n                    version=1)\n    \n    logger.info(\"create_search_index: document_id=%s index_name=%s token_count=%d\", \n                document_id, index_name, len(indexed_tokens))\n    \n    result = IndexResult(indexed=True, token_count=len(indexed_tokens), document_id=document_id)\n    assert result.indexed is True\n    return result\n# ═══ INTL:END   [id=f2763] create_search_index ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 2763}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom typing import List\n\napp = FastAPI()\n\n@app.get(\"/search\")\nasync def search(query: str, limit: int = 10):\n    results = []\n    for item in range(limit):\n        results.append({\"id\": item, \"query\": query})\n    return results\nINTL:END\n\nPATCH f0418 [target=f0418]\n  INTENT \"parallelize search result collection using concurrent tasks\"\n  REPLACE: for item in range(limit): results.append({...})\n  WITH: asyncio.gather parallel execution of search tasks\n  ADD BEFORE: import asyncio\nEND PATCH f0418", "completion": "INTL:BEGIN\nimport asyncio\nfrom fastapi import FastAPI\nfrom typing import List\n\napp = FastAPI()\n\n@app.get(\"/search\")\nasync def search(query: str, limit: int = 10):\n    async def fetch_result(item: int):\n        return {\"id\": item, \"query\": query}\n    \n    results = await asyncio.gather(*[fetch_result(item) for item in range(limit)])\n    return results\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PARALLEL", "idx": 418}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION register_webhook [id=f0050]\n  INTENT       \"register and validate a new webhook endpoint\"\n  PRECONDITION url.length > 0\n  PRECONDITION events.length > 0\n  PRECONDITION secret.length >= 16\n  POSTCONDITION result.webhook_id IS NOT NULL\n  READS        webhooks_table\n  MUTATES      webhooks_table\n  MUTATES      webhook_events_table\n  OBSERVABLE\n\n  existing = QUERY webhooks_table WHERE url == url AND status != \"deleted\" LIMIT 1\n  IF existing IS NOT NULL THEN FAIL ValidationError(\"webhook_already_registered\")\n  IF NOT is_valid_url(url) THEN FAIL ValidationError(\"invalid_url_format\")\n  IF NOT all_events_valid(events) THEN FAIL ValidationError(\"invalid_event_types\")\n  \n  webhook_id = generate_id()\n  PERSIST webhooks_table (id: webhook_id, url: url, secret: hash_secret(secret), status: \"active\", created_at: now())\n  \n  FOR event IN events DO\n    PERSIST webhook_events_table (webhook_id: webhook_id, event_type: event)\n  END\n  \n  RETURN WebhookRegistration(webhook_id: webhook_id, url: url, events: events)\nEND FUNCTION register_webhook [id=f0050]", "completion": "# ═══ INTL:BEGIN [id=f0050] register_webhook ═══\nimport logging\nfrom datetime import datetime\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\nasync def register_webhook(url: str, events: list[str], secret: str) -> WebhookRegistration:\n    assert len(url) > 0, \"url must not be empty\"\n    assert len(events) > 0, \"events list must not be empty\"\n    assert len(secret) >= 16, \"secret must be at least 16 characters\"\n    \n    existing = await db.query(webhooks_table).filter(\n        url=url,\n        status__ne=\"deleted\"\n    ).first()\n    if existing is not None:\n        raise ValidationError(\"webhook_already_registered\")\n    \n    if not is_valid_url(url):\n        raise ValidationError(\"invalid_url_format\")\n    \n    if not all_events_valid(events):\n        raise ValidationError(\"invalid_event_types\")\n    \n    webhook_id = str(uuid.uuid4())\n    await db.insert(\n        webhooks_table,\n        id=webhook_id,\n        url=url,\n        secret=hash_secret(secret),\n        status=\"active\",\n        created_at=datetime.utcnow()\n    )\n    \n    for event in events:\n        await db.insert(\n            webhook_events_table,\n            webhook_id=webhook_id,\n            event_type=event\n        )\n    \n    logger.info(\"register_webhook: webhook_id=%s url=%s events=%d\", webhook_id, url, len(events))\n    result = WebhookRegistration(webhook_id=webhook_id, url=url, events=events)\n    assert result.webhook_id is not None\n    return result\n# ═══ INTL:END   [id=f0050] register_webhook ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FAIL", "idx": 50}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return {\n        \"id\": product.id,\n        \"name\": product.name,\n        \"price\": product.price,\n        \"description\": product.description\n    }\nINTL:END\n\nPATCH f1430 [target=f1430]\n  INTENT \"add confidence score to product response to indicate data reliability\"\n  ADD AFTER: return statement opening\n    \"confidence\": calculate_confidence_score(product),\nEND PATCH f1430", "completion": "INTL:BEGIN\n@router.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return {\n        \"id\": product.id,\n        \"name\": product.name,\n        \"price\": product.price,\n        \"description\": product.description,\n        \"confidence\": calculate_confidence_score(product)\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 1430}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION apply_coupon [id=f1108]\n  INTENT       \"validate and apply a discount coupon to a cart, caching coupon metadata for performance\"\n  PRECONDITION coupon_code.length > 0\n  PRECONDITION cart_total > 0\n  PRECONDITION user_id IS NOT NULL\n  POSTCONDITION result.discount_amount >= 0\n  POSTCONDITION result.final_total == cart_total - result.discount_amount\n  READS        coupons_table\n  READS        coupon_usage_table\n  MUTATES      coupon_usage_table\n  OBSERVABLE\n\n  coupon = CACHE GET coupons_table BY coupon_code WITH TTL 3600\n  IF coupon IS NULL THEN FAIL InvalidCoupon(\"coupon_not_found\")\n  IF NOT coupon.is_active THEN FAIL InvalidCoupon(\"coupon_expired\")\n  IF coupon.min_purchase > cart_total THEN FAIL InvalidCoupon(\"minimum_purchase_not_met\")\n  usage_count = QUERY coupon_usage_table WHERE user_id == user_id AND coupon_id == coupon.id\n  IF usage_count >= coupon.max_uses_per_user THEN FAIL InvalidCoupon(\"coupon_limit_exceeded\")\n  discount = coupon.discount_percent * cart_total / 100\n  final_total = cart_total - discount\n  PERSIST coupon_usage_table (user_id: user_id, coupon_id: coupon.id, applied_at: now())\n  RETURN CouponResult(discount_amount: discount, final_total: final_total, coupon_id: coupon.id)\nEND FUNCTION apply_coupon [id=f1108]", "completion": "# ═══ INTL:BEGIN [id=f1108] apply_coupon ═══\nimport logging\nfrom datetime import datetime\nfrom functools import lru_cache\nimport time\n\nlogger = logging.getLogger(__name__)\n\n@lru_cache(maxsize=256)\ndef _get_coupon_cached(coupon_code: str, cache_ttl: int = 3600):\n    \"\"\"Internal cache wrapper with TTL simulation for coupon metadata.\"\"\"\n    cache_key = f\"{coupon_code}:{int(time.time() // cache_ttl)}\"\n    return cache_key\n\nasync def apply_coupon(coupon_code: str, cart_total: float, user_id: str) -> CouponResult:\n    assert len(coupon_code) > 0, \"coupon_code must not be empty\"\n    assert cart_total > 0, \"cart_total must be greater than zero\"\n    assert user_id is not None, \"user_id must not be null\"\n    \n    # CACHE GET with 3600s TTL\n    coupon = await db.cache.get_or_fetch(\n        key=f\"coupon:{coupon_code}\",\n        fetch_fn=lambda: db.query(coupons_table).filter(code=coupon_code).first(),\n        ttl=3600\n    )\n    \n    if coupon is None:\n        raise InvalidCoupon(\"coupon_not_found\")\n    if not coupon.is_active:\n        raise InvalidCoupon(\"coupon_expired\")\n    if coupon.min_purchase > cart_total:\n        raise InvalidCoupon(\"minimum_purchase_not_met\")\n    \n    usage_count = await db.query(coupon_usage_table).filter(\n        user_id=user_id,\n        coupon_id=coupon.id\n    ).count()\n    \n    if usage_count >= coupon.max_uses_per_user:\n        raise InvalidCoupon(\"coupon_limit_exceeded\")\n    \n    discount = (coupon.discount_percent * cart_total) / 100\n    final_total = cart_total - discount\n    \n    await db.insert(coupon_usage_table, user_id=user_id, coupon_id=coupon.id,\n                    applied_at=datetime.utcnow())\n    \n    logger.info(\"apply_coupon: user=%s coupon=%s discount=%.2f\", user_id, coupon.id, discount)\n    \n    result = CouponResult(discount_amount=discount, final_total=final_total, coupon_id=coupon.id)\n    assert result.discount_amount >= 0\n    assert abs(result.final_total - (cart_total - result.discount_amount)) < 0.01\n    return result\n# ═══ INTL:END   [id=f1108] apply_coupon ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CACHE GET", "idx": 1108}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION refresh_session [id=f1752]\n  INTENT       \"extend session expiration and update last activity timestamp\"\n  PRECONDITION token.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.expires_at > now()\n  READS        sessions_table\n  MUTATES      sessions_table\n  OBSERVABLE\n\n  session = QUERY sessions_table WHERE token == token LIMIT 1\n  IF session IS NULL THEN FAIL SessionError(\"session_not_found\")\n  IF session.expires_at < now() THEN FAIL SessionError(\"session_expired\")\n  IF session.user_id != user_id THEN FAIL SessionError(\"session_user_mismatch\")\n  new_expiry = now() + 24h\n  PERSIST sessions_table (token: token, expires_at: new_expiry, last_activity: now())\n  RETURN SessionInfo(token: token, expires_at: new_expiry, user_id: user_id)\nEND FUNCTION refresh_session [id=f1752]", "completion": "# ═══ INTL:BEGIN [id=f1752] refresh_session ═══\nimport logging\nfrom datetime import datetime, timedelta\n\nlogger = logging.getLogger(__name__)\n\nasync def refresh_session(token: str, user_id: int) -> SessionInfo:\n    assert len(token) > 0, \"token must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    session = await db.query(sessions_table).filter(token=token).first()\n    if session is None:\n        raise SessionError(\"session_not_found\")\n    if session.expires_at < datetime.utcnow():\n        raise SessionError(\"session_expired\")\n    if session.user_id != user_id:\n        raise SessionError(\"session_user_mismatch\")\n    new_expiry = datetime.utcnow() + timedelta(hours=24)\n    await db.update(sessions_table, \n                    where={\"token\": token},\n                    values={\"expires_at\": new_expiry, \n                            \"last_activity\": datetime.utcnow()})\n    logger.info(\"refresh_session: token=%s user_id=%s expires_at=%s\", \n                token, user_id, new_expiry)\n    result = SessionInfo(token=token, expires_at=new_expiry, user_id=user_id)\n    assert result.expires_at > datetime.utcnow()\n    return result\n# ═══ INTL:END   [id=f1752] refresh_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 1752}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION publish_product [id=f2120]\n  INTENT       \"publish product to catalog and emit inventory event\"\n  PRECONDITION product.sku.length > 0\n  PRECONDITION product.price > 0\n  PRECONDITION product.stock_quantity >= 0\n  POSTCONDITION result.published_at IS NOT NULL\n  READS        products_table\n  MUTATES      products_table\n  MUTATES      product_events_queue\n  OBSERVABLE\n  \n  product_record = QUERY products_table WHERE sku == product.sku LIMIT 1\n  IF product_record IS NULL THEN FAIL NotFoundError(\"product_not_found\")\n  IF product_record.status == \"published\" THEN FAIL ConflictError(\"already_published\")\n  \n  PERSIST products_table (sku: product.sku, status: \"published\", published_at: now(), price: product.price, stock_quantity: product.stock_quantity)\n  \n  EMIT product_events_queue {\n    event_type: \"product.published\",\n    sku: product.sku,\n    price: product.price,\n    stock_quantity: product.stock_quantity,\n    timestamp: now()\n  }\n  \n  RETURN PublishResult(published_at: now(), event_id: generate_uuid())\nEND FUNCTION publish_product [id=f2120]", "completion": "# ═══ INTL:BEGIN [id=f2120] publish_product ═══\nimport logging\nfrom datetime import datetime\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\nasync def publish_product(sku: str, price: float, stock_quantity: int) -> PublishResult:\n    assert len(sku) > 0, \"sku must not be empty\"\n    assert price > 0, \"price must be greater than zero\"\n    assert stock_quantity >= 0, \"stock_quantity must be non-negative\"\n    \n    product_record = await db.query(products_table).filter(sku=sku).first()\n    if product_record is None:\n        raise NotFoundError(\"product_not_found\")\n    if product_record.status == \"published\":\n        raise ConflictError(\"already_published\")\n    \n    published_at = datetime.utcnow()\n    await db.update(products_table, sku=sku, status=\"published\", \n                    published_at=published_at, price=price, stock_quantity=stock_quantity)\n    \n    event_id = str(uuid.uuid4())\n    event_payload = {\n        \"event_type\": \"product.published\",\n        \"sku\": sku,\n        \"price\": price,\n        \"stock_quantity\": stock_quantity,\n        \"timestamp\": published_at.isoformat(),\n        \"event_id\": event_id\n    }\n    await event_queue.emit(product_events_queue, event_payload)\n    \n    logger.info(\"publish_product: sku=%s, event_id=%s, price=%s\", sku, event_id, price)\n    \n    result = PublishResult(published_at=published_at, event_id=event_id)\n    assert result.published_at is not None\n    return result\n# ═══ INTL:END   [id=f2120] publish_product ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "EMIT", "idx": 2120}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION record_audit_event [id=f3132]\n  INTENT       \"record security-relevant event to audit log with tamper detection\"\n  PRECONDITION event_type.length > 0\n  PRECONDITION user_id > 0\n  PRECONDITION severity IN (\"info\", \"warning\", \"critical\")\n  POSTCONDITION result.audit_id IS NOT NULL\n  POSTCONDITION result.checksum IS NOT NULL\n  READS        audit_logs_table\n  MUTATES      audit_logs_table\n  OBSERVABLE\n\n  previous_hash = QUERY audit_logs_table ORDER BY created_at DESC LIMIT 1 SELECT checksum\n  IF previous_hash IS NULL THEN previous_hash = \"0\"\n  event_data = AuditEvent(user_id: user_id, event_type: event_type, severity: severity, timestamp: now())\n  event_checksum = hash_chain(event_data, previous_hash)\n  PERSIST audit_logs_table (user_id: user_id, event_type: event_type, severity: severity, checksum: event_checksum, created_at: now())\n  RETURN AuditRecord(audit_id: last_insert_id(), checksum: event_checksum)\nEND FUNCTION record_audit_event [id=f3132]", "completion": "# ═══ INTL:BEGIN [id=f3132] record_audit_event ═══\nimport logging\nfrom datetime import datetime\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def record_audit_event(\n    user_id: int,\n    event_type: str,\n    severity: str\n) -> AuditRecord:\n    assert len(event_type) > 0, \"event_type must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    assert severity in (\"info\", \"warning\", \"critical\"), \"severity must be one of: info, warning, critical\"\n    \n    previous_record = await db.query(audit_logs_table).order_by(\"-created_at\").first()\n    previous_hash = previous_record.checksum if previous_record else \"0\"\n    \n    event_data = {\n        \"user_id\": user_id,\n        \"event_type\": event_type,\n        \"severity\": severity,\n        \"timestamp\": datetime.utcnow().isoformat()\n    }\n    \n    event_checksum = hashlib.sha256(\n        (str(event_data) + previous_hash).encode()\n    ).hexdigest()\n    \n    inserted = await db.insert(\n        audit_logs_table,\n        user_id=user_id,\n        event_type=event_type,\n        severity=severity,\n        checksum=event_checksum,\n        created_at=datetime.utcnow()\n    )\n    \n    audit_id = inserted.id\n    logger.info(\n        \"audit_event_recorded: audit_id=%s user_id=%s event_type=%s severity=%s checksum=%s\",\n        audit_id, user_id, event_type, severity, event_checksum\n    )\n    \n    result = AuditRecord(audit_id=audit_id, checksum=event_checksum)\n    assert result.audit_id is not None\n    assert result.checksum is not None\n    return result\n# ═══ INTL:END   [id=f3132] record_audit_event ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 3132}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION apply_coupon_to_order [id=f2764]\n  INTENT       \"validate and apply a coupon code to an order, updating order total and marking coupon as used\"\n  PRECONDITION coupon_code.length > 0\n  PRECONDITION order_id > 0\n  PRECONDITION order_total >= 0\n  POSTCONDITION result.discount_amount >= 0\n  POSTCONDITION result.final_total >= 0\n  READS        coupons_table\n  READS        orders_table\n  MUTATES      orders_table\n  MUTATES      coupon_usage_table\n  OBSERVABLE\n\n  SEQUENCE\n    coupon = QUERY coupons_table WHERE code == coupon_code LIMIT 1\n    IF coupon IS NULL THEN FAIL CouponError(\"coupon_not_found\")\n    IF NOT coupon.is_active THEN FAIL CouponError(\"coupon_inactive\")\n    IF coupon.expires_at < now() THEN FAIL CouponError(\"coupon_expired\")\n    \n    order = QUERY orders_table WHERE id == order_id LIMIT 1\n    IF order IS NULL THEN FAIL OrderError(\"order_not_found\")\n    IF order.status != \"pending\" THEN FAIL OrderError(\"order_already_processed\")\n    \n    usage_count = QUERY coupon_usage_table WHERE coupon_id == coupon.id COUNT\n    IF usage_count >= coupon.max_uses THEN FAIL CouponError(\"coupon_limit_exceeded\")\n    \n    discount_amount = MIN(coupon.discount_value, order_total)\n    final_total = order_total - discount_amount\n    \n    PERSIST orders_table (id: order_id, total: final_total, coupon_id: coupon.id, updated_at: now())\n    PERSIST coupon_usage_table (coupon_id: coupon.id, order_id: order_id, used_at: now())\n    \n    RETURN CouponResult(discount_amount: discount_amount, final_total: final_total)\n  END SEQUENCE\nEND FUNCTION apply_coupon_to_order [id=f2764]", "completion": "# ═══ INTL:BEGIN [id=f2764] apply_coupon_to_order ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def apply_coupon_to_order(coupon_code: str, order_id: int, order_total: float) -> CouponResult:\n    assert len(coupon_code) > 0, \"coupon_code must not be empty\"\n    assert order_id > 0, \"order_id must be positive\"\n    assert order_total >= 0, \"order_total must be non-negative\"\n    \n    # Validate coupon exists and is usable\n    coupon = await db.query(coupons_table).filter(code=coupon_code).first()\n    if coupon is None:\n        raise CouponError(\"coupon_not_found\")\n    if not coupon.is_active:\n        raise CouponError(\"coupon_inactive\")\n    if coupon.expires_at < datetime.utcnow():\n        raise CouponError(\"coupon_expired\")\n    \n    # Validate order exists and is in correct state\n    order = await db.query(orders_table).filter(id=order_id).first()\n    if order is None:\n        raise OrderError(\"order_not_found\")\n    if order.status != \"pending\":\n        raise OrderError(\"order_already_processed\")\n    \n    # Check coupon usage limits\n    usage_count = await db.query(coupon_usage_table).filter(coupon_id=coupon.id).count()\n    if usage_count >= coupon.max_uses:\n        raise CouponError(\"coupon_limit_exceeded\")\n    \n    # Calculate discount and final total\n    discount_amount = min(coupon.discount_value, order_total)\n    final_total = order_total - discount_amount\n    \n    # Persist updates to orders and coupon usage\n    await db.update(orders_table, \n                    where={\"id\": order_id},\n                    values={\"total\": final_total, \"coupon_id\": coupon.id, \"updated_at\": datetime.utcnow()})\n    await db.insert(coupon_usage_table, \n                    coupon_id=coupon.id, order_id=order_id, used_at=datetime.utcnow())\n    \n    logger.info(\"apply_coupon_to_order: order_id=%d coupon_id=%s discount=%.2f\", \n                order_id, coupon.id, discount_amount)\n    \n    result = CouponResult(discount_amount=discount_amount, final_total=final_total)\n    assert result.discount_amount >= 0\n    assert result.final_total >= 0\n    return result\n# ═══ INTL:END   [id=f2764] apply_coupon_to_order ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 2764}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: str, db: Session = Depends(get_db)):\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    return review\nINTL:END\n\nPATCH f0419 [target=f0419]\n  INTENT \"add observable tracing to review retrieval\"\n  ADD AFTER_SIGNATURE: from opentelemetry import trace\n  ADD BEFORE: tracer = trace.get_tracer(__name__); span = tracer.start_as_current_span(\"get_review\"); span.set_attribute(\"review.id\", review_id)\n  ADD AFTER: span.end()\nEND PATCH f0419", "completion": "INTL:BEGIN\nfrom opentelemetry import trace\n\ntracer = trace.get_tracer(__name__)\n\n@router.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: str, db: Session = Depends(get_db)):\n    span = tracer.start_as_current_span(\"get_review\")\n    span.set_attribute(\"review.id\", review_id)\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        span.end()\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    span.end()\n    return review\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 419}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_inventory [id=f0051]\n  INTENT       \"replenish stock for a SKU with confidence-based validation\"\n  PRECONDITION sku.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION supplier_id > 0\n  POSTCONDITION result.stock_level >= quantity\n  READS        inventory_table, supplier_verification_table\n  MUTATES      inventory_table, restock_log_table\n  OBSERVABLE\n  CONFIDENCE   supplier_reliability >= 0.85\n\n  supplier = QUERY supplier_verification_table WHERE id == supplier_id LIMIT 1\n  IF supplier IS NULL THEN FAIL SupplierError(\"supplier_not_found\")\n  IF supplier.reliability_score < 0.85 THEN FAIL ConfidenceError(\"low_supplier_confidence\")\n  inventory_item = QUERY inventory_table WHERE sku == sku LIMIT 1\n  IF inventory_item IS NULL THEN FAIL InventoryError(\"sku_not_found\")\n  new_stock_level = inventory_item.stock_level + quantity\n  PERSIST inventory_table (sku: sku, stock_level: new_stock_level, last_restocked_at: now())\n  PERSIST restock_log_table (sku: sku, quantity: quantity, supplier_id: supplier_id, timestamp: now(), confidence_score: supplier.reliability_score)\n  RETURN RestockResult(sku: sku, stock_level: new_stock_level, confidence_score: supplier.reliability_score)\nEND FUNCTION restock_inventory [id=f0051]", "completion": "# ═══ INTL:BEGIN [id=f0051] restock_inventory ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_inventory(sku: str, quantity: int, supplier_id: int) -> RestockResult:\n    assert len(sku) > 0, \"sku must not be empty\"\n    assert quantity > 0, \"quantity must be greater than zero\"\n    assert supplier_id > 0, \"supplier_id must be greater than zero\"\n    \n    supplier = await db.query(supplier_verification_table).filter(id=supplier_id).first()\n    if supplier is None:\n        raise SupplierError(\"supplier_not_found\")\n    \n    if supplier.reliability_score < 0.85:\n        logger.warning(\"restock_inventory: low supplier confidence, supplier_id=%s, score=%.2f\",\n                       supplier_id, supplier.reliability_score)\n        raise ConfidenceError(\"low_supplier_confidence\")\n    \n    inventory_item = await db.query(inventory_table).filter(sku=sku).first()\n    if inventory_item is None:\n        raise InventoryError(\"sku_not_found\")\n    \n    new_stock_level = inventory_item.stock_level + quantity\n    \n    await db.update(inventory_table, \n                    filter_by={\"sku\": sku},\n                    stock_level=new_stock_level,\n                    last_restocked_at=datetime.utcnow())\n    \n    await db.insert(restock_log_table,\n                    sku=sku,\n                    quantity=quantity,\n                    supplier_id=supplier_id,\n                    timestamp=datetime.utcnow(),\n                    confidence_score=supplier.reliability_score)\n    \n    logger.info(\"restock_inventory: sku=%s, quantity=%d, new_stock=%d, confidence=%.2f\",\n                sku, quantity, new_stock_level, supplier.reliability_score)\n    \n    result = RestockResult(sku=sku, stock_level=new_stock_level, \n                          confidence_score=supplier.reliability_score)\n    assert result.stock_level >= quantity\n    return result\n# ═══ INTL:END   [id=f0051] restock_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 51}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION update_payment_status [id=f1431]\n  INTENT       \"patch payment record with new status and update reconciliation state\"\n  PRECONDITION payment_id.length > 0\n  PRECONDITION status IN [\"pending\", \"completed\", \"failed\", \"refunded\"]\n  PRECONDITION amount > 0\n  POSTCONDITION result.status == status\n  POSTCONDITION result.updated_at IS NOT NULL\n  READS        payments_table\n  MUTATES      payments_table\n  MUTATES      reconciliation_ledger\n  OBSERVABLE\n\n  payment = QUERY payments_table WHERE id == payment_id LIMIT 1\n  IF payment IS NULL THEN FAIL PaymentError(\"payment_not_found\")\n  IF payment.status == \"completed\" THEN FAIL PaymentError(\"cannot_modify_completed\")\n  \n  PATCH payments_table SET id == payment_id\n    status: status\n    amount: amount\n    updated_at: now()\n  END PATCH\n  \n  PERSIST reconciliation_ledger (\n    payment_id: payment_id,\n    old_status: payment.status,\n    new_status: status,\n    reconciled_at: now()\n  )\n  \n  updated_payment = QUERY payments_table WHERE id == payment_id LIMIT 1\n  RETURN PaymentResponse(id: updated_payment.id, status: updated_payment.status, amount: updated_payment.amount, updated_at: updated_payment.updated_at)\nEND FUNCTION update_payment_status [id=f1431]", "completion": "# ═══ INTL:BEGIN [id=f1431] update_payment_status ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def update_payment_status(payment_id: str, status: str, amount: float) -> PaymentResponse:\n    assert len(payment_id) > 0, \"payment_id must not be empty\"\n    assert status in [\"pending\", \"completed\", \"failed\", \"refunded\"], \"status must be one of: pending, completed, failed, refunded\"\n    assert amount > 0, \"amount must be greater than zero\"\n    \n    payment = await db.query(payments_table).filter(id=payment_id).first()\n    if payment is None:\n        raise PaymentError(\"payment_not_found\")\n    if payment.status == \"completed\":\n        raise PaymentError(\"cannot_modify_completed\")\n    \n    old_status = payment.status\n    await db.update(payments_table).filter(id=payment_id).set(\n        status=status,\n        amount=amount,\n        updated_at=datetime.utcnow()\n    )\n    \n    await db.insert(reconciliation_ledger, \n                    payment_id=payment_id,\n                    old_status=old_status,\n                    new_status=status,\n                    reconciled_at=datetime.utcnow())\n    \n    updated_payment = await db.query(payments_table).filter(id=payment_id).first()\n    logger.info(\"update_payment_status: payment_id=%s, old_status=%s, new_status=%s\", payment_id, old_status, status)\n    \n    assert updated_payment.status == status\n    assert updated_payment.updated_at is not None\n    result = PaymentResponse(id=updated_payment.id, status=updated_payment.status, amount=updated_payment.amount, updated_at=updated_payment.updated_at)\n    return result\n# ═══ INTL:END   [id=f1431] update_payment_status ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PATCH", "idx": 1431}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_session [id=f2121]\n  INTENT       \"atomically invalidate a session and log the revocation event\"\n  PRECONDITION session_id.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.revoked IS TRUE\n  READS        sessions_table\n  MUTATES      sessions_table, audit_log\n  OBSERVABLE\n\n  TRANSACTION\n    session = QUERY sessions_table WHERE id == session_id LIMIT 1\n    IF session IS NULL THEN FAIL SessionError(\"session_not_found\")\n    IF session.user_id != user_id THEN FAIL SessionError(\"unauthorized\")\n    PERSIST sessions_table (id: session_id, revoked_at: now(), status: \"revoked\")\n    PERSIST audit_log (user_id: user_id, action: \"session_revoke\", session_id: session_id, timestamp: now())\n    RETURN SessionRevoked(revoked: TRUE, session_id: session_id)\n  END TRANSACTION\nEND FUNCTION revoke_session [id=f2121]", "completion": "# ═══ INTL:BEGIN [id=f2121] revoke_session ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_session(session_id: str, user_id: int) -> SessionRevoked:\n    assert len(session_id) > 0, \"session_id must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    \n    async with db.transaction():\n        session = await db.query(sessions_table).filter(id=session_id).first()\n        if session is None:\n            raise SessionError(\"session_not_found\")\n        if session.user_id != user_id:\n            raise SessionError(\"unauthorized\")\n        \n        await db.update(sessions_table, \n                       id=session_id,\n                       revoked_at=datetime.utcnow(),\n                       status=\"revoked\")\n        \n        await db.insert(audit_log,\n                       user_id=user_id,\n                       action=\"session_revoke\",\n                       session_id=session_id,\n                       timestamp=datetime.utcnow())\n        \n        logger.info(\"revoke_session: user_id=%s, session_id=%s\", user_id, session_id)\n        result = SessionRevoked(revoked=True, session_id=session_id)\n        assert result.revoked is True\n        return result\n# ═══ INTL:END   [id=f2121] revoke_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 2121}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/shipments\")\nasync def create_shipment(shipment: ShipmentRequest):\n    shipment_id = generate_id()\n    db.save(shipment_id, shipment.dict())\n    return {\"shipment_id\": shipment_id, \"status\": \"pending\"}\nINTL:END\n\nPATCH f2765 [target=f2765]\n  INTENT \"add rate limiting to the function\"\n  ADD BEFORE: rate_limit_check(user_id)\nEND PATCH f2765", "completion": "INTL:BEGIN\n@app.post(\"/shipments\")\nasync def create_shipment(shipment: ShipmentRequest):\n    rate_limit_check(user_id)\n    shipment_id = generate_id()\n    db.save(shipment_id, shipment.dict())\n    return {\"shipment_id\": shipment_id, \"status\": \"pending\"}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PATCH", "idx": 2765}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\napp = FastAPI()\nengine = create_engine(\"sqlite:///analytics.db\")\nSessionLocal = sessionmaker(bind=engine)\n\n@app.post(\"/track_event\")\nasync def track_event(event_id: str, user_id: str, data: dict):\n    session = SessionLocal()\n    try:\n        # Insert event into database\n        query = \"INSERT INTO events (event_id, user_id, data) VALUES (?, ?, ?)\"\n        session.execute(query, (event_id, user_id, str(data)))\n        session.commit()\n        return {\"status\": \"success\"}\n    finally:\n        session.close()\nINTL:END\n\nPATCH f2443 [target=f2443]\n  INTENT \"add distributed lock to prevent concurrent event writes for same user\"\n  ADD BEFORE: session.execute(query, (event_id, user_id, str(data)))\n  LOCK user_id TIMEOUT 5000ms\nEND PATCH f2443", "completion": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nimport redis\nimport time\n\napp = FastAPI()\nengine = create_engine(\"sqlite:///analytics.db\")\nSessionLocal = sessionmaker(bind=engine)\nredis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)\n\n@app.post(\"/track_event\")\nasync def track_event(event_id: str, user_id: str, data: dict):\n    session = SessionLocal()\n    lock_key = f\"lock:user:{user_id}\"\n    lock_acquired = False\n    try:\n        # Acquire distributed lock\n        lock_acquired = redis_client.set(lock_key, \"1\", nx=True, ex=5)\n        if not lock_acquired:\n            start = time.time()\n            while not lock_acquired and (time.time() - start) < 5:\n                time.sleep(0.1)\n                lock_acquired = redis_client.set(lock_key, \"1\", nx=True, ex=5)\n        \n        if lock_acquired:\n            # Insert event into database\n            query = \"INSERT INTO events (event_id, user_id, data) VALUES (?, ?, ?)\"\n            session.execute(query, (event_id, user_id, str(data)))\n            session.commit()\n            return {\"status\": \"success\"}\n        else:\n            return {\"status\": \"lock_timeout\", \"error\": \"Could not acquire lock\"}\n    finally:\n        if lock_acquired:\n            redis_client.delete(lock_key)\n        session.close()\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "LOCK", "idx": 2443}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION get_upload_metadata [id=f3133]\n  INTENT       \"retrieve cached upload metadata by file hash to avoid duplicate processing\"\n  PRECONDITION file_hash.length == 64\n  PRECONDITION upload_id IS NOT NULL\n  POSTCONDITION result.file_hash IS NOT NULL\n  READS        uploads_table\n  READS        file_metadata_cache\n  MUTATES      upload_access_log\n  OBSERVABLE\n\n  cached_entry = CACHE GET file_metadata_cache WITH KEY file_hash\n  IF cached_entry IS NOT NULL THEN\n    PERSIST upload_access_log (upload_id: upload_id, action: \"cache_hit\", timestamp: now())\n    RETURN cached_entry\n  END IF\n  \n  metadata = QUERY uploads_table WHERE file_hash == file_hash LIMIT 1\n  IF metadata IS NULL THEN FAIL NotFoundError(\"upload_not_found\")\n  \n  CACHE SET file_metadata_cache WITH KEY file_hash VALUE metadata TTL 3600\n  PERSIST upload_access_log (upload_id: upload_id, action: \"database_fetch\", timestamp: now())\n  RETURN metadata\nEND FUNCTION get_upload_metadata [id=f3133]", "completion": "# ═══ INTL:BEGIN [id=f3133] get_upload_metadata ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def get_upload_metadata(file_hash: str, upload_id: str) -> UploadMetadata:\n    assert len(file_hash) == 64, \"file_hash must be exactly 64 characters\"\n    assert upload_id is not None, \"upload_id must not be null\"\n    \n    cached_entry = await cache.get(f\"file_metadata:{file_hash}\")\n    if cached_entry is not None:\n        await db.insert(upload_access_log, \n                       upload_id=upload_id, \n                       action=\"cache_hit\", \n                       timestamp=datetime.utcnow())\n        logger.info(\"get_upload_metadata: cache_hit file_hash=%s upload_id=%s\", file_hash, upload_id)\n        result = UploadMetadata(**cached_entry)\n        assert result.file_hash is not None\n        return result\n    \n    metadata = await db.query(uploads_table).filter(file_hash=file_hash).first()\n    if metadata is None:\n        raise NotFoundError(\"upload_not_found\")\n    \n    await cache.set(f\"file_metadata:{file_hash}\", metadata.dict(), ex=3600)\n    await db.insert(upload_access_log, \n                   upload_id=upload_id, \n                   action=\"database_fetch\", \n                   timestamp=datetime.utcnow())\n    logger.info(\"get_upload_metadata: database_fetch file_hash=%s upload_id=%s\", file_hash, upload_id)\n    \n    result = UploadMetadata(**metadata)\n    assert result.file_hash is not None\n    return result\n# ═══ INTL:END   [id=f3133] get_upload_metadata ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CACHE GET", "idx": 3133}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION reserve_stock [id=f0742]\n  INTENT       \"atomically reserve inventory items and create reservation record\"\n  PRECONDITION product_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION quantity <= 10000\n  POSTCONDITION result.reservation_id IS NOT NULL\n  READS        inventory_table, products_table\n  MUTATES      inventory_table, reservations_table\n  OBSERVABLE\n\n  TRANSACTION\n    product = QUERY products_table WHERE id == product_id LIMIT 1\n    IF product IS NULL THEN FAIL NotFoundError(\"product_not_found\")\n    stock = QUERY inventory_table WHERE product_id == product_id LIMIT 1\n    IF stock IS NULL THEN FAIL NotFoundError(\"inventory_not_found\")\n    IF stock.available_quantity < quantity THEN FAIL InsufficientStockError(\"insufficient_stock\")\n    new_available = stock.available_quantity - quantity\n    new_reserved = stock.reserved_quantity + quantity\n    UPDATE inventory_table SET available_quantity = new_available, reserved_quantity = new_reserved WHERE product_id == product_id\n    reservation_id = generate_uuid()\n    PERSIST reservations_table (reservation_id: reservation_id, product_id: product_id, quantity: quantity, status: \"active\", created_at: now())\n    result = ReservationConfirm(reservation_id: reservation_id, product_id: product_id, reserved_quantity: quantity)\n  END TRANSACTION\n  RETURN result\nEND FUNCTION reserve_stock [id=f0742]", "completion": "# ═══ INTL:BEGIN [id=f0742] reserve_stock ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\n\nlogger = logging.getLogger(__name__)\n\nasync def reserve_stock(product_id: str, quantity: int) -> ReservationConfirm:\n    assert len(product_id) > 0, \"product_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    assert quantity <= 10000, \"quantity must not exceed 10000\"\n    \n    async with db.transaction():\n        product = await db.query(products_table).filter(id=product_id).first()\n        if product is None:\n            raise NotFoundError(\"product_not_found\")\n        \n        stock = await db.query(inventory_table).filter(product_id=product_id).first()\n        if stock is None:\n            raise NotFoundError(\"inventory_not_found\")\n        \n        if stock.available_quantity < quantity:\n            raise InsufficientStockError(\"insufficient_stock\")\n        \n        new_available = stock.available_quantity - quantity\n        new_reserved = stock.reserved_quantity + quantity\n        \n        await db.update(inventory_table).filter(product_id=product_id).set(\n            available_quantity=new_available,\n            reserved_quantity=new_reserved\n        )\n        \n        reservation_id = str(uuid4())\n        await db.insert(reservations_table,\n                       reservation_id=reservation_id,\n                       product_id=product_id,\n                       quantity=quantity,\n                       status=\"active\",\n                       created_at=datetime.utcnow())\n        \n        result = ReservationConfirm(\n            reservation_id=reservation_id,\n            product_id=product_id,\n            reserved_quantity=quantity\n        )\n        \n        assert result.reservation_id is not None\n        logger.info(\"reserve_stock: reservation_id=%s, product_id=%s, quantity=%d\",\n                   result.reservation_id, product_id, quantity)\n        return result\n# ═══ INTL:END   [id=f0742] reserve_stock ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 742}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION validate_login_attempts [id=f0420]\n  INTENT       \"validate user login attempts and enforce rate limiting\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION max_attempts > 0\n  PRECONDITION max_attempts <= 10\n  POSTCONDITION result.allowed IS NOT NULL\n  READS        login_attempts_table\n  MUTATES      login_attempts_table\n  OBSERVABLE\n\n  attempt_records = QUERY login_attempts_table WHERE user_id == user_id AND created_at > now()-1h\n  attempt_count = 0\n  LOOP OVER attempt_records AS record\n    IF record.success == FALSE THEN\n      attempt_count = attempt_count + 1\n    END IF\n  END LOOP\n  \n  IF attempt_count >= max_attempts THEN\n    PERSIST login_attempts_table (user_id: user_id, success: FALSE, created_at: now(), blocked: TRUE)\n    FAIL RateLimitError(\"too_many_failed_attempts\")\n  END IF\n  \n  PERSIST login_attempts_table (user_id: user_id, success: TRUE, created_at: now(), blocked: FALSE)\n  RETURN ValidationResult(allowed: TRUE, attempts_remaining: max_attempts - attempt_count)\nEND FUNCTION validate_login_attempts [id=f0420]", "completion": "# ═══ INTL:BEGIN [id=f0420] validate_login_attempts ═══\nimport logging\nfrom datetime import datetime, timedelta\n\nlogger = logging.getLogger(__name__)\n\nasync def validate_login_attempts(user_id: str, max_attempts: int) -> ValidationResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert max_attempts > 0, \"max_attempts must be positive\"\n    assert max_attempts <= 10, \"max_attempts must not exceed 10\"\n    \n    one_hour_ago = datetime.utcnow() - timedelta(hours=1)\n    attempt_records = await db.query(login_attempts_table).filter(\n        user_id=user_id,\n        created_at__gte=one_hour_ago\n    ).all()\n    \n    attempt_count = 0\n    for record in attempt_records:\n        if record.success is False:\n            attempt_count += 1\n    \n    if attempt_count >= max_attempts:\n        await db.insert(\n            login_attempts_table,\n            user_id=user_id,\n            success=False,\n            created_at=datetime.utcnow(),\n            blocked=True\n        )\n        logger.warning(\"validate_login_attempts: rate_limit_exceeded user=%s attempts=%d\", user_id, attempt_count)\n        raise RateLimitError(\"too_many_failed_attempts\")\n    \n    await db.insert(\n        login_attempts_table,\n        user_id=user_id,\n        success=True,\n        created_at=datetime.utcnow(),\n        blocked=False\n    )\n    logger.info(\"validate_login_attempts: validation_passed user=%s attempts_used=%d\", user_id, attempt_count)\n    result = ValidationResult(allowed=True, attempts_remaining=max_attempts - attempt_count)\n    assert result.allowed is not None\n    return result\n# ═══ INTL:END   [id=f0420] validate_login_attempts ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 420}}
