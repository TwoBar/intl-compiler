{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return {\n        \"id\": product.id,\n        \"name\": product.name,\n        \"price\": product.price,\n        \"description\": product.description\n    }\nINTL:END\n\nPATCH f0408 [target=f0408]\n  INTENT \"add confidence score to product response\"\n  ADD AFTER: \"description\": product.description\n    \"confidence\": product.confidence_score if product.confidence_score else 0.85\nEND PATCH f0408", "completion": "INTL:BEGIN\n@app.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return {\n        \"id\": product.id,\n        \"name\": product.name,\n        \"price\": product.price,\n        \"description\": product.description,\n        \"confidence\": product.confidence_score if product.confidence_score else 0.85\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 408}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_session [id=f0040]\n  INTENT       \"invalidate user session and log revocation event\"\n  PRECONDITION token.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.success IS TRUE\n  READS        sessions_table\n  MUTATES      sessions_table, audit_log_table\n  OBSERVABLE\n\n  session = QUERY sessions_table WHERE token == token LIMIT 1\n  IF session IS NULL THEN FAIL SessionError(\"session_not_found\")\n  IF session.user_id != user_id THEN FAIL SessionError(\"unauthorized_revocation\")\n  DELETE sessions_table WHERE token == token\n  PERSIST audit_log_table (user_id: user_id, action: \"session_revoked\", token_hash: hash(token), timestamp: now())\n  RETURN RevokeResult(success: TRUE)\nEND FUNCTION revoke_session [id=f0040]", "completion": "# ═══ INTL:BEGIN [id=f0040] revoke_session ═══\nimport logging\nfrom datetime import datetime\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_session(token: str, user_id: int) -> RevokeResult:\n    assert len(token) > 0, \"token must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    \n    session = await db.query(sessions_table).filter(token=token).first()\n    if session is None:\n        raise SessionError(\"session_not_found\")\n    if session.user_id != user_id:\n        raise SessionError(\"unauthorized_revocation\")\n    \n    await db.delete(sessions_table).filter(token=token)\n    \n    token_hash = hashlib.sha256(token.encode()).hexdigest()\n    await db.insert(audit_log_table, \n                    user_id=user_id, \n                    action=\"session_revoked\", \n                    token_hash=token_hash, \n                    timestamp=datetime.utcnow())\n    \n    logger.info(\"revoke_session: user_id=%d token_hash=%s\", user_id, token_hash[:16])\n    result = RevokeResult(success=True)\n    assert result.success is True\n    return result\n# ═══ INTL:END   [id=f0040] revoke_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 40}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/webhook/process\")\nasync def process_webhook(request: WebhookRequest):\n    result = validate_payload(request.data)\n    event_type = request.headers.get(\"x-event-type\")\n    return {\"status\": \"received\", \"event\": event_type}\nINTL:END\n\nPATCH f0730 [target=f0730]\n  INTENT \"add confidence scoring to webhook validation\"\n  ADD BEFORE: result = validate_payload(request.data)\n    confidence_score = calculate_confidence(request.headers, request.data)\n    if confidence_score < 0.7:\n        raise HTTPException(status_code=400, detail=\"Low confidence webhook\")\nEND PATCH f0730", "completion": "INTL:BEGIN\n@app.post(\"/webhook/process\")\nasync def process_webhook(request: WebhookRequest):\n    confidence_score = calculate_confidence(request.headers, request.data)\n    if confidence_score < 0.7:\n        raise HTTPException(status_code=400, detail=\"Low confidence webhook\")\n    result = validate_payload(request.data)\n    event_type = request.headers.get(\"x-event-type\")\n    return {\"status\": \"received\", \"event\": event_type}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 730}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI, HTTPException\nfrom typing import List\n\napp = FastAPI()\n\n@app.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    if product_id <= 0:\n        raise HTTPException(status_code=400, detail=\"Invalid product ID\")\n    return {\"product_id\": product_id, \"name\": \"Sample Product\"}\n\n@app.post(\"/products\")\nasync def create_product(name: str, price: float):\n    if not name or price < 0:\n        raise HTTPException(status_code=400, detail=\"Invalid input\")\n    return {\"id\": 1, \"name\": name, \"price\": price}\nINTL:END\n\nPATCH f1098 [target=f1098]\n  INTENT \"add rate limiting to product endpoints\"\n  ADD BEFORE: rate_limit_check(user_id) for get_product and create_product\n  MODIFY: import slowapi dependencies\nEND PATCH f1098", "completion": "INTL:BEGIN\nfrom fastapi import FastAPI, HTTPException, Request\nfrom slowapi import Limiter\nfrom slowapi.util import get_remote_address\nfrom typing import List\n\napp = FastAPI()\nlimiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\n\n@app.get(\"/products/{product_id}\")\n@limiter.limit(\"5/minute\")\nasync def get_product(request: Request, product_id: int):\n    if product_id <= 0:\n        raise HTTPException(status_code=400, detail=\"Invalid product ID\")\n    return {\"product_id\": product_id, \"name\": \"Sample Product\"}\n\n@app.post(\"/products\")\n@limiter.limit(\"3/minute\")\nasync def create_product(request: Request, name: str, price: float):\n    if not name or price < 0:\n        raise HTTPException(status_code=400, detail=\"Invalid input\")\n    return {\"id\": 1, \"name\": name, \"price\": price}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PATCH", "idx": 1098}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_permission_chain [id=f1420]\n  INTENT       \"grant a permission to a user through a sequence of validation and audit steps\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION permission_name.length > 0\n  PRECONDITION requester_role IN (\"admin\", \"manager\")\n  POSTCONDITION result.grant_id IS NOT NULL\n  READS        users_table, permissions_table, roles_table\n  MUTATES      user_permissions_table, audit_log_table\n  OBSERVABLE\n\n  SEQUENCE\n    Step 1: QUERY users_table WHERE id == user_id LIMIT 1\n      -> user = result\n      -> IF user IS NULL THEN FAIL ValidationError(\"user_not_found\")\n    \n    Step 2: QUERY permissions_table WHERE name == permission_name LIMIT 1\n      -> permission = result\n      -> IF permission IS NULL THEN FAIL ValidationError(\"permission_not_found\")\n    \n    Step 3: QUERY roles_table WHERE role_name == requester_role LIMIT 1\n      -> requester_role_record = result\n      -> IF requester_role_record.can_grant_permissions IS FALSE THEN FAIL AuthorizationError(\"insufficient_grant_rights\")\n    \n    Step 4: QUERY user_permissions_table WHERE user_id == user_id AND permission_id == permission.id LIMIT 1\n      -> existing_grant = result\n      -> IF existing_grant IS NOT NULL THEN FAIL ConflictError(\"permission_already_granted\")\n    \n    Step 5: PERSIST user_permissions_table (user_id: user_id, permission_id: permission.id, granted_at: now(), granted_by: requester_id)\n      -> grant_id = result.id\n    \n    Step 6: PERSIST audit_log_table (action: \"GRANT\", user_id: user_id, permission_id: permission.id, requester_id: requester_id, timestamp: now())\n  END SEQUENCE\n\n  RETURN GrantResult(grant_id: grant_id, permission_name: permission_name, user_id: user_id)\nEND FUNCTION grant_permission_chain [id=f1420]", "completion": "# ═══ INTL:BEGIN [id=f1420] grant_permission_chain ═══\nimport logging\nfrom datetime import datetime\nfrom typing import NamedTuple\n\nlogger = logging.getLogger(__name__)\n\nclass GrantResult(NamedTuple):\n    grant_id: str\n    permission_name: str\n    user_id: str\n\nasync def grant_permission_chain(\n    user_id: str,\n    permission_name: str,\n    requester_id: str,\n    requester_role: str\n) -> GrantResult:\n    # Preconditions\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(permission_name) > 0, \"permission_name must not be empty\"\n    assert requester_role in (\"admin\", \"manager\"), \"requester_role must be admin or manager\"\n    \n    # Step 1: Validate user exists\n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise ValidationError(\"user_not_found\")\n    \n    # Step 2: Validate permission exists\n    permission = await db.query(permissions_table).filter(name=permission_name).first()\n    if permission is None:\n        raise ValidationError(\"permission_not_found\")\n    \n    # Step 3: Validate requester has grant rights\n    requester_role_record = await db.query(roles_table).filter(role_name=requester_role).first()\n    if requester_role_record is None or not requester_role_record.can_grant_permissions:\n        raise AuthorizationError(\"insufficient_grant_rights\")\n    \n    # Step 4: Check permission not already granted\n    existing_grant = await db.query(user_permissions_table).filter(\n        user_id=user_id,\n        permission_id=permission.id\n    ).first()\n    if existing_grant is not None:\n        raise ConflictError(\"permission_already_granted\")\n    \n    # Step 5: Grant permission\n    grant_result = await db.insert(\n        user_permissions_table,\n        user_id=user_id,\n        permission_id=permission.id,\n        granted_at=datetime.utcnow(),\n        granted_by=requester_id\n    )\n    grant_id = grant_result.id\n    \n    # Step 6: Log audit event\n    await db.insert(\n        audit_log_table,\n        action=\"GRANT\",\n        user_id=user_id,\n        permission_id=permission.id,\n        requester_id=requester_id,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\n        \"grant_permission_chain: grant_id=%s user_id=%s permission=%s requester=%s\",\n        grant_id, user_id, permission_name, requester_id\n    )\n    \n    result = GrantResult(grant_id=grant_id, permission_name=permission_name, user_id=user_id)\n    assert result.grant_id is not None\n    return result\n# ═══ INTL:END   [id=f1420] grant_permission_chain ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 1420}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_order [id=f1742]\n  INTENT       \"process customer order and reserve inventory with confidence scoring\"\n  PRECONDITION order_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION customer_id IS NOT NULL\n  POSTCONDITION result.status IN (\"confirmed\", \"pending_approval\")\n  POSTCONDITION result.confidence >= 0.75\n  READS        orders_table, inventory_table, customers_table\n  MUTATES      orders_table, inventory_reservations_table\n  OBSERVABLE\n\n  order = QUERY orders_table WHERE id == order_id LIMIT 1\n  IF order IS NULL THEN FAIL OrderError(\"order_not_found\")\n  customer = QUERY customers_table WHERE id == customer_id LIMIT 1\n  IF customer IS NULL THEN FAIL OrderError(\"customer_not_found\")\n  inventory = QUERY inventory_table WHERE product_id == order.product_id LIMIT 1\n  IF inventory.available < quantity THEN FAIL OrderError(\"insufficient_stock\")\n  \n  confidence = 0.0\n  IF customer.credit_score >= 750 THEN confidence += 0.4\n  IF inventory.available >= (quantity * 2) THEN confidence += 0.35\n  IF order.total_amount < 5000 THEN confidence += 0.25\n  \n  status = \"confirmed\"\n  IF confidence < 0.75 THEN status = \"pending_approval\"\n  \n  PERSIST orders_table (id: order_id, status: status, confidence: confidence, processed_at: now())\n  PERSIST inventory_reservations_table (order_id: order_id, product_id: order.product_id, quantity: quantity, reserved_at: now())\n  RETURN OrderResult(order_id: order_id, status: status, confidence: confidence)\nEND FUNCTION process_order [id=f1742]", "completion": "# ═══ INTL:BEGIN [id=f1742] process_order ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def process_order(order_id: str, customer_id: str, quantity: int) -> OrderResult:\n    assert len(order_id) > 0, \"order_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    assert customer_id is not None, \"customer_id must not be null\"\n    \n    order = await db.query(orders_table).filter(id=order_id).first()\n    if order is None:\n        raise OrderError(\"order_not_found\")\n    \n    customer = await db.query(customers_table).filter(id=customer_id).first()\n    if customer is None:\n        raise OrderError(\"customer_not_found\")\n    \n    inventory = await db.query(inventory_table).filter(\n        product_id=order.product_id\n    ).first()\n    if inventory.available < quantity:\n        raise OrderError(\"insufficient_stock\")\n    \n    confidence = 0.0\n    if customer.credit_score >= 750:\n        confidence += 0.4\n    if inventory.available >= (quantity * 2):\n        confidence += 0.35\n    if order.total_amount < 5000:\n        confidence += 0.25\n    \n    status = \"confirmed\" if confidence >= 0.75 else \"pending_approval\"\n    \n    await db.update(\n        orders_table,\n        where={\"id\": order_id},\n        values={\n            \"status\": status,\n            \"confidence\": confidence,\n            \"processed_at\": datetime.utcnow()\n        }\n    )\n    \n    await db.insert(\n        inventory_reservations_table,\n        order_id=order_id,\n        product_id=order.product_id,\n        quantity=quantity,\n        reserved_at=datetime.utcnow()\n    )\n    \n    logger.info(\n        \"process_order: order_id=%s, customer_id=%s, status=%s, confidence=%.2f\",\n        order_id, customer_id, status, confidence\n    )\n    \n    result = OrderResult(order_id=order_id, status=status, confidence=confidence)\n    assert result.status in (\"confirmed\", \"pending_approval\"), \"invalid status\"\n    assert result.confidence >= 0.75 or result.status == \"pending_approval\", \"confidence postcondition\"\n    return result\n# ═══ INTL:END   [id=f1742] process_order ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 1742}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION normalize_user_profile [id=f2432]\n  INTENT       \"normalize and enrich user profile data with standardized fields\"\n  PRECONDITION user.name IS NOT NULL\n  PRECONDITION user.email IS NOT NULL\n  PRECONDITION len(user.name) >= 2\n  POSTCONDITION result.normalized_name IS NOT NULL\n  POSTCONDITION result.email_domain IS NOT NULL\n  READS        users_table\n  MUTATES      user_profiles_table\n  TRANSFORM    user.name -> trim().lower().title_case()\n  TRANSFORM    user.email -> extract_domain()\n  TRANSFORM    user.phone -> format_phone_number() IF user.phone IS NOT NULL\n  OBSERVABLE\n\n  normalized_name = TRANSFORM user.name WITH trim().lower().title_case()\n  email_domain = TRANSFORM user.email WITH extract_domain()\n  phone_formatted = IF user.phone IS NOT NULL THEN TRANSFORM user.phone WITH format_phone_number() ELSE NULL\n  created_at = now()\n  PERSIST user_profiles_table (user_id: user.id, normalized_name: normalized_name, email_domain: email_domain, phone: phone_formatted, created_at: created_at)\n  RETURN UserProfile(normalized_name: normalized_name, email_domain: email_domain, phone: phone_formatted, created_at: created_at)\nEND FUNCTION normalize_user_profile [id=f2432]", "completion": "# ═══ INTL:BEGIN [id=f2432] normalize_user_profile ═══\nimport logging\nfrom datetime import datetime\nimport re\n\nlogger = logging.getLogger(__name__)\n\ndef extract_domain(email: str) -> str:\n    \"\"\"Extract domain from email address.\"\"\"\n    return email.split('@')[1] if '@' in email else \"\"\n\ndef format_phone_number(phone: str) -> str:\n    \"\"\"Format phone number to standard format.\"\"\"\n    digits = re.sub(r'\\D', '', phone)\n    if len(digits) == 10:\n        return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n    elif len(digits) == 11 and digits[0] == '1':\n        return f\"+1 ({digits[1:4]}) {digits[4:7]}-{digits[7:]}\"\n    return phone\n\nasync def normalize_user_profile(user: UserInput) -> UserProfile:\n    assert user.name is not None, \"user name must not be null\"\n    assert user.email is not None, \"user email must not be null\"\n    assert len(user.name) >= 2, \"user name must be at least 2 characters\"\n    \n    normalized_name = user.name.strip().lower().title()\n    email_domain = extract_domain(user.email)\n    phone_formatted = format_phone_number(user.phone) if user.phone is not None else None\n    created_at = datetime.utcnow()\n    \n    await db.insert(\n        user_profiles_table,\n        user_id=user.id,\n        normalized_name=normalized_name,\n        email_domain=email_domain,\n        phone=phone_formatted,\n        created_at=created_at\n    )\n    \n    logger.info(\"normalize_user_profile: user_id=%s, normalized_name=%s, email_domain=%s\", \n                user.id, normalized_name, email_domain)\n    \n    result = UserProfile(\n        normalized_name=normalized_name,\n        email_domain=email_domain,\n        phone=phone_formatted,\n        created_at=created_at\n    )\n    assert result.normalized_name is not None\n    assert result.email_domain is not None\n    return result\n# ═══ INTL:END   [id=f2432] normalize_user_profile ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 2432}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_inventory [id=f2754]\n  INTENT       \"replenish stock for a product and log the transaction\"\n  PRECONDITION product_id.length > 0\n  PRECONDITION quantity > 0\n  PRECONDITION warehouse_id.length > 0\n  POSTCONDITION result.stock_level >= 0\n  READS        products_table, warehouses_table\n  MUTATES      inventory_table, audit_log_table\n  OBSERVABLE\n\n  warehouse = QUERY warehouses_table WHERE id == warehouse_id LIMIT 1\n  FALLBACK warehouse = DEFAULT_WAREHOUSE()\n  \n  product = QUERY products_table WHERE id == product_id LIMIT 1\n  IF product IS NULL THEN FAIL ProductError(\"product_not_found\")\n  \n  current_stock = QUERY inventory_table WHERE product_id == product_id AND warehouse_id == warehouse.id LIMIT 1\n  FALLBACK current_stock = InventoryRecord(product_id: product_id, warehouse_id: warehouse.id, quantity: 0)\n  \n  new_stock = current_stock.quantity + quantity\n  PERSIST inventory_table (product_id: product_id, warehouse_id: warehouse.id, quantity: new_stock, updated_at: now())\n  PERSIST audit_log_table (product_id: product_id, action: \"restock\", quantity_delta: quantity, warehouse_id: warehouse.id, timestamp: now())\n  \n  RETURN RestockResult(stock_level: new_stock, warehouse_id: warehouse.id)\nEND FUNCTION restock_inventory [id=f2754]", "completion": "# ═══ INTL:BEGIN [id=f2754] restock_inventory ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_inventory(product_id: str, quantity: int, warehouse_id: str) -> RestockResult:\n    assert len(product_id) > 0, \"product_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than zero\"\n    assert len(warehouse_id) > 0, \"warehouse_id must not be empty\"\n    \n    warehouse = await db.query(warehouses_table).filter(id=warehouse_id).first()\n    if warehouse is None:\n        warehouse = DEFAULT_WAREHOUSE()\n    \n    product = await db.query(products_table).filter(id=product_id).first()\n    if product is None:\n        raise ProductError(\"product_not_found\")\n    \n    current_stock = await db.query(inventory_table).filter(\n        product_id=product_id, warehouse_id=warehouse.id\n    ).first()\n    if current_stock is None:\n        current_stock = InventoryRecord(\n            product_id=product_id,\n            warehouse_id=warehouse.id,\n            quantity=0\n        )\n    \n    new_stock = current_stock.quantity + quantity\n    \n    await db.update(\n        inventory_table,\n        filter_dict={\"product_id\": product_id, \"warehouse_id\": warehouse.id},\n        update_dict={\n            \"quantity\": new_stock,\n            \"updated_at\": datetime.utcnow()\n        }\n    )\n    \n    await db.insert(\n        audit_log_table,\n        product_id=product_id,\n        action=\"restock\",\n        quantity_delta=quantity,\n        warehouse_id=warehouse.id,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"restock_inventory: product=%s warehouse=%s quantity_delta=%d new_stock=%d\",\n                product_id, warehouse.id, quantity, new_stock)\n    \n    result = RestockResult(stock_level=new_stock, warehouse_id=warehouse.id)\n    assert result.stock_level >= 0, \"stock_level must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f2754] restock_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 2754}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/search\")\nasync def search_products(query: str, db: Session = Depends(get_db)):\n    results = db.query(Product).filter(Product.name.contains(query)).all()\n    return {\"results\": results, \"count\": len(results)}\nINTL:END\n\nPATCH f3122 [target=f3122]\n  INTENT \"wrap search query in database transaction with rollback on error\"\n  ADD BEFORE: db.begin()\n  ADD AFTER: db.commit()\n  ADD EXCEPT: db.rollback()\nEND PATCH f3122", "completion": "INTL:BEGIN\n@router.post(\"/search\")\nasync def search_products(query: str, db: Session = Depends(get_db)):\n    try:\n        db.begin()\n        results = db.query(Product).filter(Product.name.contains(query)).all()\n        db.commit()\n        return {\"results\": results, \"count\": len(results)}\n    except Exception:\n        db.rollback()\n        raise\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 3122}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\napp = FastAPI()\nengine = create_engine(\"sqlite:///analytics.db\")\nSessionLocal = sessionmaker(bind=engine)\n\n@app.get(\"/metrics/{metric_id}\")\ndef get_metric(metric_id: int):\n    session = SessionLocal()\n    result = session.query(Metric).filter(Metric.id == metric_id).first()\n    session.close()\n    return result\n\n@app.post(\"/metrics\")\ndef create_metric(data: dict):\n    session = SessionLocal()\n    metric = Metric(**data)\n    session.add(metric)\n    session.commit()\n    session.close()\n    return metric\nINTL:END\n\nPATCH f0041 [target=f0041]\n  INTENT \"add database lock for concurrent analytics writes\"\n  ADD BEFORE: session.add(metric)\n  LOCK: with_for_update() on query to prevent race conditions\nEND PATCH f0041", "completion": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\napp = FastAPI()\nengine = create_engine(\"sqlite:///analytics.db\")\nSessionLocal = sessionmaker(bind=engine)\n\n@app.get(\"/metrics/{metric_id}\")\ndef get_metric(metric_id: int):\n    session = SessionLocal()\n    result = session.query(Metric).filter(Metric.id == metric_id).first()\n    session.close()\n    return result\n\n@app.post(\"/metrics\")\ndef create_metric(data: dict):\n    session = SessionLocal()\n    metric = Metric(**data)\n    with session.begin_nested():\n        session.query(Metric).with_for_update().filter(Metric.id == metric_id).first()\n        session.add(metric)\n    session.commit()\n    session.close()\n    return metric\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "LOCK", "idx": 41}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/products/summary\")\nasync def get_product_summary(category: str = None):\n    products = await db.query(Product).filter_by(category=category).all()\n    total_price = sum(p.price for p in products)\n    total_count = len(products)\n    return {\n        \"category\": category,\n        \"total_count\": total_count,\n        \"total_price\": total_price,\n        \"products\": products\n    }\nINTL:END\n\nPATCH f0409 [target=f0409]\n  INTENT \"add inventory aggregation to product summary response\"\n  ADD BEFORE: return statement\n  AGGREGATE inventory_status: group products by stock level (in_stock, low_stock, out_of_stock)\nEND PATCH f0409", "completion": "INTL:BEGIN\n@router.get(\"/products/summary\")\nasync def get_product_summary(category: str = None):\n    products = await db.query(Product).filter_by(category=category).all()\n    total_price = sum(p.price for p in products)\n    total_count = len(products)\n    \n    inventory_status = {\n        \"in_stock\": len([p for p in products if p.stock > 10]),\n        \"low_stock\": len([p for p in products if 0 < p.stock <= 10]),\n        \"out_of_stock\": len([p for p in products if p.stock == 0])\n    }\n    \n    return {\n        \"category\": category,\n        \"total_count\": total_count,\n        \"total_price\": total_price,\n        \"inventory_status\": inventory_status,\n        \"products\": products\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "AGGREGATE", "idx": 409}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION activate_user_workflow [id=f1099]\n  INTENT       \"activate a user account through email verification and profile completion sequence\"\n  PRECONDITION user_id > 0\n  PRECONDITION verification_code.length == 6\n  PRECONDITION full_name.length > 0\n  POSTCONDITION result.is_active == TRUE\n  READS        users_table\n  READS        verification_codes_table\n  MUTATES      users_table\n  MUTATES      verification_codes_table\n  OBSERVABLE\n\n  SEQUENCE\n    code_record = QUERY verification_codes_table WHERE user_id == user_id AND code == verification_code LIMIT 1\n    IF code_record IS NULL THEN FAIL ValidationError(\"invalid_verification_code\")\n    IF code_record.expires_at < now() THEN FAIL ValidationError(\"code_expired\")\n    user = QUERY users_table WHERE id == user_id LIMIT 1\n    IF user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n    IF user.is_active == TRUE THEN FAIL ConflictError(\"user_already_active\")\n    PERSIST users_table (id: user_id, full_name: full_name, is_active: TRUE, activated_at: now())\n    DELETE verification_codes_table WHERE user_id == user_id\n  END SEQUENCE\n\n  RETURN UserActivated(user_id: user_id, is_active: TRUE, activated_at: now())\nEND FUNCTION activate_user_workflow [id=f1099]", "completion": "# ═══ INTL:BEGIN [id=f1099] activate_user_workflow ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def activate_user_workflow(user_id: int, verification_code: str, full_name: str) -> UserActivated:\n    assert user_id > 0, \"user_id must be positive\"\n    assert len(verification_code) == 6, \"verification_code must be exactly 6 characters\"\n    assert len(full_name) > 0, \"full_name must not be empty\"\n    \n    code_record = await db.query(verification_codes_table).filter(\n        user_id=user_id, code=verification_code\n    ).first()\n    if code_record is None:\n        raise ValidationError(\"invalid_verification_code\")\n    \n    if code_record.expires_at < datetime.utcnow():\n        raise ValidationError(\"code_expired\")\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    if user.is_active is True:\n        raise ConflictError(\"user_already_active\")\n    \n    now = datetime.utcnow()\n    await db.update(users_table, where={\"id\": user_id},\n                    values={\"full_name\": full_name, \"is_active\": True, \"activated_at\": now})\n    \n    await db.delete(verification_codes_table, where={\"user_id\": user_id})\n    \n    logger.info(\"activate_user_workflow: user_id=%d activated with full_name=%s\", user_id, full_name)\n    \n    result = UserActivated(user_id=user_id, is_active=True, activated_at=now)\n    assert result.is_active is True\n    return result\n# ═══ INTL:END   [id=f1099] activate_user_workflow ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 1099}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION compute_user_cohort_metrics [id=f0731]\n  INTENT       \"aggregate cohort analytics and persist metrics within SLA\"\n  PRECONDITION cohort_id.length > 0\n  PRECONDITION time_window_days > 0\n  PRECONDITION time_window_days <= 365\n  TIMEOUT      30s\n  POSTCONDITION result.metrics_id IS NOT NULL\n  POSTCONDITION result.computed_at IS NOT NULL\n  READS        events_table\n  READS        users_table\n  MUTATES      cohort_metrics_table\n  OBSERVABLE\n\n  IF cohort_id IS EMPTY THEN FAIL ValidationError(\"cohort_id_required\")\n  events = QUERY events_table WHERE cohort_id == cohort_id AND created_at >= now()-time_window_days*days TIMEOUT 15s\n  IF events IS NULL THEN FAIL QueryError(\"events_unavailable\")\n  retention = COUNT(events WHERE event_type == \"retention\") / COUNT(events)\n  engagement = SUM(events.engagement_score) / COUNT(events)\n  metrics_id = generate_uuid()\n  PERSIST cohort_metrics_table (metrics_id: metrics_id, cohort_id: cohort_id, retention: retention, engagement: engagement, computed_at: now())\n  RETURN CohortMetrics(metrics_id: metrics_id, retention: retention, engagement: engagement, computed_at: now())\nEND FUNCTION compute_user_cohort_metrics [id=f0731]", "completion": "# ═══ INTL:BEGIN [id=f0731] compute_user_cohort_metrics ═══\nimport logging\nimport asyncio\nfrom datetime import datetime, timedelta\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\nasync def compute_user_cohort_metrics(cohort_id: str, time_window_days: int) -> CohortMetrics:\n    assert len(cohort_id) > 0, \"cohort_id must not be empty\"\n    assert time_window_days > 0, \"time_window_days must be positive\"\n    assert time_window_days <= 365, \"time_window_days must not exceed 365\"\n    \n    if not cohort_id:\n        raise ValidationError(\"cohort_id_required\")\n    \n    try:\n        events = await asyncio.wait_for(\n            db.query(events_table)\n              .filter(cohort_id=cohort_id, created_at__gte=datetime.utcnow() - timedelta(days=time_window_days))\n              .all(),\n            timeout=15.0\n        )\n    except asyncio.TimeoutError:\n        raise QueryError(\"events_unavailable\")\n    \n    if events is None or len(events) == 0:\n        raise QueryError(\"events_unavailable\")\n    \n    retention_count = sum(1 for e in events if e.event_type == \"retention\")\n    retention = retention_count / len(events) if len(events) > 0 else 0.0\n    engagement = sum(e.engagement_score for e in events) / len(events) if len(events) > 0 else 0.0\n    \n    metrics_id = str(uuid.uuid4())\n    computed_at = datetime.utcnow()\n    \n    await db.insert(\n        cohort_metrics_table,\n        metrics_id=metrics_id,\n        cohort_id=cohort_id,\n        retention=retention,\n        engagement=engagement,\n        computed_at=computed_at\n    )\n    \n    logger.info(\"compute_user_cohort_metrics: cohort_id=%s, metrics_id=%s, retention=%.2f, engagement=%.2f\",\n                cohort_id, metrics_id, retention, engagement)\n    \n    result = CohortMetrics(\n        metrics_id=metrics_id,\n        retention=retention,\n        engagement=engagement,\n        computed_at=computed_at\n    )\n    \n    assert result.metrics_id is not None\n    assert result.computed_at is not None\n    return result\n# ═══ INTL:END   [id=f0731] compute_user_cohort_metrics ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TIMEOUT", "idx": 731}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/reviews\")\nasync def get_reviews(skip: int = 0, limit: int = 10):\n    reviews = db.query(Review).offset(skip).limit(limit).all()\n    return reviews\nINTL:END\n\nPATCH f1743 [target=f1743]\n  INTENT \"add filtering by rating to the review query\"\n  ADD PARAMETER: rating: int = None\n  MODIFY QUERY: filter by rating if provided\nEND PATCH f1743", "completion": "INTL:BEGIN\n@app.get(\"/reviews\")\nasync def get_reviews(skip: int = 0, limit: int = 10, rating: int = None):\n    query = db.query(Review)\n    if rating is not None:\n        query = query.filter(Review.rating == rating)\n    reviews = query.offset(skip).limit(limit).all()\n    return reviews\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "QUERY", "idx": 1743}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_bulk_permissions [id=f1421]\n  INTENT       \"grant multiple permissions to a user in batch\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION permissions_list.length > 0\n  PRECONDITION permissions_list.length <= 100\n  POSTCONDITION result.granted_count == permissions_list.length\n  READS        users_table\n  READS        permissions_catalog\n  MUTATES      user_permissions_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n  \n  granted_count = 0\n  LOOP permission IN permissions_list DO\n    perm_def = QUERY permissions_catalog WHERE name == permission LIMIT 1\n    IF perm_def IS NULL THEN CONTINUE\n    \n    existing = QUERY user_permissions_table WHERE user_id == user_id AND permission == permission LIMIT 1\n    IF existing IS NOT NULL THEN CONTINUE\n    \n    PERSIST user_permissions_table (user_id: user_id, permission: permission, granted_at: now())\n    granted_count = granted_count + 1\n  END LOOP\n  \n  RETURN GrantResult(granted_count: granted_count, user_id: user_id)\nEND FUNCTION grant_bulk_permissions [id=f1421]", "completion": "# ═══ INTL:BEGIN [id=f1421] grant_bulk_permissions ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def grant_bulk_permissions(user_id: str, permissions_list: List[str]) -> GrantResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(permissions_list) > 0, \"permissions_list must not be empty\"\n    assert len(permissions_list) <= 100, \"permissions_list must not exceed 100 items\"\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    granted_count = 0\n    for permission in permissions_list:\n        perm_def = await db.query(permissions_catalog).filter(name=permission).first()\n        if perm_def is None:\n            continue\n        \n        existing = await db.query(user_permissions_table).filter(\n            user_id=user_id, permission=permission\n        ).first()\n        if existing is not None:\n            continue\n        \n        await db.insert(user_permissions_table, \n                       user_id=user_id, \n                       permission=permission,\n                       granted_at=datetime.utcnow())\n        granted_count += 1\n    \n    logger.info(\"grant_bulk_permissions: user=%s, granted=%d, total_requested=%d\", \n                user_id, granted_count, len(permissions_list))\n    \n    result = GrantResult(granted_count=granted_count, user_id=user_id)\n    assert result.granted_count == granted_count\n    return result\n# ═══ INTL:END   [id=f1421] grant_bulk_permissions ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 1421}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/analytics/events\")\nasync def get_events(user_id: str, limit: int = 100):\n    events = db.query(Event).filter(Event.user_id == user_id).limit(limit).all()\n    return {\n        \"user_id\": user_id,\n        \"event_count\": len(events),\n        \"events\": [\n            {\n                \"id\": e.id,\n                \"timestamp\": e.timestamp,\n                \"event_type\": e.event_type,\n                \"data\": e.data\n            }\n            for e in events\n        ]\n    }\nINTL:END\n\nPATCH f2111 [target=f2111]\n  INTENT \"transform raw event data to include calculated metrics\"\n  TRANSFORM events INTO enriched_events:\n    ADD FIELD: duration_ms = e.duration if hasattr(e, 'duration') else 0\n    ADD FIELD: severity_level = classify_severity(e.event_type)\n    REMOVE FIELD: data\nEND PATCH f2111", "completion": "INTL:BEGIN\n@app.get(\"/analytics/events\")\nasync def get_events(user_id: str, limit: int = 100):\n    events = db.query(Event).filter(Event.user_id == user_id).limit(limit).all()\n    enriched_events = [\n        {\n            \"id\": e.id,\n            \"timestamp\": e.timestamp,\n            \"event_type\": e.event_type,\n            \"duration_ms\": e.duration if hasattr(e, 'duration') else 0,\n            \"severity_level\": classify_severity(e.event_type)\n        }\n        for e in events\n    ]\n    return {\n        \"user_id\": user_id,\n        \"event_count\": len(enriched_events),\n        \"events\": enriched_events\n    }\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 2111}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/coupons/{coupon_id}\")\nasync def get_coupon(coupon_id: str, db: Session = Depends(get_db)):\n    coupon = db.query(Coupon).filter(Coupon.id == coupon_id).first()\n    if not coupon:\n        raise HTTPException(status_code=404, detail=\"Coupon not found\")\n    return coupon\nINTL:END\n\nPATCH f2755 [target=f2755]\n  INTENT \"add fallback response when coupon service is unavailable\"\n  ADD FALLBACK: return {\"id\": coupon_id, \"status\": \"unavailable\", \"discount\": 0}\nEND PATCH f2755", "completion": "INTL:BEGIN\n@router.get(\"/coupons/{coupon_id}\")\nasync def get_coupon(coupon_id: str, db: Session = Depends(get_db)):\n    try:\n        coupon = db.query(Coupon).filter(Coupon.id == coupon_id).first()\n        if not coupon:\n            raise HTTPException(status_code=404, detail=\"Coupon not found\")\n        return coupon\n    except Exception:\n        return {\"id\": coupon_id, \"status\": \"unavailable\", \"discount\": 0}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 2755}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: int):\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    return review\nINTL:END\n\nPATCH f3123 [target=f3123]\n  INTENT \"add response timestamp to review return\"\n  MODIFY RETURN: include created_at field in response\nEND PATCH f3123", "completion": "INTL:BEGIN\n@app.get(\"/reviews/{review_id}\")\nasync def get_review(review_id: int):\n    review = db.query(Review).filter(Review.id == review_id).first()\n    if not review:\n        raise HTTPException(status_code=404, detail=\"Review not found\")\n    return {**review.__dict__, \"created_at\": review.created_at}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "RETURN", "idx": 3123}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return product\nINTL:END\n\nPATCH f0042 [target=f0042]\n  INTENT \"emit structured product response with metadata\"\n  EMIT SCHEMA: ProductResponse\n  ADD BEFORE return: response_metadata = {\"timestamp\": datetime.now(), \"version\": \"1.0\"}\n  MODIFY return: return {**product.dict(), \"meta\": response_metadata}\nEND PATCH f0042", "completion": "INTL:BEGIN\n@router.get(\"/products/{product_id}\")\nasync def get_product(product_id: int):\n    product = db.query(Product).filter(Product.id == product_id).first()\n    if not product:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    response_metadata = {\"timestamp\": datetime.now(), \"version\": \"1.0\"}\n    return {**product.dict(), \"meta\": response_metadata}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "EMIT", "idx": 42}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_api_key [id=f0410]\n  INTENT       \"revoke an active API key and prevent further use\"\n  PRECONDITION key_id.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.revoked_at IS NOT NULL\n  READS        api_keys_table\n  MUTATES      api_keys_table\n  LOCK         api_keys_table FOR UPDATE\n  OBSERVABLE\n\n  LOCK api_keys_table FOR UPDATE\n  key_record = QUERY api_keys_table WHERE id == key_id LIMIT 1\n  IF key_record IS NULL THEN FAIL NotFoundError(\"key_not_found\")\n  IF key_record.user_id != user_id THEN FAIL PermissionError(\"unauthorized_revocation\")\n  IF key_record.revoked_at IS NOT NULL THEN FAIL ConflictError(\"key_already_revoked\")\n  now_timestamp = now()\n  UPDATE api_keys_table SET revoked_at = now_timestamp WHERE id == key_id\n  RETURN ApiKeyRevocationResult(key_id: key_id, revoked_at: now_timestamp)\nEND FUNCTION revoke_api_key [id=f0410]", "completion": "# ═══ INTL:BEGIN [id=f0410] revoke_api_key ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_api_key(key_id: str, user_id: int) -> ApiKeyRevocationResult:\n    assert len(key_id) > 0, \"key_id must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    \n    async with db.transaction():\n        async with db.lock(api_keys_table, mode=\"FOR UPDATE\"):\n            key_record = await db.query(api_keys_table).filter(id=key_id).first()\n            if key_record is None:\n                raise NotFoundError(\"key_not_found\")\n            if key_record.user_id != user_id:\n                raise PermissionError(\"unauthorized_revocation\")\n            if key_record.revoked_at is not None:\n                raise ConflictError(\"key_already_revoked\")\n            \n            now_timestamp = datetime.utcnow()\n            await db.update(api_keys_table).filter(id=key_id).set(revoked_at=now_timestamp)\n            logger.info(\"revoke_api_key: key_id=%s user_id=%s revoked_at=%s\", \n                       key_id, user_id, now_timestamp)\n            \n            result = ApiKeyRevocationResult(key_id=key_id, revoked_at=now_timestamp)\n            assert result.revoked_at is not None\n            return result\n# ═══ INTL:END   [id=f0410] revoke_api_key ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOCK", "idx": 410}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION rotate_api_key [id=f1100]\n  INTENT       \"rotate an existing API key and emit audit event\"\n  PRECONDITION key_id.length > 0\n  PRECONDITION user_id > 0\n  PRECONDITION reason.length > 0\n  POSTCONDITION result.new_key IS NOT NULL\n  POSTCONDITION result.old_key_revoked IS TRUE\n  READS        api_keys_table\n  MUTATES      api_keys_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n  \n  existing_key = QUERY api_keys_table WHERE id == key_id AND owner_id == user_id LIMIT 1\n  IF existing_key IS NULL THEN FAIL KeyError(\"key_not_found\")\n  IF existing_key.revoked IS TRUE THEN FAIL KeyError(\"key_already_revoked\")\n  \n  new_key_value = generate_secure_key()\n  new_key_hash = hash_key(new_key_value)\n  \n  PERSIST api_keys_table (id: key_id, hash: new_key_hash, rotated_at: now(), revoked: FALSE)\n  PERSIST api_keys_table (owner_id: user_id, revoked: TRUE, revoked_at: now())\n  \n  EMIT AuditEvent(event_type: \"key_rotation\", user_id: user_id, key_id: key_id, \n                  reason: reason, timestamp: now())\n  \n  RETURN KeyRotationResult(new_key: new_key_value, old_key_revoked: TRUE)\nEND FUNCTION rotate_api_key [id=f1100]", "completion": "# ═══ INTL:BEGIN [id=f1100] rotate_api_key ═══\nimport logging\nfrom datetime import datetime\nimport secrets\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def rotate_api_key(key_id: str, user_id: int, reason: str) -> KeyRotationResult:\n    assert len(key_id) > 0, \"key_id must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    assert len(reason) > 0, \"reason must not be empty\"\n    \n    existing_key = await db.query(api_keys_table).filter(\n        id=key_id, owner_id=user_id\n    ).first()\n    \n    if existing_key is None:\n        raise KeyError(\"key_not_found\")\n    if existing_key.revoked is True:\n        raise KeyError(\"key_already_revoked\")\n    \n    new_key_value = secrets.token_urlsafe(32)\n    new_key_hash = hashlib.sha256(new_key_value.encode()).hexdigest()\n    \n    await db.update(api_keys_table, \n                   where={\"id\": key_id},\n                   hash=new_key_hash,\n                   rotated_at=datetime.utcnow(),\n                   revoked=False)\n    \n    await db.update(api_keys_table,\n                   where={\"owner_id\": user_id, \"id\": key_id},\n                   revoked=True,\n                   revoked_at=datetime.utcnow())\n    \n    await db.insert(audit_log_table,\n                   event_type=\"key_rotation\",\n                   user_id=user_id,\n                   key_id=key_id,\n                   reason=reason,\n                   timestamp=datetime.utcnow())\n    \n    logger.info(\"rotate_api_key: user_id=%d key_id=%s reason=%s\", user_id, key_id, reason)\n    \n    result = KeyRotationResult(new_key=new_key_value, old_key_revoked=True)\n    assert result.new_key is not None\n    assert result.old_key_revoked is True\n    return result\n# ═══ INTL:END   [id=f1100] rotate_api_key ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "EMIT", "idx": 1100}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_shipments [id=f1744]\n  INTENT       \"process pending shipments and update tracking status\"\n  PRECONDITION shipments IS NOT NULL\n  PRECONDITION max_batch_size > 0\n  POSTCONDITION processed_count >= 0\n  READS        shipments_table\n  MUTATES      shipments_table\n  MUTATES      tracking_history_table\n  OBSERVABLE\n\n  processed_count = 0\n  LOOP shipment IN QUERY shipments_table WHERE status == \"pending\" LIMIT max_batch_size\n    IF shipment.carrier_id IS NULL THEN CONTINUE\n    tracking_info = fetch_carrier_tracking(shipment.carrier_id, shipment.tracking_number)\n    IF tracking_info.current_status != shipment.status THEN\n      UPDATE shipments_table SET status = tracking_info.current_status WHERE id == shipment.id\n      PERSIST tracking_history_table (shipment_id: shipment.id, old_status: shipment.status, new_status: tracking_info.current_status, updated_at: now())\n      processed_count = processed_count + 1\n    END IF\n  END LOOP\n  RETURN ShipmentResult(processed: processed_count)\nEND FUNCTION process_shipments [id=f1744]", "completion": "# ═══ INTL:BEGIN [id=f1744] process_shipments ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def process_shipments(shipments: List[dict], max_batch_size: int) -> ShipmentResult:\n    assert shipments is not None, \"shipments must not be null\"\n    assert max_batch_size > 0, \"max_batch_size must be greater than 0\"\n    \n    processed_count = 0\n    pending_shipments = await db.query(shipments_table).filter(\n        status=\"pending\"\n    ).limit(max_batch_size).all()\n    \n    for shipment in pending_shipments:\n        if shipment.carrier_id is None:\n            continue\n        \n        tracking_info = await fetch_carrier_tracking(\n            shipment.carrier_id,\n            shipment.tracking_number\n        )\n        \n        if tracking_info.current_status != shipment.status:\n            old_status = shipment.status\n            new_status = tracking_info.current_status\n            \n            await db.update(\n                shipments_table,\n                where={\"id\": shipment.id},\n                values={\"status\": new_status}\n            )\n            \n            await db.insert(\n                tracking_history_table,\n                shipment_id=shipment.id,\n                old_status=old_status,\n                new_status=new_status,\n                updated_at=datetime.utcnow()\n            )\n            \n            processed_count += 1\n            logger.info(\n                \"process_shipments: shipment_id=%s status_changed=%s->%s\",\n                shipment.id,\n                old_status,\n                new_status\n            )\n    \n    result = ShipmentResult(processed=processed_count)\n    assert result.processed >= 0, \"processed_count must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f1744] process_shipments ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 1744}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION update_user_profile [id=f2434]\n  INTENT       \"apply partial updates to user profile and log the change\"\n  PRECONDITION user_id > 0\n  PRECONDITION updates IS NOT NULL\n  PRECONDITION updates.display_name.length <= 255\n  POSTCONDITION result.updated_at IS NOT NULL\n  READS        users_table\n  MUTATES      users_table audit_log_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n  PATCH user WITH updates\n  PERSIST users_table user\n  PERSIST audit_log_table (user_id: user_id, action: \"profile_update\", changes: updates, timestamp: now())\n  RETURN UserProfile(id: user.id, display_name: user.display_name, email: user.email, updated_at: user.updated_at)\nEND FUNCTION update_user_profile [id=f2434]", "completion": "# ═══ INTL:BEGIN [id=f2434] update_user_profile ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def update_user_profile(user_id: int, updates: dict) -> UserProfile:\n    assert user_id > 0, \"user_id must be positive\"\n    assert updates is not None, \"updates must not be null\"\n    assert updates.get(\"display_name\") is None or len(updates[\"display_name\"]) <= 255, \"display_name must not exceed 255 chars\"\n    \n    user = await db.query(users_table).filter(id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    user.update(updates)\n    user.updated_at = datetime.utcnow()\n    await db.update(users_table, user)\n    \n    await db.insert(audit_log_table, user_id=user_id, action=\"profile_update\", \n                    changes=updates, timestamp=datetime.utcnow())\n    \n    logger.info(\"update_user_profile: user_id=%d, changes=%s\", user_id, updates)\n    \n    result = UserProfile(id=user.id, display_name=user.display_name, \n                        email=user.email, updated_at=user.updated_at)\n    assert result.updated_at is not None\n    return result\n# ═══ INTL:END   [id=f2434] update_user_profile ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PATCH", "idx": 2434}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    contents = await file.read()\n    with open(file.filename, \"wb\") as f:\n        f.write(contents)\n    return {\"filename\": file.filename}\nINTL:END\n\nPATCH f2756 [target=f2756]\n  INTENT \"validate file sequence: check mime type before read, then verify size after read, then write to disk\"\n  ADD BEFORE: contents = await file.read() | validate_mimetype(file.content_type)\n  ADD AFTER: contents = await file.read() | verify_size(contents, MAX_SIZE)\n  ADD BEFORE: f.write(contents) | sanitize_filename(file.filename)\nEND PATCH f2756", "completion": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    validate_mimetype(file.content_type)\n    contents = await file.read()\n    verify_size(contents, MAX_SIZE)\n    with open(sanitize_filename(file.filename), \"wb\") as f:\n        f.write(contents)\n    return {\"filename\": file.filename}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 2756}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION send_notification [id=f3124]\n  INTENT       \"deliver notification to user and track delivery status\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION message.length > 0\n  PRECONDITION message.length <= 500\n  PRECONDITION recipient_email IS NOT NULL\n  POSTCONDITION result.notification_id IS NOT NULL\n  POSTCONDITION result.delivered IS TRUE\n  READS        users_table\n  MUTATES      notifications_table\n  MUTATES      delivery_log_table\n  OBSERVABLE\n\n  user = QUERY users_table WHERE user_id == user_id LIMIT 1\n  IF user IS NULL THEN FAIL NotFoundError(\"user_does_not_exist\")\n  notification_id = generate_uuid()\n  PERSIST notifications_table (id: notification_id, user_id: user_id, message: message, created_at: now())\n  PERSIST delivery_log_table (notification_id: notification_id, recipient: recipient_email, status: \"sent\", sent_at: now())\n  RETURN NotificationResult(notification_id: notification_id, delivered: TRUE)\nEND FUNCTION send_notification [id=f3124]", "completion": "# ═══ INTL:BEGIN [id=f3124] send_notification ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\n\nlogger = logging.getLogger(__name__)\n\nasync def send_notification(user_id: str, message: str, recipient_email: str) -> NotificationResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(message) > 0, \"message must not be empty\"\n    assert len(message) <= 500, \"message must not exceed 500 characters\"\n    assert recipient_email is not None, \"recipient_email must not be null\"\n    \n    user = await db.query(users_table).filter(user_id=user_id).first()\n    if user is None:\n        raise NotFoundError(\"user_does_not_exist\")\n    \n    notification_id = str(uuid4())\n    await db.insert(notifications_table, \n                   id=notification_id, \n                   user_id=user_id, \n                   message=message, \n                   created_at=datetime.utcnow())\n    \n    await db.insert(delivery_log_table,\n                   notification_id=notification_id,\n                   recipient=recipient_email,\n                   status=\"sent\",\n                   sent_at=datetime.utcnow())\n    \n    logger.info(\"send_notification: notification_id=%s, user_id=%s, recipient=%s\", \n                notification_id, user_id, recipient_email)\n    \n    result = NotificationResult(notification_id=notification_id, delivered=True)\n    assert result.notification_id is not None\n    assert result.delivered is True\n    return result\n# ═══ INTL:END   [id=f3124] send_notification ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 3124}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.get(\"/search\")\nasync def search(q: str, limit: int = 10):\n    results = db.query(q)\n    return {\"results\": results[:limit]}\nINTL:END\n\nPATCH f0043 [target=f0043]\n  INTENT \"add cache retrieval before database query\"\n  ADD BEFORE: cached_result = cache.get(cache_key)\n  ADD AFTER: if cached_result: return {\"results\": cached_result}\nEND PATCH f0043", "completion": "INTL:BEGIN\n@router.get(\"/search\")\nasync def search(q: str, limit: int = 10):\n    cache_key = f\"search:{q}:{limit}\"\n    cached_result = cache.get(cache_key)\n    if cached_result:\n        return {\"results\": cached_result}\n    results = db.query(q)\n    return {\"results\": results[:limit]}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CACHE GET", "idx": 43}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION list_role_permissions [id=f0733]\n  INTENT       \"retrieve paginated list of permissions for a given role with filtering\"\n  PRECONDITION role_id > 0\n  PRECONDITION page_size > 0 AND page_size <= 100\n  PRECONDITION page_number >= 1\n  POSTCONDITION result.items IS NOT NULL\n  POSTCONDITION result.total_count >= 0\n  READS        roles_table, permissions_table, role_permissions_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n  \n  role = QUERY roles_table WHERE id == role_id LIMIT 1\n  IF role IS NULL THEN FAIL PermissionError(\"role_not_found\")\n  \n  offset = (page_number - 1) * page_size\n  perms = PAGINATE role_permissions_table \n    WHERE role_id == role_id \n    JOIN permissions_table ON role_permissions_table.permission_id == permissions_table.id\n    ORDER BY permissions_table.name ASC\n    LIMIT page_size OFFSET offset\n  \n  total = COUNT role_permissions_table WHERE role_id == role_id\n  \n  PERSIST audit_log_table (action: \"list_permissions\", role_id: role_id, timestamp: now(), user_id: context.user_id)\n  \n  RETURN PaginatedPermissions(items: perms, total_count: total, page: page_number, page_size: page_size)\nEND FUNCTION list_role_permissions [id=f0733]", "completion": "# ═══ INTL:BEGIN [id=f0733] list_role_permissions ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def list_role_permissions(\n    role_id: int,\n    page_number: int,\n    page_size: int,\n    context: RequestContext\n) -> PaginatedPermissions:\n    assert role_id > 0, \"role_id must be positive\"\n    assert page_size > 0 and page_size <= 100, \"page_size must be between 1 and 100\"\n    assert page_number >= 1, \"page_number must be at least 1\"\n    \n    role = await db.query(roles_table).filter(id=role_id).first()\n    if role is None:\n        raise PermissionError(\"role_not_found\")\n    \n    offset = (page_number - 1) * page_size\n    \n    perms = await db.query(role_permissions_table).filter(\n        role_id=role_id\n    ).join(\n        permissions_table,\n        role_permissions_table.permission_id == permissions_table.id\n    ).order_by(\n        permissions_table.name\n    ).limit(page_size).offset(offset).all()\n    \n    total = await db.query(role_permissions_table).filter(\n        role_id=role_id\n    ).count()\n    \n    await db.insert(\n        audit_log_table,\n        action=\"list_permissions\",\n        role_id=role_id,\n        timestamp=datetime.utcnow(),\n        user_id=context.user_id\n    )\n    \n    logger.info(\"list_role_permissions: role_id=%d, page=%d, page_size=%d, total=%d\",\n                role_id, page_number, page_size, total)\n    \n    result = PaginatedPermissions(\n        items=perms,\n        total_count=total,\n        page=page_number,\n        page_size=page_size\n    )\n    assert result.items is not None, \"items must not be null\"\n    assert result.total_count >= 0, \"total_count must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f0733] list_role_permissions ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PAGINATE", "idx": 733}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/reports/{report_id}\")\nasync def get_report(report_id: int, db: Session = Depends(get_db)):\n    report = db.query(Report).filter(Report.id == report_id).first()\n    if not report:\n        raise HTTPException(status_code=404, detail=\"Report not found\")\n    return report\nINTL:END\n\nPATCH f1423 [target=f1423]\n  INTENT \"add validation and logging sequence to report retrieval\"\n  ADD BEFORE: validate_report_access(report_id)\n  ADD AFTER: logger.info(f\"Report {report_id} retrieved by user\")\nEND PATCH f1423", "completion": "INTL:BEGIN\n@app.get(\"/reports/{report_id}\")\nasync def get_report(report_id: int, db: Session = Depends(get_db)):\n    validate_report_access(report_id)\n    report = db.query(Report).filter(Report.id == report_id).first()\n    if not report:\n        raise HTTPException(status_code=404, detail=\"Report not found\")\n    logger.info(f\"Report {report_id} retrieved by user\")\n    return report\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 1423}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    new_review = Review(\n        user_id=review.user_id,\n        product_id=review.product_id,\n        rating=review.rating,\n        text=review.text\n    )\n    db.add(new_review)\n    db.commit()\n    return {\"id\": new_review.id, \"status\": \"created\"}\nINTL:END\n\nPATCH f1101 [target=f1101]\n  INTENT \"add automatic transaction rollback on database persistence errors\"\n  PERSIST: ADD ERROR_HANDLER db.rollback() on_exception\nEND PATCH f1101", "completion": "INTL:BEGIN\n@router.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    try:\n        new_review = Review(\n            user_id=review.user_id,\n            product_id=review.product_id,\n            rating=review.rating,\n            text=review.text\n        )\n        db.add(new_review)\n        db.commit()\n        return {\"id\": new_review.id, \"status\": \"created\"}\n    except Exception as e:\n        db.rollback()\n        raise\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 1101}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/api/keys\")\nasync def create_api_key(request: KeyRequest, db: Session = Depends(get_db)):\n    key = APIKey(\n        user_id=request.user_id,\n        key_hash=hash_key(request.key),\n        created_at=datetime.utcnow()\n    )\n    db.add(key)\n    db.commit()\n    return {\"status\": \"created\", \"key_id\": key.id}\nINTL:END\n\nPATCH f1745 [target=f1745]\n  INTENT \"add encrypted persistence for sensitive api key metadata\"\n  ADD BEFORE: db.commit()\n    key.encrypted_secret = encrypt_secret(request.secret)\n  ADD AFTER: db.commit()\n    persist_key_audit_log(key.id, request.user_id, \"api_key_created\")\nEND PATCH f1745", "completion": "INTL:BEGIN\n@app.post(\"/api/keys\")\nasync def create_api_key(request: KeyRequest, db: Session = Depends(get_db)):\n    key = APIKey(\n        user_id=request.user_id,\n        key_hash=hash_key(request.key),\n        created_at=datetime.utcnow()\n    )\n    db.add(key)\n    key.encrypted_secret = encrypt_secret(request.secret)\n    db.commit()\n    persist_key_audit_log(key.id, request.user_id, \"api_key_created\")\n    return {\"status\": \"created\", \"key_id\": key.id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PERSIST", "idx": 1745}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    db_review = Review(\n        title=review.title,\n        content=review.content,\n        rating=review.rating\n    )\n    db.add(db_review)\n    db.commit()\n    db.refresh(db_review)\n    return db_review\nINTL:END\n\nPATCH f2113 [target=f2113]\n  INTENT \"add validation failure handling for invalid rating values\"\n  FAIL ON: rating < 1 or rating > 5\n  ADD: raise HTTPException(status_code=400, detail=\"Rating must be between 1 and 5\")\nEND PATCH f2113", "completion": "INTL:BEGIN\n@app.post(\"/reviews\")\nasync def create_review(review: ReviewSchema, db: Session = Depends(get_db)):\n    if review.rating < 1 or review.rating > 5:\n        raise HTTPException(status_code=400, detail=\"Rating must be between 1 and 5\")\n    db_review = Review(\n        title=review.title,\n        content=review.content,\n        rating=review.rating\n    )\n    db.add(db_review)\n    db.commit()\n    db.refresh(db_review)\n    return db_review\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "FAIL", "idx": 2113}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/audit/log\")\nasync def create_audit_log(event: AuditEvent):\n    log_entry = {\n        \"timestamp\": datetime.utcnow(),\n        \"event_type\": event.type,\n        \"user_id\": event.user_id,\n        \"action\": event.action,\n        \"resource\": event.resource,\n        \"status\": event.status\n    }\n    await db.audit_logs.insert_one(log_entry)\n    return {\"logged\": True}\nINTL:END\n\nPATCH f2757 [target=f2757]\n  INTENT \"add confidence score to audit log entries\"\n  ADD AFTER: \"status\": event.status,\n  ADD: \"confidence\": event.confidence_score\nEND PATCH f2757", "completion": "INTL:BEGIN\n@app.post(\"/audit/log\")\nasync def create_audit_log(event: AuditEvent):\n    log_entry = {\n        \"timestamp\": datetime.utcnow(),\n        \"event_type\": event.type,\n        \"user_id\": event.user_id,\n        \"action\": event.action,\n        \"resource\": event.resource,\n        \"status\": event.status,\n        \"confidence\": event.confidence_score\n    }\n    await db.audit_logs.insert_one(log_entry)\n    return {\"logged\": True}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 2757}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/subscriptions/{subscription_id}/confirm\")\nasync def confirm_subscription(subscription_id: str, request: ConfirmRequest, db: Session = Depends(get_db)):\n    subscription = db.query(Subscription).filter(Subscription.id == subscription_id).first()\n    if not subscription:\n        raise HTTPException(status_code=404, detail=\"Subscription not found\")\n    \n    subscription.status = \"active\"\n    db.commit()\n    return {\"status\": \"confirmed\", \"subscription_id\": subscription_id}\nINTL:END\n\nPATCH f2435 [target=f2435]\n  INTENT \"add confidence score validation to subscription confirmation\"\n  ADD BEFORE: subscription.status = \"active\"\n    confidence_score = calculate_confidence(subscription, request)\n    if confidence_score < 0.75:\n        raise HTTPException(status_code=422, detail=f\"Confidence score {confidence_score} below threshold\")\nEND PATCH f2435", "completion": "INTL:BEGIN\n@router.post(\"/subscriptions/{subscription_id}/confirm\")\nasync def confirm_subscription(subscription_id: str, request: ConfirmRequest, db: Session = Depends(get_db)):\n    subscription = db.query(Subscription).filter(Subscription.id == subscription_id).first()\n    if not subscription:\n        raise HTTPException(status_code=404, detail=\"Subscription not found\")\n    \n    confidence_score = calculate_confidence(subscription, request)\n    if confidence_score < 0.75:\n        raise HTTPException(status_code=422, detail=f\"Confidence score {confidence_score} below threshold\")\n    subscription.status = \"active\"\n    db.commit()\n    return {\"status\": \"confirmed\", \"subscription_id\": subscription_id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 2435}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    if not file.filename:\n        return {\"error\": \"No filename provided\"}\n    \n    saved_path = await save_to_disk(file)\n    return {\"filename\": file.filename, \"path\": saved_path}\nINTL:END\n\nPATCH f0044 [target=f0044]\n  INTENT \"add file size validation before return\"\n  ADD BEFORE: return {\"filename\": file.filename, \"path\": saved_path}\n    max_size = 10 * 1024 * 1024\n    if file.size > max_size:\n        return {\"error\": f\"File exceeds {max_size} bytes\"}\nEND PATCH f0044", "completion": "INTL:BEGIN\n@app.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    if not file.filename:\n        return {\"error\": \"No filename provided\"}\n    \n    saved_path = await save_to_disk(file)\n    max_size = 10 * 1024 * 1024\n    if file.size > max_size:\n        return {\"error\": f\"File exceeds {max_size} bytes\"}\n    return {\"filename\": file.filename, \"path\": saved_path}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "RETURN", "idx": 44}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@router.post(\"/subscriptions\")\nasync def create_subscription(req: SubscriptionRequest, db: Session = Depends(get_db)):\n    user = db.query(User).filter(User.id == req.user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    \n    sub = Subscription(\n        user_id=req.user_id,\n        plan=req.plan,\n        status=\"active\"\n    )\n    db.add(sub)\n    db.commit()\n    return {\"subscription_id\": sub.id, \"status\": sub.status}\nINTL:END\n\nPATCH f0412 [target=f0412]\n  INTENT \"add confidence scoring to subscription creation validation\"\n  ADD BEFORE: sub = Subscription(\n    confidence_score = validate_subscription_confidence(user, req.plan)\n    ADD TO: sub definition\nEND PATCH f0412", "completion": "INTL:BEGIN\n@router.post(\"/subscriptions\")\nasync def create_subscription(req: SubscriptionRequest, db: Session = Depends(get_db)):\n    user = db.query(User).filter(User.id == req.user_id).first()\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    \n    confidence_score = validate_subscription_confidence(user, req.plan)\n    sub = Subscription(\n        user_id=req.user_id,\n        plan=req.plan,\n        status=\"active\",\n        confidence_score=confidence_score\n    )\n    db.add(sub)\n    db.commit()\n    return {\"subscription_id\": sub.id, \"status\": sub.status, \"confidence\": confidence_score}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CONFIDENCE", "idx": 412}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION refresh_session [id=f1102]\n  INTENT       \"refresh an active session token with extended expiration\"\n  PRECONDITION token.length > 0\n  PRECONDITION token_type == \"bearer\"\n  POSTCONDITION result.new_token IS NOT NULL\n  POSTCONDITION result.expires_at > now()\n  READS        sessions_table\n  READS        users_table\n  MUTATES      sessions_table\n  OBSERVABLE\n\n  session = QUERY sessions_table WHERE token == token LIMIT 1\n  FALLBACK session IS NULL THEN\n    QUERY users_table WHERE last_active > now()-7d LIMIT 10\n    RETURN SessionRefreshFailed(reason: \"session_expired\", suggestions: [])\n  END FALLBACK\n\n  IF session.expires_at < now() THEN FAIL SessionError(\"token_already_expired\")\n  \n  new_token = generate_token(session.user_id)\n  new_expiry = now() + 72h\n  \n  PERSIST sessions_table (id: session.id, token: new_token, expires_at: new_expiry)\n  DELETE sessions_table WHERE id == session.id AND token == token\n  \n  RETURN SessionToken(token: new_token, expires_at: new_expiry)\nEND FUNCTION refresh_session [id=f1102]", "completion": "# ═══ INTL:BEGIN [id=f1102] refresh_session ═══\nimport logging\nfrom datetime import datetime, timedelta\n\nlogger = logging.getLogger(__name__)\n\nasync def refresh_session(token: str, token_type: str) -> dict:\n    assert len(token) > 0, \"token must not be empty\"\n    assert token_type == \"bearer\", \"token_type must be 'bearer'\"\n    \n    session = await db.query(sessions_table).filter(token=token).first()\n    \n    if session is None:\n        recent_users = await db.query(users_table).filter(\n            last_active__gt=datetime.utcnow() - timedelta(days=7)\n        ).limit(10).all()\n        logger.warning(\"refresh_session: session_not_found, token=%s\", token[:16])\n        raise SessionRefreshFailed(reason=\"session_expired\", suggestions=[])\n    \n    if session.expires_at < datetime.utcnow():\n        raise SessionError(\"token_already_expired\")\n    \n    new_token = generate_token(session.user_id)\n    new_expiry = datetime.utcnow() + timedelta(hours=72)\n    \n    await db.update(sessions_table, id=session.id, \n                    token=new_token, expires_at=new_expiry)\n    await db.delete(sessions_table, id=session.id, token=token)\n    \n    logger.info(\"refresh_session: user=%s, old_token=%s\", \n                session.user_id, token[:16])\n    \n    result = SessionToken(token=new_token, expires_at=new_expiry)\n    assert result.new_token is not None\n    assert result.expires_at > datetime.utcnow()\n    return result\n# ═══ INTL:END   [id=f1102] refresh_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 1102}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION upload_document [id=f1424]\n  INTENT       \"validate and persist uploaded document with virus scan\"\n  PRECONDITION file_size > 0\n  PRECONDITION file_size <= 52428800\n  PRECONDITION file_name.length > 0\n  PRECONDITION file_name.length <= 255\n  PRECONDITION mime_type IN (\"application/pdf\", \"application/msword\", \"text/plain\")\n  POSTCONDITION result.document_id IS NOT NULL\n  POSTCONDITION result.scan_status == \"clean\"\n  READS        mime_types_table\n  MUTATES      documents_table\n  MUTATES      file_storage\n  OBSERVABLE\n\n  IF file_size == 0 THEN FAIL ValidationError(\"file_is_empty\")\n  IF file_size > 52428800 THEN FAIL ValidationError(\"file_exceeds_50mb\")\n  IF file_name.length == 0 THEN FAIL ValidationError(\"filename_required\")\n  IF file_name.length > 255 THEN FAIL ValidationError(\"filename_too_long\")\n  allowed_types = QUERY mime_types_table WHERE enabled == true\n  IF mime_type NOT IN allowed_types THEN FAIL ValidationError(\"unsupported_file_type\")\n  \n  scan_result = scan_virus(file_buffer)\n  IF scan_result.threat_detected THEN FAIL SecurityError(\"malware_detected\")\n  \n  document_id = generate_uuid()\n  file_path = store_file(file_buffer, document_id, file_name)\n  PERSIST documents_table (id: document_id, file_name: file_name, file_path: file_path, mime_type: mime_type, file_size: file_size, scan_status: \"clean\", uploaded_at: now())\n  RETURN DocumentUpload(document_id: document_id, file_name: file_name, scan_status: \"clean\")\nEND FUNCTION upload_document [id=f1424]", "completion": "# ═══ INTL:BEGIN [id=f1424] upload_document ═══\nimport logging\nfrom datetime import datetime\nfrom uuid import uuid4\n\nlogger = logging.getLogger(__name__)\n\nasync def upload_document(file_buffer: bytes, file_name: str, file_size: int, mime_type: str) -> DocumentUpload:\n    assert file_size > 0, \"file_is_empty\"\n    assert file_size <= 52428800, \"file_exceeds_50mb\"\n    assert len(file_name) > 0, \"filename_required\"\n    assert len(file_name) <= 255, \"filename_too_long\"\n    \n    allowed_types = await db.query(mime_types_table).filter(enabled=True).all()\n    allowed_mime_types = {mt.mime_type for mt in allowed_types}\n    if mime_type not in allowed_mime_types:\n        raise ValidationError(\"unsupported_file_type\")\n    \n    scan_result = await scan_virus(file_buffer)\n    if scan_result.threat_detected:\n        raise SecurityError(\"malware_detected\")\n    \n    document_id = str(uuid4())\n    file_path = await store_file(file_buffer, document_id, file_name)\n    \n    await db.insert(\n        documents_table,\n        id=document_id,\n        file_name=file_name,\n        file_path=file_path,\n        mime_type=mime_type,\n        file_size=file_size,\n        scan_status=\"clean\",\n        uploaded_at=datetime.utcnow()\n    )\n    \n    logger.info(\"upload_document: document_id=%s, file_name=%s, file_size=%d\", document_id, file_name, file_size)\n    \n    result = DocumentUpload(document_id=document_id, file_name=file_name, scan_status=\"clean\")\n    assert result.document_id is not None\n    assert result.scan_status == \"clean\"\n    return result\n# ═══ INTL:END   [id=f1424] upload_document ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FAIL", "idx": 1424}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION process_batch_uploads [id=f1746]\n  INTENT       \"validate and store multiple file uploads with virus scanning\"\n  PRECONDITION files.length > 0\n  PRECONDITION files.length <= 100\n  PRECONDITION max_file_size > 0\n  POSTCONDITION result.processed_count == result.success_count + result.failed_count\n  READS        virus_definitions\n  MUTATES      uploads_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n\n  processed_count = 0\n  success_count = 0\n  failed_count = 0\n  results = []\n\n  LOOP file IN files DO\n    processed_count = processed_count + 1\n    IF file.size > max_file_size THEN\n      APPEND results (file_name: file.name, status: \"rejected\", reason: \"exceeds_size_limit\")\n      failed_count = failed_count + 1\n      CONTINUE\n    END IF\n    IF NOT scan_virus(file.content, virus_definitions) THEN\n      APPEND results (file_name: file.name, status: \"rejected\", reason: \"virus_detected\")\n      failed_count = failed_count + 1\n      CONTINUE\n    END IF\n    file_id = generate_uuid()\n    PERSIST uploads_table (id: file_id, file_name: file.name, file_size: file.size, upload_timestamp: now(), user_id: user_id, status: \"completed\")\n    APPEND results (file_name: file.name, status: \"uploaded\", file_id: file_id)\n    success_count = success_count + 1\n  END LOOP\n\n  PERSIST audit_log_table (user_id: user_id, action: \"batch_upload\", file_count: processed_count, success_count: success_count, timestamp: now())\n  RETURN BatchUploadResult(processed_count: processed_count, success_count: success_count, failed_count: failed_count, details: results)\nEND FUNCTION process_batch_uploads [id=f1746]", "completion": "# ═══ INTL:BEGIN [id=f1746] process_batch_uploads ═══\nimport logging\nimport uuid\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def process_batch_uploads(\n    files: List[UploadFile],\n    user_id: str,\n    max_file_size: int\n) -> BatchUploadResult:\n    assert len(files) > 0, \"files list must not be empty\"\n    assert len(files) <= 100, \"files list must not exceed 100 items\"\n    assert max_file_size > 0, \"max_file_size must be greater than 0\"\n\n    virus_definitions = await db.query(virus_definitions_table).all()\n\n    processed_count = 0\n    success_count = 0\n    failed_count = 0\n    results = []\n\n    for file in files:\n        processed_count += 1\n        file_content = await file.read()\n\n        if len(file_content) > max_file_size:\n            results.append({\n                \"file_name\": file.filename,\n                \"status\": \"rejected\",\n                \"reason\": \"exceeds_size_limit\"\n            })\n            failed_count += 1\n            continue\n\n        if not scan_virus(file_content, virus_definitions):\n            results.append({\n                \"file_name\": file.filename,\n                \"status\": \"rejected\",\n                \"reason\": \"virus_detected\"\n            })\n            failed_count += 1\n            continue\n\n        file_id = str(uuid.uuid4())\n        await db.insert(uploads_table,\n                       id=file_id,\n                       file_name=file.filename,\n                       file_size=len(file_content),\n                       upload_timestamp=datetime.utcnow(),\n                       user_id=user_id,\n                       status=\"completed\")\n\n        results.append({\n            \"file_name\": file.filename,\n            \"status\": \"uploaded\",\n            \"file_id\": file_id\n        })\n        success_count += 1\n\n    await db.insert(audit_log_table,\n                   user_id=user_id,\n                   action=\"batch_upload\",\n                   file_count=processed_count,\n                   success_count=success_count,\n                   timestamp=datetime.utcnow())\n\n    logger.info(\"batch_upload: user=%s, processed=%d, success=%d, failed=%d\",\n               user_id, processed_count, success_count, failed_count)\n\n    result = BatchUploadResult(\n        processed_count=processed_count,\n        success_count=success_count,\n        failed_count=failed_count,\n        details=results\n    )\n    assert result.processed_count == result.success_count + result.failed_count\n    return result\n# ═══ INTL:END   [id=f1746] process_batch_uploads ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "LOOP", "idx": 1746}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION list_active_sessions [id=f2436]\n  INTENT       \"retrieve paginated list of active user sessions with filtering\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION page >= 1\n  PRECONDITION page_size > 0 AND page_size <= 100\n  POSTCONDITION result.total >= 0\n  POSTCONDITION result.items IS NOT NULL\n  READS        sessions_table\n  MUTATES      session_audit_log\n  OBSERVABLE\n\n  sessions = PAGINATE sessions_table \n    WHERE user_id == user_id AND expires_at > now()\n    ORDER BY created_at DESC\n    PAGE page\n    SIZE page_size\n  \n  total_count = COUNT sessions_table WHERE user_id == user_id AND expires_at > now()\n  PERSIST session_audit_log (user_id: user_id, action: \"list_sessions\", page: page, timestamp: now())\n  RETURN SessionList(items: sessions, total: total_count, page: page, page_size: page_size)\nEND FUNCTION list_active_sessions [id=f2436]", "completion": "# ═══ INTL:BEGIN [id=f2436] list_active_sessions ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def list_active_sessions(\n    user_id: str,\n    page: int,\n    page_size: int\n) -> SessionList:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert page >= 1, \"page must be >= 1\"\n    assert page_size > 0, \"page_size must be > 0\"\n    assert page_size <= 100, \"page_size must be <= 100\"\n    \n    offset = (page - 1) * page_size\n    sessions = await db.query(sessions_table).filter(\n        user_id=user_id,\n        expires_at__gt=datetime.utcnow()\n    ).order_by(\"-created_at\").offset(offset).limit(page_size).all()\n    \n    total_count = await db.query(sessions_table).filter(\n        user_id=user_id,\n        expires_at__gt=datetime.utcnow()\n    ).count()\n    \n    await db.insert(\n        session_audit_log,\n        user_id=user_id,\n        action=\"list_sessions\",\n        page=page,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"list_active_sessions: user_id=%s page=%d total=%d\", user_id, page, total_count)\n    \n    result = SessionList(\n        items=sessions,\n        total=total_count,\n        page=page,\n        page_size=page_size\n    )\n    assert result.total >= 0\n    assert result.items is not None\n    return result\n# ═══ INTL:END   [id=f2436] list_active_sessions ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "PAGINATE", "idx": 2436}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION search_and_bookmark [id=f2114]\n  INTENT       \"search products by query and atomically bookmark top result for user\"\n  PRECONDITION query.length > 0\n  PRECONDITION query.length <= 256\n  PRECONDITION user_id > 0\n  PRECONDITION limit >= 1\n  PRECONDITION limit <= 100\n  POSTCONDITION result.search_id IS NOT NULL\n  POSTCONDITION result.bookmarked_product_id IS NOT NULL\n  READS        products_table\n  MUTATES      search_logs_table\n  MUTATES      bookmarks_table\n  OBSERVABLE\n\n  TRANSACTION\n    results = QUERY products_table WHERE name ILIKE query LIMIT limit\n    IF results.length == 0 THEN FAIL SearchError(\"no_products_found\")\n    top_product = results[0]\n    search_log = PERSIST search_logs_table (user_id: user_id, query: query, result_count: results.length, top_product_id: top_product.id, searched_at: now())\n    existing_bookmark = QUERY bookmarks_table WHERE user_id == user_id AND product_id == top_product.id LIMIT 1\n    IF existing_bookmark IS NULL THEN\n      PERSIST bookmarks_table (user_id: user_id, product_id: top_product.id, created_at: now())\n    END IF\n  END TRANSACTION\n  \n  RETURN SearchResult(search_id: search_log.id, bookmarked_product_id: top_product.id, total_results: results.length)\nEND FUNCTION search_and_bookmark [id=f2114]", "completion": "# ═══ INTL:BEGIN [id=f2114] search_and_bookmark ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def search_and_bookmark(user_id: int, query: str, limit: int = 20) -> SearchResult:\n    assert len(query) > 0, \"query must not be empty\"\n    assert len(query) <= 256, \"query must be at most 256 characters\"\n    assert user_id > 0, \"user_id must be positive\"\n    assert limit >= 1, \"limit must be at least 1\"\n    assert limit <= 100, \"limit must be at most 100\"\n    \n    async with db.transaction():\n        results = await db.query(products_table).filter(\n            products_table.name.ilike(f\"%{query}%\")\n        ).limit(limit).all()\n        \n        if not results:\n            raise SearchError(\"no_products_found\")\n        \n        top_product = results[0]\n        \n        search_log = await db.insert(\n            search_logs_table,\n            user_id=user_id,\n            query=query,\n            result_count=len(results),\n            top_product_id=top_product.id,\n            searched_at=datetime.utcnow()\n        )\n        \n        existing_bookmark = await db.query(bookmarks_table).filter(\n            (bookmarks_table.user_id == user_id) &\n            (bookmarks_table.product_id == top_product.id)\n        ).limit(1).first()\n        \n        if existing_bookmark is None:\n            await db.insert(\n                bookmarks_table,\n                user_id=user_id,\n                product_id=top_product.id,\n                created_at=datetime.utcnow()\n            )\n        \n        logger.info(\"search_and_bookmark: user_id=%s query=%s top_product_id=%s result_count=%s\",\n                    user_id, query, top_product.id, len(results))\n    \n    assert search_log.id is not None\n    assert top_product.id is not None\n    \n    return SearchResult(\n        search_id=search_log.id,\n        bookmarked_product_id=top_product.id,\n        total_results=len(results)\n    )\n# ═══ INTL:END   [id=f2114] search_and_bookmark ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 2114}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom redis import Redis\n\napp = FastAPI()\ncache = Redis(host='localhost', port=6379, db=0)\n\n@app.get(\"/inventory/{item_id}\")\ndef get_inventory(item_id: str):\n    result = cache.get(f\"inventory:{item_id}\")\n    if result:\n        return {\"cached\": True, \"data\": result}\n    return {\"cached\": False, \"data\": None}\n\n@app.post(\"/inventory/{item_id}\")\ndef update_inventory(item_id: str, quantity: int):\n    cache.set(f\"inventory:{item_id}\", quantity)\n    return {\"status\": \"updated\", \"item_id\": item_id}\nINTL:END\n\nPATCH f2758 [target=f2758]\n  INTENT \"add TTL expiration to cache SET operations for inventory items\"\n  MODIFY: cache.set(f\"inventory:{item_id}\", quantity)\n  REPLACE WITH: cache.setex(f\"inventory:{item_id}\", 3600, quantity)\nEND PATCH f2758", "completion": "INTL:BEGIN\nfrom fastapi import FastAPI\nfrom redis import Redis\n\napp = FastAPI()\ncache = Redis(host='localhost', port=6379, db=0)\n\n@app.get(\"/inventory/{item_id}\")\ndef get_inventory(item_id: str):\n    result = cache.get(f\"inventory:{item_id}\")\n    if result:\n        return {\"cached\": True, \"data\": result}\n    return {\"cached\": False, \"data\": None}\n\n@app.post(\"/inventory/{item_id}\")\ndef update_inventory(item_id: str, quantity: int):\n    cache.setex(f\"inventory:{item_id}\", 3600, quantity)\n    return {\"status\": \"updated\", \"item_id\": item_id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "CACHE SET", "idx": 2758}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/api/resource\")\nasync def create_resource(request: ResourceRequest, current_user: User = Depends(get_current_user)):\n    resource = Resource(name=request.name, owner_id=current_user.id)\n    db.add(resource)\n    db.commit()\n    return {\"status\": \"created\", \"resource_id\": resource.id}\nINTL:END\n\nPATCH f0413 [target=f0413]\n  INTENT \"transform resource creation to enforce role-based permissions\"\n  TRANSFORM check_ownership → check_role_permission(current_user, \"resource:create\")\n  ADD BEFORE: if not check_role_permission(current_user, \"resource:create\"): raise HTTPException(status_code=403, detail=\"Insufficient permissions\")\nEND PATCH f0413", "completion": "INTL:BEGIN\n@app.post(\"/api/resource\")\nasync def create_resource(request: ResourceRequest, current_user: User = Depends(get_current_user)):\n    if not check_role_permission(current_user, \"resource:create\"):\n        raise HTTPException(status_code=403, detail=\"Insufficient permissions\")\n    resource = Resource(name=request.name, owner_id=current_user.id)\n    db.add(resource)\n    db.commit()\n    return {\"status\": \"created\", \"resource_id\": resource.id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSFORM", "idx": 413}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_role_hierarchy [id=f0045]\n  INTENT       \"grant a role to a user, propagating permissions through the role hierarchy\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION role_name.length > 0\n  PRECONDITION requester_id IS NOT NULL\n  POSTCONDITION result.success == TRUE\n  READS        users_table, roles_table, permissions_table, role_hierarchy_table\n  MUTATES      user_roles_table, audit_log_table\n  OBSERVABLE\n\n  SEQUENCE\n    step_1: requester = QUERY users_table WHERE id == requester_id LIMIT 1\n    IF requester IS NULL THEN FAIL AuthError(\"requester_not_found\")\n    \n    step_2: role = QUERY roles_table WHERE name == role_name LIMIT 1\n    IF role IS NULL THEN FAIL PermissionError(\"role_not_found\")\n    \n    step_3: IF NOT requester.admin THEN FAIL AuthError(\"insufficient_permissions\")\n    \n    step_4: target_user = QUERY users_table WHERE id == user_id LIMIT 1\n    IF target_user IS NULL THEN FAIL NotFoundError(\"user_not_found\")\n    \n    step_5: parent_roles = QUERY role_hierarchy_table WHERE child_role_id == role.id\n    \n    step_6: PERSIST user_roles_table (user_id: user_id, role_id: role.id, granted_at: now(), granted_by: requester_id)\n    \n    step_7: FOR each parent IN parent_roles DO\n      PERSIST user_roles_table (user_id: user_id, role_id: parent.parent_role_id, granted_at: now(), granted_by: requester_id)\n    END FOR\n    \n    step_8: PERSIST audit_log_table (action: \"role_granted\", target_user_id: user_id, role_id: role.id, requester_id: requester_id, timestamp: now())\n  END SEQUENCE\n\n  RETURN GrantResult(success: TRUE, role_id: role.id, user_id: user_id)\nEND FUNCTION grant_role_hierarchy [id=f0045]", "completion": "# ═══ INTL:BEGIN [id=f0045] grant_role_hierarchy ═══\nimport logging\nfrom datetime import datetime\nfrom typing import List\n\nlogger = logging.getLogger(__name__)\n\nasync def grant_role_hierarchy(user_id: str, role_name: str, requester_id: str) -> GrantResult:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(role_name) > 0, \"role_name must not be empty\"\n    assert requester_id is not None, \"requester_id must not be null\"\n    \n    # step_1: Verify requester exists\n    requester = await db.query(users_table).filter(id=requester_id).first()\n    if requester is None:\n        raise AuthError(\"requester_not_found\")\n    \n    # step_2: Verify role exists\n    role = await db.query(roles_table).filter(name=role_name).first()\n    if role is None:\n        raise PermissionError(\"role_not_found\")\n    \n    # step_3: Check requester has admin privileges\n    if not requester.admin:\n        raise AuthError(\"insufficient_permissions\")\n    \n    # step_4: Verify target user exists\n    target_user = await db.query(users_table).filter(id=user_id).first()\n    if target_user is None:\n        raise NotFoundError(\"user_not_found\")\n    \n    # step_5: Fetch parent roles from hierarchy\n    parent_roles = await db.query(role_hierarchy_table).filter(\n        child_role_id=role.id\n    ).all()\n    \n    # step_6: Grant the primary role\n    await db.insert(\n        user_roles_table,\n        user_id=user_id,\n        role_id=role.id,\n        granted_at=datetime.utcnow(),\n        granted_by=requester_id\n    )\n    \n    # step_7: Grant all inherited parent roles\n    for parent in parent_roles:\n        await db.insert(\n            user_roles_table,\n            user_id=user_id,\n            role_id=parent.parent_role_id,\n            granted_at=datetime.utcnow(),\n            granted_by=requester_id\n        )\n    \n    # step_8: Log audit entry\n    await db.insert(\n        audit_log_table,\n        action=\"role_granted\",\n        target_user_id=user_id,\n        role_id=role.id,\n        requester_id=requester_id,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"grant_role_hierarchy: user=%s, role=%s, requester=%s\", \n                user_id, role.id, requester_id)\n    \n    result = GrantResult(success=True, role_id=role.id, user_id=user_id)\n    assert result.success == True\n    return result\n# ═══ INTL:END   [id=f0045] grant_role_hierarchy ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 45}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/shipments\")\nasync def create_shipment(shipment: ShipmentRequest):\n    order_id = shipment.order_id\n    carrier = shipment.carrier\n    tracking_number = generate_tracking()\n    db.insert_shipment(order_id, carrier, tracking_number)\n    return {\"status\": \"created\", \"tracking\": tracking_number}\nINTL:END\n\nPATCH f1103 [target=f1103]\n  INTENT \"add database transaction wrapping to ensure atomic shipment creation\"\n  ADD BEFORE: session.begin_transaction()\n  ADD AFTER: session.commit()\nEND PATCH f1103", "completion": "INTL:BEGIN\n@app.post(\"/shipments\")\nasync def create_shipment(shipment: ShipmentRequest):\n    session.begin_transaction()\n    order_id = shipment.order_id\n    carrier = shipment.carrier\n    tracking_number = generate_tracking()\n    db.insert_shipment(order_id, carrier, tracking_number)\n    session.commit()\n    return {\"status\": \"created\", \"tracking\": tracking_number}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "TRANSACTION", "idx": 1103}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION grant_permission [id=f0735]\n  INTENT       \"grant a permission to a user with validation and audit logging\"\n  PRECONDITION user_id.length > 0\n  PRECONDITION permission_name.length > 0\n  PRECONDITION requester_role IN (\"admin\", \"owner\")\n  POSTCONDITION result.granted IS TRUE\n  READS        users_table\n  READS        roles_table\n  MUTATES      permissions_table\n  MUTATES      audit_log_table\n  OBSERVABLE\n\n  requester = QUERY users_table WHERE id == requester_id LIMIT 1\n  IF requester IS NULL THEN FAIL PermissionError(\"requester_not_found\")\n  IF requester.role NOT IN (\"admin\", \"owner\") THEN FAIL PermissionError(\"insufficient_privileges\")\n  \n  target_user = QUERY users_table WHERE id == user_id LIMIT 1\n  IF target_user IS NULL THEN FAIL PermissionError(\"target_user_not_found\")\n  \n  perm_check = QUERY permissions_table WHERE user_id == user_id AND permission == permission_name LIMIT 1\n  IF perm_check IS NOT NULL THEN FAIL PermissionError(\"permission_already_granted\")\n  \n  PERSIST permissions_table (user_id: user_id, permission: permission_name, granted_by: requester_id, granted_at: now())\n  PERSIST audit_log_table (action: \"GRANT_PERMISSION\", actor_id: requester_id, target_id: user_id, permission: permission_name, timestamp: now())\n  \n  RETURN PermissionGrant(granted: TRUE, user_id: user_id, permission: permission_name)\nEND FUNCTION grant_permission [id=f0735]", "completion": "# ═══ INTL:BEGIN [id=f0735] grant_permission ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nclass PermissionError(Exception):\n    pass\n\nasync def grant_permission(user_id: str, permission_name: str, requester_id: str, requester_role: str) -> dict:\n    assert len(user_id) > 0, \"user_id must not be empty\"\n    assert len(permission_name) > 0, \"permission_name must not be empty\"\n    assert requester_role in (\"admin\", \"owner\"), \"requester_role must be admin or owner\"\n    \n    requester = await db.query(users_table).filter(id=requester_id).first()\n    if requester is None:\n        raise PermissionError(\"requester_not_found\")\n    if requester.role not in (\"admin\", \"owner\"):\n        raise PermissionError(\"insufficient_privileges\")\n    \n    target_user = await db.query(users_table).filter(id=user_id).first()\n    if target_user is None:\n        raise PermissionError(\"target_user_not_found\")\n    \n    perm_check = await db.query(permissions_table).filter(\n        user_id=user_id, permission=permission_name\n    ).first()\n    if perm_check is not None:\n        raise PermissionError(\"permission_already_granted\")\n    \n    await db.insert(\n        permissions_table,\n        user_id=user_id,\n        permission=permission_name,\n        granted_by=requester_id,\n        granted_at=datetime.utcnow()\n    )\n    \n    await db.insert(\n        audit_log_table,\n        action=\"GRANT_PERMISSION\",\n        actor_id=requester_id,\n        target_id=user_id,\n        permission=permission_name,\n        timestamp=datetime.utcnow()\n    )\n    \n    logger.info(\"grant_permission: requester=%s granted %s to user=%s\", requester_id, permission_name, user_id)\n    \n    result = {\"granted\": True, \"user_id\": user_id, \"permission\": permission_name}\n    assert result[\"granted\"] is True\n    return result\n# ═══ INTL:END   [id=f0735] grant_permission ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FAIL", "idx": 735}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION revoke_session [id=f1425]\n  INTENT       \"invalidate an active session token and log the revocation event\"\n  PRECONDITION token.length > 0\n  PRECONDITION user_id > 0\n  POSTCONDITION result.revoked IS TRUE\n  READS        sessions_table\n  MUTATES      sessions_table, audit_log\n  OBSERVABLE\n\n  session = QUERY sessions_table WHERE token == token LIMIT 1\n  IF session IS NULL THEN FAIL SessionError(\"session_not_found\")\n  IF session.user_id != user_id THEN FAIL SessionError(\"unauthorized_revocation\")\n  IF session.expires_at < now() THEN FAIL SessionError(\"session_already_expired\")\n  UPDATE sessions_table SET status = \"revoked\", revoked_at = now() WHERE token == token\n  PERSIST audit_log (user_id: user_id, action: \"session_revoke\", timestamp: now(), token_hash: hash(token))\n  RETURN RevokeResult(revoked: TRUE, revoked_at: now())\nEND FUNCTION revoke_session [id=f1425]", "completion": "# ═══ INTL:BEGIN [id=f1425] revoke_session ═══\nimport logging\nfrom datetime import datetime\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nasync def revoke_session(token: str, user_id: int) -> RevokeResult:\n    assert len(token) > 0, \"token must not be empty\"\n    assert user_id > 0, \"user_id must be positive\"\n    \n    session = await db.query(sessions_table).filter(token=token).first()\n    if session is None:\n        raise SessionError(\"session_not_found\")\n    if session.user_id != user_id:\n        raise SessionError(\"unauthorized_revocation\")\n    if session.expires_at < datetime.utcnow():\n        raise SessionError(\"session_already_expired\")\n    \n    await db.update(sessions_table).filter(token=token).set(\n        status=\"revoked\", revoked_at=datetime.utcnow()\n    )\n    \n    token_hash = hashlib.sha256(token.encode()).hexdigest()\n    await db.insert(audit_log, user_id=user_id, action=\"session_revoke\",\n                    timestamp=datetime.utcnow(), token_hash=token_hash)\n    \n    logger.info(\"revoke_session: user_id=%s token_hash=%s\", user_id, token_hash[:16])\n    \n    result = RevokeResult(revoked=True, revoked_at=datetime.utcnow())\n    assert result.revoked is True\n    return result\n# ═══ INTL:END   [id=f1425] revoke_session ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "OBSERVABLE", "idx": 1425}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.get(\"/resources/{resource_id}/check\")\nasync def check_resource_permissions(resource_id: str, user_id: str):\n    perm1 = db.query_user_role(user_id)\n    perm2 = db.query_resource_access(resource_id)\n    perm3 = db.query_group_membership(user_id)\n    perm4 = db.query_delegation_rights(user_id)\n    \n    result = {\n        \"role\": perm1,\n        \"access\": perm2,\n        \"group\": perm3,\n        \"delegation\": perm4\n    }\n    return result\nINTL:END\n\nPATCH f1747 [target=f1747]\n  INTENT \"parallelize permission lookups for performance\"\n  CONSTRUCT PARALLEL\n  ADD: import asyncio\n  MODIFY: Execute perm1, perm2, perm3, perm4 queries concurrently using gather\nEND PATCH f1747", "completion": "INTL:BEGIN\nimport asyncio\n\n@app.get(\"/resources/{resource_id}/check\")\nasync def check_resource_permissions(resource_id: str, user_id: str):\n    perm1, perm2, perm3, perm4 = await asyncio.gather(\n        db.query_user_role(user_id),\n        db.query_resource_access(resource_id),\n        db.query_group_membership(user_id),\n        db.query_delegation_rights(user_id)\n    )\n    \n    result = {\n        \"role\": perm1,\n        \"access\": perm2,\n        \"group\": perm3,\n        \"delegation\": perm4\n    }\n    return result\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "PARALLEL", "idx": 1747}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION apply_coupon [id=f2115]\n  INTENT       \"validate and apply a coupon code to a cart, returning discount details\"\n  PRECONDITION coupon_code.length > 0\n  PRECONDITION cart_id.length > 0\n  PRECONDITION quantity > 0\n  POSTCONDITION result.discount_amount >= 0\n  READS        coupons_table, carts_table\n  MUTATES      coupon_usage_table\n  OBSERVABLE\n\n  coupon = QUERY coupons_table WHERE code == coupon_code LIMIT 1\n  IF coupon IS NULL THEN FAIL CouponError(\"coupon_not_found\")\n  IF coupon.is_active == FALSE THEN FAIL CouponError(\"coupon_expired\")\n  IF coupon.max_uses IS NOT NULL AND coupon.used_count >= coupon.max_uses THEN FAIL CouponError(\"coupon_limit_reached\")\n  cart = QUERY carts_table WHERE id == cart_id LIMIT 1\n  IF cart IS NULL THEN FAIL CartError(\"cart_not_found\")\n  discount_amount = (cart.subtotal * coupon.discount_percent) / 100\n  IF discount_amount > coupon.max_discount THEN discount_amount = coupon.max_discount\n  PERSIST coupon_usage_table (coupon_id: coupon.id, cart_id: cart_id, applied_at: now())\n  RETURN CouponResult(coupon_code: coupon_code, discount_amount: discount_amount, final_total: cart.subtotal - discount_amount)\nEND FUNCTION apply_coupon [id=f2115]", "completion": "# ═══ INTL:BEGIN [id=f2115] apply_coupon ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def apply_coupon(coupon_code: str, cart_id: str, quantity: int) -> CouponResult:\n    assert len(coupon_code) > 0, \"coupon_code must not be empty\"\n    assert len(cart_id) > 0, \"cart_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    \n    coupon = await db.query(coupons_table).filter(code=coupon_code).first()\n    if coupon is None:\n        raise CouponError(\"coupon_not_found\")\n    if coupon.is_active is False:\n        raise CouponError(\"coupon_expired\")\n    if coupon.max_uses is not None and coupon.used_count >= coupon.max_uses:\n        raise CouponError(\"coupon_limit_reached\")\n    \n    cart = await db.query(carts_table).filter(id=cart_id).first()\n    if cart is None:\n        raise CartError(\"cart_not_found\")\n    \n    discount_amount = (cart.subtotal * coupon.discount_percent) / 100\n    if discount_amount > coupon.max_discount:\n        discount_amount = coupon.max_discount\n    \n    await db.insert(coupon_usage_table, coupon_id=coupon.id, cart_id=cart_id,\n                    applied_at=datetime.utcnow())\n    \n    logger.info(\"apply_coupon: coupon=%s cart=%s discount=%.2f\", coupon_code, cart_id, discount_amount)\n    \n    final_total = cart.subtotal - discount_amount\n    result = CouponResult(coupon_code=coupon_code, discount_amount=discount_amount, final_total=final_total)\n    assert result.discount_amount >= 0\n    return result\n# ═══ INTL:END   [id=f2115] apply_coupon ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "RETURN", "idx": 2115}}
{"system": "You are the INTL compiler for Python Fastapi in PATCH mode. Apply the PATCH block to the existing code with minimal diff. Wrap output in INTL:BEGIN / INTL:END sentinels.", "prompt": "INTL:BEGIN\n@app.post(\"/process_payment\")\nasync def process_payment(payment: PaymentRequest):\n    user = get_user(payment.user_id)\n    amount = validate_amount(payment.amount)\n    transaction = create_transaction(user, amount)\n    charge_card(transaction.card_id, amount)\n    log_transaction(transaction)\n    return {\"status\": \"success\", \"transaction_id\": transaction.id}\nINTL:END\n\nPATCH f2437 [target=f2437]\n  INTENT \"add rate limiting and fraud check to payment sequence\"\n  ADD BEFORE: rate_limit_check(payment.user_id)\n  ADD AFTER: validate_amount(payment.amount): fraud_detection_check(user, amount)\nEND PATCH f2437", "completion": "INTL:BEGIN\n@app.post(\"/process_payment\")\nasync def process_payment(payment: PaymentRequest):\n    rate_limit_check(payment.user_id)\n    user = get_user(payment.user_id)\n    amount = validate_amount(payment.amount)\n    fraud_detection_check(user, amount)\n    transaction = create_transaction(user, amount)\n    charge_card(transaction.card_id, amount)\n    log_transaction(transaction)\n    return {\"status\": \"success\", \"transaction_id\": transaction.id}\nINTL:END", "metadata": {"category": "B", "adapter": "python_fastapi", "construct": "SEQUENCE", "idx": 2437}}
{"system": "You are the INTL compiler for Python Fastapi. Given an INTL block, produce idiomatic, production-ready Python Fastapi code. Wrap output in INTL:BEGIN / INTL:END sentinels with the correct block ID.", "prompt": "FUNCTION restock_inventory [id=f2759]\n  INTENT       \"replenish stock for a product and log the transaction\"\n  PRECONDITION product_id.length > 0\n  PRECONDITION quantity > 0\n  POSTCONDITION result.stock_level >= 0\n  READS        products_table\n  MUTATES      products_table\n  MUTATES      inventory_log_table\n  OBSERVABLE\n\n  product = QUERY products_table WHERE id == product_id LIMIT 1\n  FALLBACK product IS NULL THEN\n    PERSIST inventory_log_table (product_id: product_id, action: \"restock_failed\", reason: \"product_not_found\", timestamp: now())\n    RETURN RestockResult(success: FALSE, stock_level: 0, message: \"Product not found\")\n  END FALLBACK\n\n  new_stock = product.stock_level + quantity\n  UPDATE products_table SET stock_level = new_stock WHERE id == product_id\n  PERSIST inventory_log_table (product_id: product_id, action: \"restock\", quantity_added: quantity, new_stock: new_stock, timestamp: now())\n  RETURN RestockResult(success: TRUE, stock_level: new_stock, message: \"Stock replenished successfully\")\nEND FUNCTION restock_inventory [id=f2759]", "completion": "# ═══ INTL:BEGIN [id=f2759] restock_inventory ═══\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nasync def restock_inventory(product_id: str, quantity: int) -> RestockResult:\n    assert len(product_id) > 0, \"product_id must not be empty\"\n    assert quantity > 0, \"quantity must be greater than 0\"\n    \n    product = await db.query(products_table).filter(id=product_id).first()\n    if product is None:\n        await db.insert(inventory_log_table, \n                       product_id=product_id, \n                       action=\"restock_failed\", \n                       reason=\"product_not_found\", \n                       timestamp=datetime.utcnow())\n        logger.warning(\"restock_inventory: product_not_found product_id=%s\", product_id)\n        return RestockResult(success=False, stock_level=0, message=\"Product not found\")\n    \n    new_stock = product.stock_level + quantity\n    await db.update(products_table).filter(id=product_id).set(stock_level=new_stock)\n    await db.insert(inventory_log_table,\n                   product_id=product_id,\n                   action=\"restock\",\n                   quantity_added=quantity,\n                   new_stock=new_stock,\n                   timestamp=datetime.utcnow())\n    \n    logger.info(\"restock_inventory: product_id=%s quantity=%d new_stock=%d\", product_id, quantity, new_stock)\n    result = RestockResult(success=True, stock_level=new_stock, message=\"Stock replenished successfully\")\n    assert result.stock_level >= 0, \"stock_level must be non-negative\"\n    return result\n# ═══ INTL:END   [id=f2759] restock_inventory ═══", "metadata": {"category": "A", "adapter": "python_fastapi", "construct": "FALLBACK", "idx": 2759}}
